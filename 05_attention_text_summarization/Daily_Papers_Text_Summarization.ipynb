{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31154,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanguyenai/sudo-code-nlp/blob/main/05_attention_text_summarization/Daily_Papers_Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Setup & Install dependencies"
      ],
      "metadata": {
        "id": "qoDI_OWGoHDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swu3suCtc1Kv",
        "outputId": "74180208-644a-4bf3-b510-4aa7528923b1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=59cbeb21801ad7f9519dc555eff1203503c48683a67006d39b2784c2854d1f53\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "from typing import List, Dict\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import HTML, display\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixYBt2cfuEwW",
        "outputId": "d5d15f4c-5e91-43f5-bb3a-b1919439b605",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-15T01:02:55.062687Z",
          "iopub.execute_input": "2025-10-15T01:02:55.063380Z",
          "iopub.status.idle": "2025-10-15T01:03:00.577739Z",
          "shell.execute_reply.started": "2025-10-15T01:02:55.063355Z",
          "shell.execute_reply": "2025-10-15T01:03:00.576935Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "execution_count": 87
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Crawl papers from Hugging Face"
      ],
      "metadata": {
        "id": "TFIUkVPb79cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HuggingFaceScraper:\n",
        "    \"\"\"\n",
        "    Advanced HuggingFace Papers Scraper with Full Abstract Support\n",
        "    Scrapes papers from https://huggingface.co/papers with complete abstracts\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.base_url = \"https://huggingface.co\"\n",
        "        self.session = requests.Session()\n",
        "        self.user_agents = [\n",
        "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
        "        ]\n",
        "        self.session.headers.update({\n",
        "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
        "            'Accept-Language': 'en-US,en;q=0.5',\n",
        "            'Accept-Encoding': 'gzip, deflate, br',\n",
        "            'Connection': 'keep-alive',\n",
        "            'Upgrade-Insecure-Requests': '1'\n",
        "        })\n",
        "\n",
        "    def scrape_date_range(self, start_date, end_date, delay=2.5, fetch_full_abstract=True):\n",
        "        \"\"\"\n",
        "        Scrape papers from date range\n",
        "\n",
        "        Args:\n",
        "            start_date (str): Start date in YYYY-MM-DD format\n",
        "            end_date (str): End date in YYYY-MM-DD format\n",
        "            delay (float): Delay between requests in seconds\n",
        "            fetch_full_abstract (bool): If True, visit each paper page to get full abstract\n",
        "\n",
        "        Returns:\n",
        "            list: List of paper dictionaries\n",
        "        \"\"\"\n",
        "        current = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "        end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "\n",
        "        all_papers = []\n",
        "        days = 0\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"üöÄ SCRAPING HUGGINGFACE PAPERS\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"üìÖ Date range: {start_date} to {end_date}\")\n",
        "        print(f\"‚öôÔ∏è  Full abstract mode: {'ENABLED ‚úì' if fetch_full_abstract else 'DISABLED ‚úó'}\")\n",
        "        if fetch_full_abstract:\n",
        "            print(f\"‚ö†Ô∏è  Note: Full abstract mode is SLOWER but gets complete abstracts\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "        while current <= end:\n",
        "            date_str = current.strftime(\"%Y-%m-%d\")\n",
        "            papers = self._scrape_date(date_str, fetch_full_abstract)\n",
        "\n",
        "            if papers:\n",
        "                all_papers.extend(papers)\n",
        "                print(f\"‚úì {date_str}: {len(papers)} papers\")\n",
        "            else:\n",
        "                print(f\"‚óã {date_str}: no papers\")\n",
        "\n",
        "            days += 1\n",
        "\n",
        "            # Progress update every 10 days\n",
        "            if days % 10 == 0:\n",
        "                print(f\"\\n{'‚îÄ'*80}\")\n",
        "                print(f\"üìä Progress: {days} days, {len(all_papers)} papers total\")\n",
        "                print(f\"{'‚îÄ'*80}\\n\")\n",
        "                time.sleep(random.uniform(5, 10))  # Longer break\n",
        "\n",
        "            current += timedelta(days=1)\n",
        "            time.sleep(delay + random.uniform(0, 2))\n",
        "\n",
        "        # Deduplicate\n",
        "        unique = self._deduplicate(all_papers)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"‚úÖ SCRAPING COMPLETE!\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"üìä Total unique papers: {len(unique)}\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "        return unique\n",
        "\n",
        "    def _scrape_date(self, date_str, fetch_full_abstract=True):\n",
        "        \"\"\"\n",
        "        Scrape papers from a specific date\n",
        "\n",
        "        Args:\n",
        "            date_str (str): Date in YYYY-MM-DD format\n",
        "            fetch_full_abstract (bool): Whether to fetch full abstracts\n",
        "\n",
        "        Returns:\n",
        "            list: List of papers for that date\n",
        "        \"\"\"\n",
        "        url = f\"{self.base_url}/papers/date/{date_str}\"\n",
        "\n",
        "        try:\n",
        "            headers = {'User-Agent': random.choice(self.user_agents)}\n",
        "            response = self.session.get(url, headers=headers, timeout=15)\n",
        "\n",
        "            if response.status_code == 404:\n",
        "                return []\n",
        "\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Find all paper articles (limit to 50 per day)\n",
        "            articles = soup.find_all('article')[:50]\n",
        "\n",
        "            papers = []\n",
        "            for i, article in enumerate(articles, 1):\n",
        "                paper = self._parse_article(article, date_str, fetch_full_abstract)\n",
        "                if paper:\n",
        "                    papers.append(paper)\n",
        "                    if fetch_full_abstract and i % 5 == 0:\n",
        "                        print(f\"      Progress: {i}/{len(articles)} papers processed\")\n",
        "\n",
        "            return papers\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"   ‚ùå Request error for {date_str}: {e}\")\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Unexpected error for {date_str}: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _parse_article(self, article, date_str, fetch_full_abstract=True):\n",
        "        \"\"\"\n",
        "        Parse article element to extract paper information\n",
        "\n",
        "        Args:\n",
        "            article: BeautifulSoup element\n",
        "            date_str (str): Date string\n",
        "            fetch_full_abstract (bool): Whether to fetch full abstract\n",
        "\n",
        "        Returns:\n",
        "            dict: Paper information or None if parsing fails\n",
        "        \"\"\"\n",
        "        paper = {\n",
        "            'date': date_str,\n",
        "            'scraped_at': datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        # Extract title\n",
        "        title_elem = article.find('h3') or article.find('h2')\n",
        "        if not title_elem:\n",
        "            return None\n",
        "        paper['title'] = title_elem.get_text(strip=True)\n",
        "\n",
        "        # Extract link and paper ID\n",
        "        link_elem = article.find('a', href=re.compile(r'/papers/\\d+\\.\\d+'))\n",
        "        if link_elem:\n",
        "            paper['link'] = self.base_url + link_elem['href']\n",
        "\n",
        "            # Extract arXiv ID (format: YYMM.NNNNN)\n",
        "            match = re.search(r'(\\d{4})\\.(\\d{4,5})', link_elem['href'])\n",
        "            if match:\n",
        "                paper['paper_id'] = f\"{match.group(1)}.{match.group(2)}\"\n",
        "                # Extract year from arXiv ID\n",
        "                year_code = match.group(1)[:2]\n",
        "                paper['year'] = 2000 + int(year_code)\n",
        "\n",
        "        # Extract metadata from listing page\n",
        "        text_content = article.get_text()\n",
        "\n",
        "        # Extract number of authors\n",
        "        author_match = re.search(r'(\\d+)\\s+authors?', text_content, re.IGNORECASE)\n",
        "        if author_match:\n",
        "            paper['authors_count'] = int(author_match.group(1))\n",
        "\n",
        "        # Extract upvotes - Multiple strategies\n",
        "        # Strategy 1: Look for div with class \"leading-none\" (common for upvote count)\n",
        "        upvote_div = article.find('div', class_='leading-none')\n",
        "        if upvote_div:\n",
        "            upvote_text = upvote_div.get_text(strip=True)\n",
        "            try:\n",
        "                paper['upvotes'] = int(upvote_text)\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "        # Strategy 2: Text pattern matching (fallback)\n",
        "        if 'upvotes' not in paper:\n",
        "            upvote_match = re.search(r'(\\d+)\\s+(?:upvotes?|likes?)', text_content, re.IGNORECASE)\n",
        "            if upvote_match:\n",
        "                paper['upvotes'] = int(upvote_match.group(1))\n",
        "\n",
        "        # Extract abstract\n",
        "        if fetch_full_abstract and paper.get('link'):\n",
        "            # Fetch FULL abstract AND additional metadata from detail page\n",
        "            print(f\"      üìñ {paper['title'][:60]}...\")\n",
        "            detail_data = self._fetch_detail_page(paper['link'])\n",
        "\n",
        "            if detail_data:\n",
        "                # Update with full abstract\n",
        "                if detail_data.get('abstract'):\n",
        "                    paper['abstract'] = detail_data['abstract']\n",
        "                    paper['abstract_type'] = 'full'\n",
        "                    word_count = len(detail_data['abstract'].split())\n",
        "                    print(f\"         ‚úì Full abstract: {word_count} words\")\n",
        "\n",
        "                # Update upvotes from detail page if not found earlier\n",
        "                if detail_data.get('upvotes') and not paper.get('upvotes'):\n",
        "                    paper['upvotes'] = detail_data['upvotes']\n",
        "\n",
        "                # Add any other metadata from detail page\n",
        "                if detail_data.get('authors'):\n",
        "                    paper['authors'] = detail_data['authors']\n",
        "            else:\n",
        "                # Fallback to preview\n",
        "                print(f\"         ‚ö†Ô∏è Detail page failed, using preview\")\n",
        "                preview = self._extract_preview_abstract(article)\n",
        "                if preview:\n",
        "                    paper['abstract'] = preview\n",
        "                    paper['abstract_type'] = 'preview'\n",
        "\n",
        "            # Add delay between detail page requests\n",
        "            time.sleep(random.uniform(1.5, 3))\n",
        "        else:\n",
        "            # Get preview abstract from listing page\n",
        "            preview = self._extract_preview_abstract(article)\n",
        "            if preview:\n",
        "                paper['abstract'] = preview\n",
        "                paper['abstract_type'] = 'preview'\n",
        "\n",
        "        # Only return paper if it has an abstract\n",
        "        return paper if paper.get('abstract') else None\n",
        "\n",
        "    def _extract_preview_abstract(self, article):\n",
        "        \"\"\"\n",
        "        Extract preview abstract from listing page\n",
        "\n",
        "        Args:\n",
        "            article: BeautifulSoup element\n",
        "\n",
        "        Returns:\n",
        "            str: Preview abstract or None\n",
        "        \"\"\"\n",
        "        paragraphs = article.find_all('p')\n",
        "        abstracts = [p.get_text(strip=True) for p in paragraphs\n",
        "                    if len(p.get_text(strip=True)) > 50]\n",
        "\n",
        "        if abstracts:\n",
        "            return ' '.join(abstracts)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _fetch_detail_page(self, paper_url):\n",
        "        \"\"\"\n",
        "        Fetch complete information from paper detail page\n",
        "        Including: full abstract, upvotes, authors, etc.\n",
        "\n",
        "        Args:\n",
        "            paper_url (str): URL of the paper detail page\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary with abstract, upvotes, authors, etc. or None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            headers = {'User-Agent': random.choice(self.user_agents)}\n",
        "            response = self.session.get(paper_url, headers=headers, timeout=15)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            detail_data = {}\n",
        "\n",
        "            # ===== EXTRACT UPVOTES =====\n",
        "            # Look for div with class \"leading-none\" (common pattern for upvote display)\n",
        "            upvote_div = soup.find('div', class_='leading-none')\n",
        "            if upvote_div:\n",
        "                upvote_text = upvote_div.get_text(strip=True)\n",
        "                try:\n",
        "                    detail_data['upvotes'] = int(upvote_text)\n",
        "                except ValueError:\n",
        "                    pass\n",
        "\n",
        "            # ===== EXTRACT AUTHORS =====\n",
        "            # Look for author information (may need adjustment based on actual HTML)\n",
        "            author_links = soup.find_all('a', href=re.compile(r'/papers\\?author='))\n",
        "            if author_links:\n",
        "                detail_data['authors'] = [a.get_text(strip=True) for a in author_links]\n",
        "\n",
        "            # ===== EXTRACT FULL ABSTRACT =====\n",
        "            abstract = self._extract_abstract_from_soup(soup)\n",
        "            if abstract:\n",
        "                detail_data['abstract'] = abstract\n",
        "\n",
        "            return detail_data if detail_data else None\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"         ‚ùå Request error: {e}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"         ‚ùå Parse error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _extract_abstract_from_soup(self, soup):\n",
        "        \"\"\"\n",
        "        Extract abstract from BeautifulSoup object using multiple strategies\n",
        "\n",
        "        Args:\n",
        "            soup: BeautifulSoup object of the detail page\n",
        "\n",
        "        Returns:\n",
        "            str: Full abstract or None\n",
        "        \"\"\"\n",
        "        # ===== STRATEGY 1: Find Abstract heading and extract following content =====\n",
        "        headings = soup.find_all(['h2', 'h3'])\n",
        "        for heading in headings:\n",
        "            heading_text = heading.get_text(strip=True).lower()\n",
        "            if heading_text == 'abstract':\n",
        "                # Look for next sibling div or container\n",
        "                next_container = heading.find_next_sibling()\n",
        "                if next_container:\n",
        "                    # Extract all paragraphs with class text-gray\n",
        "                    paragraphs = next_container.find_all('p', class_=re.compile(r'text-gray'))\n",
        "                    if paragraphs:\n",
        "                        abstract_parts = []\n",
        "                        for p in paragraphs:\n",
        "                            text = p.get_text(separator=' ', strip=True)\n",
        "                            if len(text) > 20:\n",
        "                                abstract_parts.append(text)\n",
        "                        if abstract_parts:\n",
        "                            return ' '.join(abstract_parts)\n",
        "\n",
        "        # ===== STRATEGY 2: Direct search for text-gray-600 paragraphs =====\n",
        "        gray_paragraphs = soup.find_all('p', class_=re.compile(r'text-gray-600'))\n",
        "        if gray_paragraphs:\n",
        "            abstract_parts = []\n",
        "            for p in gray_paragraphs:\n",
        "                text = p.get_text(separator=' ', strip=True)\n",
        "                if len(text) > 50:\n",
        "                    abstract_parts.append(text)\n",
        "\n",
        "            if abstract_parts:\n",
        "                full_text = ' '.join(abstract_parts)\n",
        "                return full_text[:5000] if len(full_text) > 5000 else full_text\n",
        "\n",
        "        # ===== STRATEGY 3: Look in prose/content containers =====\n",
        "        content_containers = soup.find_all('div', class_=re.compile(r'prose|content|article'))\n",
        "        for container in content_containers:\n",
        "            paragraphs = container.find_all('p')\n",
        "            long_paras = []\n",
        "            for p in paragraphs:\n",
        "                text = p.get_text(separator=' ', strip=True)\n",
        "                if len(text) > 100:\n",
        "                    long_paras.append(text)\n",
        "\n",
        "            if long_paras:\n",
        "                return ' '.join(long_paras[:5])\n",
        "\n",
        "        # ===== STRATEGY 4: Get all substantial paragraphs (fallback) =====\n",
        "        all_paragraphs = soup.find_all('p')\n",
        "        substantial = []\n",
        "        for p in all_paragraphs:\n",
        "            text = p.get_text(separator=' ', strip=True)\n",
        "            if len(text) > 100:\n",
        "                substantial.append(text)\n",
        "\n",
        "        if substantial:\n",
        "            return ' '.join(substantial[:3])\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _deduplicate(self, papers):\n",
        "        \"\"\"\n",
        "        Remove duplicate papers based on paper_id or title\n",
        "\n",
        "        Args:\n",
        "            papers (list): List of paper dictionaries\n",
        "\n",
        "        Returns:\n",
        "            list: Deduplicated list of papers\n",
        "        \"\"\"\n",
        "        seen = set()\n",
        "        unique = []\n",
        "\n",
        "        for paper in papers:\n",
        "            # Use paper_id as primary key, fall back to title\n",
        "            key = paper.get('paper_id') or paper.get('title')\n",
        "            if key and key not in seen:\n",
        "                seen.add(key)\n",
        "                unique.append(paper)\n",
        "\n",
        "        if len(papers) != len(unique):\n",
        "            print(f\"üîÑ Deduplication: {len(papers)} ‚Üí {len(unique)} papers\")\n",
        "\n",
        "        return unique\n",
        "\n",
        "    def save(self, papers, filename=\"papers.json\"):\n",
        "        \"\"\"\n",
        "        Save papers to JSON file with statistics\n",
        "\n",
        "        Args:\n",
        "            papers (list): List of paper dictionaries\n",
        "            filename (str): Output filename\n",
        "\n",
        "        Returns:\n",
        "            str: Filename of saved file\n",
        "        \"\"\"\n",
        "        # Calculate statistics\n",
        "        stats = {\n",
        "            'total': len(papers),\n",
        "            'with_abstract': sum(1 for p in papers if p.get('abstract')),\n",
        "            'with_full_abstract': sum(1 for p in papers\n",
        "                                     if p.get('abstract_type') == 'full'),\n",
        "            'with_preview_abstract': sum(1 for p in papers\n",
        "                                        if p.get('abstract_type') == 'preview'),\n",
        "            'with_paper_id': sum(1 for p in papers if p.get('paper_id')),\n",
        "            'with_authors': sum(1 for p in papers if p.get('authors_count')),\n",
        "            'with_author_names': sum(1 for p in papers if p.get('authors')),\n",
        "            'with_upvotes': sum(1 for p in papers if p.get('upvotes')),\n",
        "            'avg_abstract_length': sum(len(p.get('abstract', '').split())\n",
        "                                      for p in papers) / len(papers) if papers else 0,\n",
        "            'avg_upvotes': sum(p.get('upvotes', 0) for p in papers) / sum(1 for p in papers if p.get('upvotes')) if any(p.get('upvotes') for p in papers) else 0\n",
        "        }\n",
        "\n",
        "        # Prepare output\n",
        "        output = {\n",
        "            'scraped_at': datetime.now().isoformat(),\n",
        "            'statistics': stats,\n",
        "            'papers': papers\n",
        "        }\n",
        "\n",
        "        # Save to file\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(output, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        # Print summary\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"üíæ SAVED TO: {filename}\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"üìä Statistics:\")\n",
        "        print(f\"   Total papers: {stats['total']}\")\n",
        "        print(f\"   With abstracts: {stats['with_abstract']}\")\n",
        "        print(f\"   - Full abstracts: {stats['with_full_abstract']}\")\n",
        "        print(f\"   - Preview abstracts: {stats['with_preview_abstract']}\")\n",
        "        print(f\"   With upvotes: {stats['with_upvotes']} (avg: {stats['avg_upvotes']:.1f})\")\n",
        "        print(f\"   With author names: {stats['with_author_names']}\")\n",
        "        print(f\"   Average abstract length: {stats['avg_abstract_length']:.1f} words\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "        return filename\n",
        "\n",
        "    def scrape_recent_days(self, num_days=30, fetch_full_abstract=True):\n",
        "        \"\"\"\n",
        "        Scrape papers from recent N days\n",
        "\n",
        "        Args:\n",
        "            num_days (int): Number of recent days to scrape\n",
        "            fetch_full_abstract (bool): Whether to fetch full abstracts\n",
        "\n",
        "        Returns:\n",
        "            list: List of papers\n",
        "        \"\"\"\n",
        "        end_date = datetime.now()\n",
        "        start_date = end_date - timedelta(days=num_days)\n",
        "\n",
        "        return self.scrape_date_range(\n",
        "            start_date=start_date.strftime(\"%Y-%m-%d\"),\n",
        "            end_date=end_date.strftime(\"%Y-%m-%d\"),\n",
        "            fetch_full_abstract=fetch_full_abstract\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def load(filename=\"papers.json\"):\n",
        "        \"\"\"Load papers from JSON file (works for both FastHFScraper and HuggingFaceScraper formats)\"\"\"\n",
        "        try:\n",
        "            with open(filename, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            papers = data.get('papers', [])\n",
        "            stats = data.get('stats') or data.get('statistics', {})  # Support both formats\n",
        "            scraped_at = data.get('scraped_at', 'Unknown')\n",
        "\n",
        "            print(f\"\\nüìÇ Loaded from: {filename}\")\n",
        "            print(f\"   Scraped at: {scraped_at}\")\n",
        "            print(f\"   Total papers: {stats.get('total', len(papers))}\")\n",
        "\n",
        "            # Handle both date_range formats\n",
        "            date_range = stats.get('date_range')\n",
        "            if date_range:\n",
        "                if isinstance(date_range, list):\n",
        "                    print(f\"   Date range: {date_range[0]} to {date_range[1]}\")\n",
        "                else:\n",
        "                    print(f\"   Date range: {date_range}\")\n",
        "\n",
        "            return papers\n",
        "        except FileNotFoundError:\n",
        "            print(f\"‚ùå File not found: {filename}\")\n",
        "            return []\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"‚ùå Invalid JSON file: {filename}\")\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading file: {e}\")\n",
        "            return []"
      ],
      "metadata": {
        "id": "vRNFttKyuSTm",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-15T01:03:00.579047Z",
          "iopub.execute_input": "2025-10-15T01:03:00.579425Z",
          "iopub.status.idle": "2025-10-15T01:03:00.614246Z",
          "shell.execute_reply.started": "2025-10-15T01:03:00.579389Z",
          "shell.execute_reply": "2025-10-15T01:03:00.613452Z"
        }
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"üî• SCRAPING WITH ANTI-BLOCKING PROTECTION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "scraper = HuggingFaceScraper()\n",
        "\n",
        "print(\"\\nüéØ Full scraping mode: Every day from Jan to Oct 2025\")\n",
        "papers = scraper.scrape_recent_days(num_days=365, fetch_full_abstract=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UY8_47pT-BH",
        "outputId": "e032f2d2-fca1-468b-aefa-4f45e2af2bb4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-15T01:03:00.614978Z",
          "iopub.execute_input": "2025-10-15T01:03:00.615226Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "================================================================================\nüî• SCRAPING WITH ANTI-BLOCKING PROTECTION\n================================================================================\n\nüéØ Full scraping mode: Every day from Jan to Oct 2025\n‚ö†Ô∏è  This will take 15-20 minutes but gives maximum papers!\n\n\n================================================================================\nüöÄ SCRAPING HUGGINGFACE PAPERS\n================================================================================\nüìÖ Date range: 2024-10-15 to 2025-10-15\n‚öôÔ∏è  Full abstract mode: ENABLED ‚úì\n‚ö†Ô∏è  Note: Full abstract mode is SLOWER but gets complete abstracts\n================================================================================\n\n      üìñ Animate-X: Universal Character Image Animation with Enhanced...\n         ‚úì Full abstract: 214 words\n      üìñ LOKI: A Comprehensive Synthetic Data Detection Benchmark usi...\n         ‚úì Full abstract: 198 words\n      üìñ MMIE: Massive Multimodal Interleaved Comprehension Benchmark...\n         ‚úì Full abstract: 226 words\n      üìñ Toward General Instruction-Following Alignment for Retrieval...\n         ‚úì Full abstract: 237 words\n      üìñ MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-W...\n         ‚úì Full abstract: 171 words\n      Progress: 5/22 papers processed\n      üìñ Omni-MATH: A Universal Olympiad Level Mathematic Benchmark F...\n         ‚úì Full abstract: 175 words\n      üìñ Semantic Image Inversion and Editing using Rectified Stochas...\n         ‚úì Full abstract: 194 words\n      üìñ VisRAG: Vision-based Retrieval-augmented Generation on Multi...\n         ‚úì Full abstract: 211 words\n      üìñ LiveXiv -- A Multi-Modal Live Benchmark Based on Arxiv Paper...\n         ‚úì Full abstract: 242 words\n      üìñ Cavia: Camera-controllable Multi-view Video Diffusion with\n ...\n         ‚úì Full abstract: 182 words\n      Progress: 10/22 papers processed\n      üìñ Thinking LLMs: General Instruction Following with Thought Ge...\n         ‚úì Full abstract: 167 words\n      üìñ TemporalBench: Benchmarking Fine-grained Temporal Understand...\n         ‚úì Full abstract: 231 words\n      üìñ Rethinking Data Selection at Scale: Random Selection is Almo...\n         ‚úì Full abstract: 202 words\n      üìñ LongMemEval: Benchmarking Chat Assistants on Long-Term Inter...\n         ‚úì Full abstract: 213 words\n      üìñ MMCOMPOSITION: Revisiting the Compositionality of Pre-traine...\n         ‚úì Full abstract: 207 words\n      Progress: 15/22 papers processed\n      üìñ Tree of Problems: Improving structured problem solving with\n...\n         ‚úì Full abstract: 128 words\n      üìñ DuoAttention: Efficient Long-Context LLM Inference with Retr...\n         ‚úì Full abstract: 238 words\n      üìñ Generalizable Humanoid Manipulation with Improved 3D Diffusi...\n         ‚úì Full abstract: 140 words\n      üìñ TVBench: Redesigning Video-Language Evaluation...\n         ‚úì Full abstract: 204 words\n      üìñ The Same But Different: Structural Similarities and Differen...\n         ‚úì Full abstract: 188 words\n      Progress: 20/22 papers processed\n      üìñ ReLU's Revival: On the Entropic Overload in Normalization-Fr...\n         ‚úì Full abstract: 169 words\n      üìñ Latent Action Pretraining from Videos...\n         ‚úì Full abstract: 187 words\n‚úì 2024-10-15: 22 papers\n      üìñ Your Mixture-of-Experts LLM Is Secretly an Embedding Model F...\n         ‚úì Full abstract: 199 words\n      üìñ Efficiently Democratizing Medical LLMs for 50 Languages via ...\n         ‚úì Full abstract: 198 words\n      üìñ LLMtimesMapReduce: Simplified Long-Sequence Processing using...\n         ‚úì Full abstract: 170 words\n      üìñ What Matters in Transformers? Not All Attention is Needed...\n         ‚úì Full abstract: 214 words\n      üìñ MLLM can see? Dynamic Correction Decoding for Hallucination ...\n         ‚úì Full abstract: 160 words\n      Progress: 5/18 papers processed\n      üìñ Agent-as-a-Judge: Evaluate Agents with Agents...\n         ‚úì Full abstract: 176 words\n      üìñ LVD-2M: A Long-take Video Dataset with Temporally Dense Capt...\n         ‚úì Full abstract: 240 words\n      üìñ MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large ...\n         ‚úì Full abstract: 190 words\n      üìñ Efficient Diffusion Models: A Comprehensive Survey from Prin...\n         ‚úì Full abstract: 161 words\n      üìñ NesTools: A Dataset for Evaluating Nested Tool Learning Abil...\n         ‚úì Full abstract: 160 words\n      Progress: 10/18 papers processed\n      üìñ EchoPrime: A Multi-Video View-Informed Vision-Language Model...\n         ‚úì Full abstract: 214 words\n      üìñ SecCodePLT: A Unified Platform for Evaluating the Security o...\n         ‚úì Full abstract: 263 words\n      üìñ GS^3: Efficient Relighting with Triple Gaussian Splatting...\n         ‚úì Full abstract: 191 words\n      üìñ SimBa: Simplicity Bias for Scaling Up Parameters in Deep Rei...\n         ‚úì Full abstract: 194 words\n      üìñ Towards Synergistic, Generalized, and Efficient Dual-System ...\n         ‚úì Full abstract: 185 words\n      Progress: 15/18 papers processed\n      üìñ Towards Natural Image Matting in the Wild via Real-Scenario ...\n         ‚úì Full abstract: 246 words\n      üìñ Empirical Study of Mutual Reinforcement Effect and Applicati...\n         ‚úì Full abstract: 158 words\n      üìñ MultiVENT 2.0: A Massive Multilingual Benchmark for Event-Ce...\n         ‚úì Full abstract: 153 words\n‚úì 2024-10-16: 18 papers\n      üìñ VidEgoThink: Assessing Egocentric Video Understanding Capabi...\n         ‚úì Full abstract: 204 words\n      üìñ HumanEval-V: Benchmarking High-Level Visual Reasoning with C...\n         ‚úì Full abstract: 162 words\n      üìñ DocLayout-YOLO: Enhancing Document Layout Analysis through D...\n         ‚úì Full abstract: 185 words\n      üìñ The Curse of Multi-Modalities: Evaluating Hallucinations of ...\n         ‚úì Full abstract: 173 words\n      üìñ Revealing the Barriers of Language Agents in Planning...\n         ‚úì Full abstract: 195 words\n      Progress: 5/23 papers processed\n      üìñ Exploring Model Kinship for Merging Large Language Models...\n         ‚úì Full abstract: 159 words\n      üìñ Simplifying, Stabilizing and Scaling Continuous-Time Consist...\n         ‚úì Full abstract: 152 words\n      üìñ Large Language Model Evaluation via Matrix Nuclear-Norm...\n         ‚úì Full abstract: 215 words\n      üìñ Improving Long-Text Alignment for Text-to-Image Diffusion Mo...\n         ‚úì Full abstract: 235 words\n      üìñ Controllable Safety Alignment: Inference-Time Adaptation to ...\n         ‚úì Full abstract: 239 words\n      Progress: 10/23 papers processed\n      üìñ DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with...\n         ‚úì Full abstract: 145 words\n      üìñ ProSA: Assessing and Understanding the Prompt Sensitivity of...\n         ‚úì Full abstract: 161 words\n      üìñ ZipVL: Efficient Large Vision-Language Models with Dynamic T...\n         ‚úì Full abstract: 262 words\n      üìñ Stabilize the Latent Space for Image Autoregressive Modeling...\n         ‚úì Full abstract: 260 words\n      üìñ ChroKnowledge: Unveiling Chronological Knowledge of Language...\n         ‚úì Full abstract: 255 words\n      Progress: 15/23 papers processed\n      üìñ Neural Metamorphosis...\n         ‚úì Full abstract: 217 words\n      üìñ WorldMedQA-V: a multilingual, multimodal medical examination...\n         ‚úì Full abstract: 159 words\n      üìñ Tracking Universal Features Through Fine-Tuning and Model Me...\n         ‚úì Full abstract: 104 words\n      üìñ Insights from the Inverse: Reconstructing LLM Training Goals...\n         ‚úì Full abstract: 143 words\n      üìñ OMCAT: Omni Context Aware Transformer...\n         ‚úì Full abstract: 198 words\n      Progress: 20/23 papers processed\n      üìñ FLARE: Faithful Logic-Aided Reasoning and Exploration...\n         ‚úì Full abstract: 245 words\n      üìñ Taming Overconfidence in LLMs: Reward Calibration in RLHF...\n         ‚úì Full abstract: 244 words\n      üìñ From Commands to Prompts: LLM-based Semantic File System for...\n         ‚úì Full abstract: 243 words\n‚úì 2024-10-17: 23 papers\n      üìñ Movie Gen: A Cast of Media Foundation Models...\n         ‚úì Full abstract: 172 words\n      üìñ MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtu...\n         ‚úì Full abstract: 149 words\n      üìñ JudgeBench: A Benchmark for Evaluating LLM-based Judges...\n         ‚úì Full abstract: 204 words\n      üìñ Fluid: Scaling Autoregressive Text-to-image Generative Model...\n         ‚úì Full abstract: 197 words\n      üìñ Janus: Decoupling Visual Encoding for Unified Multimodal Und...\n         ‚úì Full abstract: 154 words\n      Progress: 5/34 papers processed\n      üìñ Roadmap towards Superhuman Speech Understanding using Large ...\n         ‚úì Full abstract: 166 words\n      üìñ MobA: A Two-Level Agent System for Efficient Mobile Task Aut...\n         ‚úì Full abstract: 135 words\n      üìñ WorldCuisines: A Massive-Scale Benchmark for Multilingual an...\n         ‚úì Full abstract: 151 words\n      üìñ Harnessing Webpage UIs for Text-Rich Visual Understanding...\n         ‚úì Full abstract: 176 words\n      üìñ DreamVideo-2: Zero-Shot Subject-Driven Video Customization w...\n         ‚úì Full abstract: 233 words\n      Progress: 10/34 papers processed\n      üìñ MMed-RAG: Versatile Multimodal RAG System for Medical Vision...\n         ‚úì Full abstract: 211 words\n      üìñ MoH: Multi-Head Attention as Mixture-of-Head Attention...\n         ‚úì Full abstract: 214 words\n      üìñ BenTo: Benchmark Task Reduction with In-Context Transferabil...\n         ‚úì Full abstract: 133 words\n      üìñ PopAlign: Diversifying Contrasting Patterns for a More Compr...\n         ‚úì Full abstract: 154 words\n      üìñ A Comparative Study on Reasoning Patterns of OpenAI's o1 Mod...\n         ‚úì Full abstract: 230 words\n      Progress: 15/34 papers processed\n      üìñ A Unified View of Delta Parameter Editing in Post-Trained La...\n         ‚úì Full abstract: 189 words\n      üìñ FlatQuant: Flatness Matters for LLM Quantization...\n         ‚úì Full abstract: 204 words\n      üìñ VidPanos: Generative Panoramic Videos from Casual Panning Vi...\n         ‚úì Full abstract: 190 words\n      üìñ Do LLMs Have Political Correctness? Analyzing Ethical Biases...\n         ‚úì Full abstract: 235 words\n      üìñ Can MLLMs Understand the Deep Implication Behind Chinese Ima...\n         ‚úì Full abstract: 270 words\n      Progress: 20/34 papers processed\n      üìñ Retrospective Learning from Interactions...\n         ‚úì Full abstract: 151 words\n      üìñ Failing Forward: Improving Generative Error Correction for A...\n         ‚úì Full abstract: 211 words\n      üìñ Remember, Retrieve and Generate: Understanding Infinite Visu...\n         ‚úì Full abstract: 220 words\n      üìñ MuVi: Video-to-Music Generation with Semantic Alignment and ...\n         ‚úì Full abstract: 168 words\n      üìñ MedMobile: A mobile-sized language model with expert-level c...\n         ‚úì Full abstract: 112 words\n      Progress: 25/34 papers processed\n      üìñ Œ≥-MoD: Exploring Mixture-of-Depth Adaptation for Multimodal ...\n         ‚úì Full abstract: 256 words\n      üìñ LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decompositio...\n         ‚úì Full abstract: 184 words\n      üìñ Open Materials 2024 (OMat24) Inorganic Materials Dataset and...\n         ‚úì Full abstract: 215 words\n      üìñ Long-LRM: Long-sequence Large Reconstruction Model for Wide-...\n         ‚úì Full abstract: 150 words\n      üìñ Minimum Tuning to Unlock Long Output from LLMs with High Qua...\n         ‚úì Full abstract: 221 words\n      Progress: 30/34 papers processed\n      üìñ Toward Guidance-Free AR Visual Generation via Condition Cont...\n         ‚úì Full abstract: 196 words\n      üìñ AERO: Softmax-Only LLMs for Efficient Private Inference...\n         ‚úì Full abstract: 149 words\n      üìñ TransAgent: Transfer Vision-Language Foundation Models with\n...\n         ‚úì Full abstract: 196 words\n      üìñ SBI-RAG: Enhancing Math Word Problem Solving for Students th...\n         ‚úì Full abstract: 118 words\n‚úì 2024-10-18: 34 papers\n      üìñ Movie Gen: A Cast of Media Foundation Models...\n         ‚úì Full abstract: 172 words\n      üìñ MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtu...\n         ‚úì Full abstract: 149 words\n      üìñ JudgeBench: A Benchmark for Evaluating LLM-based Judges...\n         ‚úì Full abstract: 204 words\n      üìñ Fluid: Scaling Autoregressive Text-to-image Generative Model...\n         ‚úì Full abstract: 197 words\n      üìñ Janus: Decoupling Visual Encoding for Unified Multimodal Und...\n         ‚úì Full abstract: 154 words\n      Progress: 5/34 papers processed\n      üìñ Roadmap towards Superhuman Speech Understanding using Large ...\n         ‚úì Full abstract: 166 words\n      üìñ MobA: A Two-Level Agent System for Efficient Mobile Task Aut...\n         ‚úì Full abstract: 135 words\n      üìñ WorldCuisines: A Massive-Scale Benchmark for Multilingual an...\n         ‚úì Full abstract: 151 words\n      üìñ Harnessing Webpage UIs for Text-Rich Visual Understanding...\n         ‚úì Full abstract: 176 words\n      üìñ DreamVideo-2: Zero-Shot Subject-Driven Video Customization w...\n         ‚úì Full abstract: 233 words\n      Progress: 10/34 papers processed\n      üìñ MMed-RAG: Versatile Multimodal RAG System for Medical Vision...\n         ‚úì Full abstract: 211 words\n      üìñ MoH: Multi-Head Attention as Mixture-of-Head Attention...\n         ‚úì Full abstract: 214 words\n      üìñ BenTo: Benchmark Task Reduction with In-Context Transferabil...\n         ‚úì Full abstract: 133 words\n      üìñ PopAlign: Diversifying Contrasting Patterns for a More Compr...\n         ‚úì Full abstract: 154 words\n      üìñ A Comparative Study on Reasoning Patterns of OpenAI's o1 Mod...\n         ‚úì Full abstract: 230 words\n      Progress: 15/34 papers processed\n      üìñ A Unified View of Delta Parameter Editing in Post-Trained La...\n         ‚úì Full abstract: 189 words\n      üìñ FlatQuant: Flatness Matters for LLM Quantization...\n         ‚úì Full abstract: 204 words\n      üìñ VidPanos: Generative Panoramic Videos from Casual Panning Vi...\n         ‚úì Full abstract: 190 words\n      üìñ Do LLMs Have Political Correctness? Analyzing Ethical Biases...\n         ‚úì Full abstract: 235 words\n      üìñ Can MLLMs Understand the Deep Implication Behind Chinese Ima...\n         ‚úì Full abstract: 270 words\n      Progress: 20/34 papers processed\n      üìñ Retrospective Learning from Interactions...\n         ‚úì Full abstract: 151 words\n      üìñ Failing Forward: Improving Generative Error Correction for A...\n         ‚úì Full abstract: 211 words\n      üìñ Remember, Retrieve and Generate: Understanding Infinite Visu...\n         ‚úì Full abstract: 220 words\n      üìñ MuVi: Video-to-Music Generation with Semantic Alignment and ...\n         ‚úì Full abstract: 168 words\n      üìñ MedMobile: A mobile-sized language model with expert-level c...\n         ‚úì Full abstract: 112 words\n      Progress: 25/34 papers processed\n      üìñ Œ≥-MoD: Exploring Mixture-of-Depth Adaptation for Multimodal ...\n         ‚úì Full abstract: 256 words\n      üìñ LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decompositio...\n         ‚úì Full abstract: 184 words\n      üìñ Open Materials 2024 (OMat24) Inorganic Materials Dataset and...\n         ‚úì Full abstract: 215 words\n      üìñ Long-LRM: Long-sequence Large Reconstruction Model for Wide-...\n         ‚úì Full abstract: 150 words\n      üìñ Minimum Tuning to Unlock Long Output from LLMs with High Qua...\n         ‚úì Full abstract: 221 words\n      Progress: 30/34 papers processed\n      üìñ Toward Guidance-Free AR Visual Generation via Condition Cont...\n         ‚úì Full abstract: 196 words\n      üìñ AERO: Softmax-Only LLMs for Efficient Private Inference...\n         ‚úì Full abstract: 149 words\n      üìñ TransAgent: Transfer Vision-Language Foundation Models with\n...\n         ‚úì Full abstract: 196 words\n      üìñ SBI-RAG: Enhancing Math Word Problem Solving for Students th...\n         ‚úì Full abstract: 118 words\n‚úì 2024-10-19: 34 papers\n      üìñ Movie Gen: A Cast of Media Foundation Models...\n         ‚úì Full abstract: 172 words\n      üìñ MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtu...\n         ‚úì Full abstract: 149 words\n      üìñ JudgeBench: A Benchmark for Evaluating LLM-based Judges...\n         ‚úì Full abstract: 204 words\n      üìñ Fluid: Scaling Autoregressive Text-to-image Generative Model...\n         ‚úì Full abstract: 197 words\n      üìñ Janus: Decoupling Visual Encoding for Unified Multimodal Und...\n         ‚úì Full abstract: 154 words\n      Progress: 5/34 papers processed\n      üìñ Roadmap towards Superhuman Speech Understanding using Large ...\n         ‚úì Full abstract: 166 words\n      üìñ MobA: A Two-Level Agent System for Efficient Mobile Task Aut...\n         ‚úì Full abstract: 135 words\n      üìñ WorldCuisines: A Massive-Scale Benchmark for Multilingual an...\n         ‚úì Full abstract: 151 words\n      üìñ Harnessing Webpage UIs for Text-Rich Visual Understanding...\n         ‚úì Full abstract: 176 words\n      üìñ DreamVideo-2: Zero-Shot Subject-Driven Video Customization w...\n         ‚úì Full abstract: 233 words\n      Progress: 10/34 papers processed\n      üìñ MMed-RAG: Versatile Multimodal RAG System for Medical Vision...\n         ‚úì Full abstract: 211 words\n      üìñ MoH: Multi-Head Attention as Mixture-of-Head Attention...\n         ‚úì Full abstract: 214 words\n      üìñ BenTo: Benchmark Task Reduction with In-Context Transferabil...\n         ‚úì Full abstract: 133 words\n      üìñ PopAlign: Diversifying Contrasting Patterns for a More Compr...\n         ‚úì Full abstract: 154 words\n      üìñ A Comparative Study on Reasoning Patterns of OpenAI's o1 Mod...\n         ‚úì Full abstract: 230 words\n      Progress: 15/34 papers processed\n      üìñ A Unified View of Delta Parameter Editing in Post-Trained La...\n         ‚úì Full abstract: 189 words\n      üìñ FlatQuant: Flatness Matters for LLM Quantization...\n         ‚úì Full abstract: 204 words\n      üìñ VidPanos: Generative Panoramic Videos from Casual Panning Vi...\n         ‚úì Full abstract: 190 words\n      üìñ Do LLMs Have Political Correctness? Analyzing Ethical Biases...\n         ‚úì Full abstract: 235 words\n      üìñ Can MLLMs Understand the Deep Implication Behind Chinese Ima...\n         ‚úì Full abstract: 270 words\n      Progress: 20/34 papers processed\n      üìñ Retrospective Learning from Interactions...\n         ‚úì Full abstract: 151 words\n      üìñ Failing Forward: Improving Generative Error Correction for A...\n         ‚úì Full abstract: 211 words\n      üìñ Remember, Retrieve and Generate: Understanding Infinite Visu...\n         ‚úì Full abstract: 220 words\n      üìñ MuVi: Video-to-Music Generation with Semantic Alignment and ...\n         ‚úì Full abstract: 168 words\n      üìñ MedMobile: A mobile-sized language model with expert-level c...\n         ‚úì Full abstract: 112 words\n      Progress: 25/34 papers processed\n      üìñ Œ≥-MoD: Exploring Mixture-of-Depth Adaptation for Multimodal ...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2410.13859\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decompositio...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2410.13618\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Open Materials 2024 (OMat24) Inorganic Materials Dataset and...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2410.12771\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Long-LRM: Long-sequence Large Reconstruction Model for Wide-...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2410.12781\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Minimum Tuning to Unlock Long Output from LLMs with High Qua...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2410.10210\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Toward Guidance-Free AR Visual Generation via Condition Cont...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2410.09347\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ AERO: Softmax-Only LLMs for Efficient Private Inference...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2410.13060\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ TransAgent: Transfer Vision-Language Foundation Models with\n...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2410.12183\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ SBI-RAG: Enhancing Math Word Problem Solving for Students th...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2410.13293\n         ‚ö†Ô∏è Detail page failed, using preview\n‚úì 2024-10-20: 25 papers\n   ‚ùå Request error for 2024-10-21: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-10-21\n‚óã 2024-10-21: no papers\n   ‚ùå Request error for 2024-10-22: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-10-22\n‚óã 2024-10-22: no papers\n   ‚ùå Request error for 2024-10-23: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-10-23\n‚óã 2024-10-23: no papers\n   ‚ùå Request error for 2024-10-24: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-10-24\n‚óã 2024-10-24: no papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 10 days, 156 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n   ‚ùå Request error for 2024-10-25: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-10-25\n‚óã 2024-10-25: no papers\n      üìñ Breaking the Memory Barrier: Near Infinite Batch Size Scalin...\n         ‚úì Full abstract: 183 words\n      üìñ Can Knowledge Editing Really Correct Hallucinations?...\n         ‚úì Full abstract: 223 words\n      üìñ LOGO -- Long cOntext aliGnment via efficient preference Opti...\n         ‚úì Full abstract: 207 words\n      üìñ Unleashing Reasoning Capability of LLMs via Scalable Questio...\n         ‚úì Full abstract: 199 words\n      üìñ Framer: Interactive Frame Interpolation...\n         ‚úì Full abstract: 189 words\n      Progress: 5/29 papers processed\n      üìñ Unbounded: A Generative Infinite Game of Character Life Simu...\n         ‚úì Full abstract: 209 words\n      üìñ Distill Visual Chart Reasoning Ability from LLMs to MLLMs...\n         ‚úì Full abstract: 193 words\n      üìñ Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs...\n         ‚úì Full abstract: 110 words\n      üìñ Steering Knowledge Selection Behaviours in LLMs via SAE-Base...\n         ‚úì Full abstract: 182 words\n      üìñ Why Does the Effective Context Length of LLMs Fall Short?...\n         ‚úì Full abstract: 172 words\n      Progress: 10/29 papers processed\n      üìñ Taipan: Efficient and Expressive State Space Language Models...\n         ‚úì Full abstract: 154 words\n      üìñ SMITE: Segment Me In TimE...\n         ‚úì Full abstract: 92 words\n      üìñ MotionCLR: Motion Generation and Training-free Editing via U...\n         ‚úì Full abstract: 191 words\n      üìñ WAFFLE: Multi-Modal Model for Automated Front-End Developmen...\n         ‚úì Full abstract: 159 words\n      üìñ CAMEL-Bench: A Comprehensive Arabic LMM Benchmark...\n         ‚úì Full abstract: 192 words\n      Progress: 15/29 papers processed\n      üìñ DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate\n...\n         ‚úì Full abstract: 161 words\n      üìñ CCI3.0-HQ: a large-scale Chinese dataset of high quality des...\n         ‚úì Full abstract: 101 words\n      üìñ Stable Consistency Tuning: Understanding and Improving Consi...\n         ‚úì Full abstract: 168 words\n      üìñ Robust Watermarking Using Generative Priors Against Image Ed...\n         ‚úì Full abstract: 214 words\n      üìñ Value Residual Learning For Alleviating Attention Concentrat...\n         ‚úì Full abstract: 186 words\n      Progress: 20/29 papers processed\n      üìñ ADEM-VL: Adaptive and Embedded Fusion for Efficient Vision-L...\n         ‚úì Full abstract: 257 words\n      üìñ Language Models are Symbolic Learners in Arithmetic...\n         ‚úì Full abstract: 189 words\n      üìñ Should We Really Edit Language Models? On the Evaluation of ...\n         ‚úì Full abstract: 219 words\n      üìñ The Nature of Mathematical Modeling and Probabilistic Optimi...\n         ‚úì Full abstract: 235 words\n      üìñ Asynchronous RLHF: Faster and More Efficient Off-Policy RL f...\n         ‚úì Full abstract: 203 words\n      Progress: 25/29 papers processed\n      üìñ Data Scaling Laws in Imitation Learning for Robotic Manipula...\n         ‚úì Full abstract: 222 words\n      üìñ ZIP-FIT: Embedding-Free Data Selection via Compression-Based...\n         ‚úì Full abstract: 257 words\n      üìñ Multi-Draft Speculative Sampling: Canonical Architectures an...\n         ‚úì Full abstract: 207 words\n      üìñ Pantograph: A Machine-to-Machine Interaction Interface for A...\n         ‚úì Full abstract: 154 words\n‚úì 2024-10-26: 29 papers\n      üìñ Breaking the Memory Barrier: Near Infinite Batch Size Scalin...\n         ‚úì Full abstract: 183 words\n      üìñ Can Knowledge Editing Really Correct Hallucinations?...\n         ‚úì Full abstract: 223 words\n      üìñ LOGO -- Long cOntext aliGnment via efficient preference Opti...\n         ‚úì Full abstract: 207 words\n      üìñ Unleashing Reasoning Capability of LLMs via Scalable Questio...\n         ‚úì Full abstract: 199 words\n      üìñ Framer: Interactive Frame Interpolation...\n         ‚úì Full abstract: 189 words\n      Progress: 5/29 papers processed\n      üìñ Unbounded: A Generative Infinite Game of Character Life Simu...\n         ‚úì Full abstract: 209 words\n      üìñ Distill Visual Chart Reasoning Ability from LLMs to MLLMs...\n         ‚úì Full abstract: 193 words\n      üìñ Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs...\n         ‚úì Full abstract: 110 words\n      üìñ Steering Knowledge Selection Behaviours in LLMs via SAE-Base...\n         ‚úì Full abstract: 182 words\n      üìñ Why Does the Effective Context Length of LLMs Fall Short?...\n         ‚úì Full abstract: 172 words\n      Progress: 10/29 papers processed\n      üìñ Taipan: Efficient and Expressive State Space Language Models...\n         ‚úì Full abstract: 154 words\n      üìñ SMITE: Segment Me In TimE...\n         ‚úì Full abstract: 92 words\n      üìñ MotionCLR: Motion Generation and Training-free Editing via U...\n         ‚úì Full abstract: 191 words\n      üìñ WAFFLE: Multi-Modal Model for Automated Front-End Developmen...\n         ‚úì Full abstract: 159 words\n      üìñ CAMEL-Bench: A Comprehensive Arabic LMM Benchmark...\n         ‚úì Full abstract: 192 words\n      Progress: 15/29 papers processed\n      üìñ DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate\n...\n         ‚úì Full abstract: 161 words\n      üìñ CCI3.0-HQ: a large-scale Chinese dataset of high quality des...\n         ‚úì Full abstract: 101 words\n      üìñ Stable Consistency Tuning: Understanding and Improving Consi...\n         ‚úì Full abstract: 168 words\n      üìñ Robust Watermarking Using Generative Priors Against Image Ed...\n         ‚úì Full abstract: 214 words\n      üìñ Value Residual Learning For Alleviating Attention Concentrat...\n         ‚úì Full abstract: 186 words\n      Progress: 20/29 papers processed\n      üìñ ADEM-VL: Adaptive and Embedded Fusion for Efficient Vision-L...\n         ‚úì Full abstract: 257 words\n      üìñ Language Models are Symbolic Learners in Arithmetic...\n         ‚úì Full abstract: 189 words\n      üìñ Should We Really Edit Language Models? On the Evaluation of ...\n         ‚úì Full abstract: 219 words\n      üìñ The Nature of Mathematical Modeling and Probabilistic Optimi...\n         ‚úì Full abstract: 235 words\n      üìñ Asynchronous RLHF: Faster and More Efficient Off-Policy RL f...\n         ‚úì Full abstract: 203 words\n      Progress: 25/29 papers processed\n      üìñ Data Scaling Laws in Imitation Learning for Robotic Manipula...\n         ‚úì Full abstract: 222 words\n      üìñ ZIP-FIT: Embedding-Free Data Selection via Compression-Based...\n         ‚úì Full abstract: 257 words\n      üìñ Multi-Draft Speculative Sampling: Canonical Architectures an...\n         ‚úì Full abstract: 207 words\n      üìñ Pantograph: A Machine-to-Machine Interaction Interface for A...\n         ‚úì Full abstract: 154 words\n‚úì 2024-10-27: 29 papers\n      üìñ ROCKET-1: Master Open-World Interaction with Visual-Temporal...\n         ‚úì Full abstract: 216 words\n      üìñ Continuous Speech Synthesis using per-token Latent Diffusion...\n         ‚úì Full abstract: 139 words\n      üìñ Teach Multimodal LLMs to Comprehend Electrocardiographic Ima...\n         ‚úì Full abstract: 196 words\n      üìñ FasterCache: Training-Free Video Diffusion Model Acceleratio...\n         ‚úì Full abstract: 168 words\n      üìñ MMAU: A Massive Multi-Task Audio Understanding and Reasoning...\n         ‚úì Full abstract: 172 words\n      Progress: 5/16 papers processed\n      üìñ Infinity-MM: Scaling Multimodal Performance with Large-Scale...\n         ‚úì Full abstract: 109 words\n      üìñ Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of E...\n         ‚úì Full abstract: 212 words\n      üìñ Are LLMs Better than Reported? Detecting Label Errors and Mi...\n         ‚úì Full abstract: 218 words\n      üìñ Counting Ability of Large Language Models and Impact of Toke...\n         ‚úì Full abstract: 233 words\n      üìñ Hybrid Preferences: Learning to Route Instances for Human vs...\n         ‚úì Full abstract: 283 words\n      Progress: 10/16 papers processed\n      üìñ Fictitious Synthetic Data Can Improve LLM Factuality via Pre...\n         ‚úì Full abstract: 157 words\n      üìñ Analysing the Residual Stream of Language Models Under Knowl...\n         ‚úì Full abstract: 204 words\n      üìñ Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics...\n         ‚úì Full abstract: 211 words\n      üìñ Reflection-Bench: probing AI intelligence with reflection...\n         ‚úì Full abstract: 161 words\n      üìñ Mapping the Media Landscape: Predicting Factual Reporting an...\n         ‚úì Full abstract: 180 words\n      Progress: 15/16 papers processed\n      üìñ Leveraging Skills from Unlabeled Prior Data for Efficient On...\n         ‚úì Full abstract: 189 words\n‚úì 2024-10-28: 16 papers\n      üìñ GPT-4o System Card...\n         ‚úì Full abstract: 217 words\n      üìñ Bielik 7B v0.1: A Polish Language Model -- Development, Insi...\n         ‚úì Full abstract: 146 words\n      üìñ A Survey of Small Language Models...\n         ‚úì Full abstract: 133 words\n      üìñ AgentStore: Scalable Integration of Heterogeneous Agents As ...\n         ‚úì Full abstract: 195 words\n      üìñ Document Parsing Unveiled: Techniques, Challenges, and Prosp...\n         ‚úì Full abstract: 155 words\n      Progress: 5/21 papers processed\n      üìñ MarDini: Masked Autoregressive Diffusion for Video Generatio...\n         ‚úì Full abstract: 175 words\n      üìñ LongReward: Improving Long-context Large Language Models wit...\n         ‚úì Full abstract: 163 words\n      üìñ COAT: Compressing Optimizer states and Activation for Memory...\n         ‚úì Full abstract: 210 words\n      üìñ DreamClear: High-Capacity Real-World Image Restoration with ...\n         ‚úì Full abstract: 230 words\n      üìñ GrounDiT: Grounding Diffusion Transformers via Noisy Patch\n ...\n         ‚úì Full abstract: 209 words\n      Progress: 10/21 papers processed\n      üìñ Vision Search Assistant: Empower Vision-Language Models as M...\n         ‚úì Full abstract: 190 words\n      üìñ Fast Best-of-N Decoding via Speculative Rejection...\n         ‚úì Full abstract: 162 words\n      üìñ LARP: Tokenizing Videos with a Learned Autoregressive Genera...\n         ‚úì Full abstract: 237 words\n      üìñ EoRA: Training-free Compensation for Compressed LLM with Eig...\n         ‚úì Full abstract: 215 words\n      üìñ Relaxed Recursive Transformers: Effective Parameter Sharing ...\n         ‚úì Full abstract: 223 words\n      Progress: 15/21 papers processed\n      üìñ VideoWebArena: Evaluating Long Context Multimodal Agents wit...\n         ‚úì Full abstract: 228 words\n      üìñ Neural Fields in Robotics: A Survey...\n         ‚úì Full abstract: 209 words\n      üìñ Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sen...\n         ‚úì Full abstract: 198 words\n      üìñ Language Models And A Second Opinion Use Case: The Pocket Pr...\n         ‚úì Full abstract: 258 words\n      üìñ Leveraging Locality to Boost Sample Efficiency in Robotic Ma...\n         ‚úì Full abstract: 164 words\n      Progress: 20/21 papers processed\n      üìñ Bi-Level Motion Imitation for Humanoid Robots...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2410.01968\n         ‚ö†Ô∏è Detail page failed, using preview\n‚úì 2024-10-29: 20 papers\n   ‚ùå Request error for 2024-10-30: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-10-30\n‚óã 2024-10-30: no papers\n   ‚ùå Request error for 2024-10-31: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-10-31\n‚óã 2024-10-31: no papers\n   ‚ùå Request error for 2024-11-01: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-01\n‚óã 2024-11-01: no papers\n   ‚ùå Request error for 2024-11-02: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-01\n‚óã 2024-11-02: no papers\n   ‚ùå Request error for 2024-11-03: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-03\n‚óã 2024-11-03: no papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 20 days, 250 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n   ‚ùå Request error for 2024-11-04: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-04\n‚óã 2024-11-04: no papers\n   ‚ùå Request error for 2024-11-05: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-05\n‚óã 2024-11-05: no papers\n   ‚ùå Request error for 2024-11-06: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-06\n‚óã 2024-11-06: no papers\n   ‚ùå Request error for 2024-11-07: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-07\n‚óã 2024-11-07: no papers\n   ‚ùå Request error for 2024-11-08: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-08\n‚óã 2024-11-08: no papers\n      üìñ OpenCoder: The Open Cookbook for Top-Tier Code Large Languag...\n         ‚úì Full abstract: 237 words\n      üìñ BitNet a4.8: 4-bit Activations for 1-bit LLMs...\n         ‚úì Full abstract: 136 words\n      üìñ DimensionX: Create Any 3D and 4D Scenes from a Single Image ...\n         ‚úì Full abstract: 201 words\n      üìñ Mixture-of-Transformers: A Sparse and Scalable Architecture ...\n         ‚úì Full abstract: 231 words\n      üìñ M3DocRAG: Multi-modal Retrieval is What You Need for Multi-p...\n         ‚úì Full abstract: 262 words\n      Progress: 5/16 papers processed\n      üìñ Analyzing The Language of Visual Tokens...\n         ‚úì Full abstract: 207 words\n      üìñ VideoGLaMM: A Large Multimodal Model for Pixel-Level Visual ...\n         ‚úì Full abstract: 184 words\n      üìñ Thanos: Enhancing Conversational Agents with Skill-of-Mind-I...\n         ‚úì Full abstract: 179 words\n      üìñ SVDQunat: Absorbing Outliers by Low-Rank Components for 4-Bi...\n         ‚úì Full abstract: 277 words\n      üìñ Needle Threading: Can LLMs Follow Threads through Near-Milli...\n         ‚úì Full abstract: 207 words\n      Progress: 10/16 papers processed\n      üìñ DynaMem: Online Dynamic Spatio-Semantic Memory for Open Worl...\n         ‚úì Full abstract: 204 words\n      üìñ RetrieveGPT: Merging Prompts and Mathematical Models for Enh...\n         ‚úì Full abstract: 186 words\n      üìñ M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmar...\n         ‚úì Full abstract: 159 words\n      üìñ SG-I2V: Self-Guided Trajectory Control in Image-to-Video Gen...\n         ‚úì Full abstract: 141 words\n      üìñ GazeGen: Gaze-Driven User Interaction for Visual Content Gen...\n         ‚úì Full abstract: 289 words\n      Progress: 15/16 papers processed\n      üìñ Diff-2-in-1: Bridging Generation and Dense Perception with D...\n         ‚úì Full abstract: 159 words\n‚úì 2024-11-09: 16 papers\n      üìñ StdGEN: Semantic-Decomposed 3D Character Generation from Sin...\n         ‚úì Full abstract: 186 words\n‚úì 2024-11-10: 1 papers\n      üìñ LLM2CLIP: Powerful Language Model Unlock Richer Visual Repre...\n         ‚úì Full abstract: 265 words\n      üìñ Language Models are Hidden Reasoners: Unlocking Latent Reaso...\n         ‚úì Full abstract: 162 words\n      üìñ Balancing Pipeline Parallelism with Vocabulary Parallelism...\n         ‚úì Full abstract: 199 words\n      üìñ DELIFT: Data Efficient Language model Instruction Fine Tunin...\n         ‚úì Full abstract: 190 words\n      üìñ CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation ...\n         ‚úì Full abstract: 221 words\n      Progress: 5/10 papers processed\n      üìñ Parameter-Efficient Fine-Tuning of Large Language Models for...\n         ‚úì Full abstract: 211 words\n      üìñ The Semantic Hub Hypothesis: Language Models Share Semantic\n...\n         ‚úì Full abstract: 193 words\n      üìñ Golden Touchstone: A Comprehensive Bilingual Benchmark for E...\n         ‚úì Full abstract: 233 words\n      üìñ RaVL: Discovering and Mitigating Spurious Correlations in Fi...\n         ‚úì Full abstract: 191 words\n      üìñ Improving the detection of technical debt in Java source cod...\n         ‚úì Full abstract: 278 words\n      Progress: 10/10 papers processed\n‚úì 2024-11-11: 10 papers\n      üìñ Add-it: Training-Free Object Insertion in Images With Pretra...\n         ‚úì Full abstract: 155 words\n      üìñ OmniEdit: Building Image Editing Generalist Models Through S...\n         ‚úì Full abstract: 259 words\n      üìñ M-Longdoc: A Benchmark For Multimodal Super-Long Document Un...\n         ‚úì Full abstract: 200 words\n      üìñ Chinese SimpleQA: A Chinese Factuality Evaluation for Large ...\n         ‚úì Full abstract: 164 words\n      üìñ Edify Image: High-Quality Image Generation with Pixel Space ...\n         ‚úì Full abstract: 71 words\n      Progress: 5/15 papers processed\n      üìñ Watermark Anything with Localized Messages...\n         ‚úì Full abstract: 175 words\n      üìñ IOPO: Empowering LLMs with Complex Instruction Following via...\n         ‚úì Full abstract: 164 words\n      üìñ GitChameleon: Unmasking the Version-Switching Capabilities o...\n         ‚úì Full abstract: 213 words\n      üìñ Autoregressive Models in Vision: A Survey...\n         ‚úì Full abstract: 238 words\n      üìñ Game-theoretic LLM: Agent Workflow for Negotiation Games...\n         ‚úì Full abstract: 238 words\n      Progress: 10/15 papers processed\n      üìñ Counterfactual Generation from Language Models...\n         ‚úì Full abstract: 194 words\n      üìñ KMM: Key Frame Mask Mamba for Extended Motion Generation...\n         ‚úì Full abstract: 203 words\n      üìñ Ablation is Not Enough to Emulate DPO: How Neuron Dynamics D...\n         ‚úì Full abstract: 160 words\n      üìñ Energy Efficient Protein Language Models: Leveraging Small L...\n         ‚úì Full abstract: 278 words\n      üìñ NeKo: Toward Post Recognition Generative Correction Large La...\n         ‚úì Full abstract: 178 words\n      Progress: 15/15 papers processed\n‚úì 2024-11-12: 15 papers\n      üìñ Stronger Models are NOT Stronger Teachers for Instruction Tu...\n         ‚úì Full abstract: 179 words\n      üìñ JanusFlow: Harmonizing Autoregression and Rectified Flow for...\n         ‚úì Full abstract: 130 words\n      üìñ SAMPart3D: Segment Any Part in 3D Objects...\n         ‚úì Full abstract: 246 words\n      üìñ BLIP3-KALE: Knowledge Augmented Large-Scale Dense Captions...\n         ‚úì Full abstract: 100 words\n      üìñ Scaling Properties of Diffusion Models for Perceptual Tasks...\n         ‚úì Full abstract: 103 words\n      Progress: 5/8 papers processed\n      üìñ Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Genera...\n         ‚úì Full abstract: 198 words\n      üìñ Acoustic Volume Rendering for Neural Impulse Response Fields...\n         ‚úì Full abstract: 180 words\n      üìñ Hardware and Software Platform Inference...\n         ‚úì Full abstract: 265 words\n‚úì 2024-11-13: 8 papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 30 days, 300 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n      üìñ Large Language Models Can Self-Improve in Long-context Reaso...\n         ‚úì Full abstract: 169 words\n      üìñ EgoVid-5M: A Large-Scale Video-Action Dataset for Egocentric...\n         ‚úì Full abstract: 200 words\n      üìñ Direct Preference Optimization Using Sparse Feature-Level Co...\n         ‚úì Full abstract: 143 words\n      üìñ CamemBERT 2.0: A Smarter French Language Model Aged to Perfe...\n         ‚úì Full abstract: 226 words\n      üìñ Can sparse autoencoders be used to decompose and interpret s...\n         ‚úì Full abstract: 112 words\n      Progress: 5/7 papers processed\n      üìñ PerceiverS: A Multi-Scale Perceiver with Effective Segmentat...\n         ‚úì Full abstract: 125 words\n      üìñ Motion Control for Enhanced Complex Action Video Generation...\n         ‚úì Full abstract: 190 words\n‚úì 2024-11-14: 7 papers\n      üìñ MagicQuill: An Intelligent Interactive Image Editing System...\n         ‚úì Full abstract: 127 words\n      üìñ LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models...\n         ‚úì Full abstract: 194 words\n      üìñ Cut Your Losses in Large-Vocabulary Language Models...\n         ‚úì Full abstract: 235 words\n      üìñ ClinicalBench: Can LLMs Beat Traditional ML Models in Clinic...\n         ‚úì Full abstract: 184 words\n      üìñ Inconsistencies In Consistency Models: Better ODE Solving Do...\n         ‚úì Full abstract: 162 words\n      Progress: 5/7 papers processed\n      üìñ Sharingan: Extract User Action Sequence from Desktop Recordi...\n         ‚úì Full abstract: 181 words\n      üìñ Hermes: A Large Language Model Framework on the Journey to A...\n         ‚úì Full abstract: 166 words\n‚úì 2024-11-15: 7 papers\n      üìñ MagicQuill: An Intelligent Interactive Image Editing System...\n         ‚úì Full abstract: 127 words\n      üìñ LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models...\n         ‚úì Full abstract: 194 words\n      üìñ Cut Your Losses in Large-Vocabulary Language Models...\n         ‚úì Full abstract: 235 words\n      üìñ ClinicalBench: Can LLMs Beat Traditional ML Models in Clinic...\n         ‚úì Full abstract: 184 words\n      üìñ Inconsistencies In Consistency Models: Better ODE Solving Do...\n         ‚úì Full abstract: 162 words\n      Progress: 5/7 papers processed\n      üìñ Sharingan: Extract User Action Sequence from Desktop Recordi...\n         ‚úì Full abstract: 181 words\n      üìñ Hermes: A Large Language Model Framework on the Journey to A...\n         ‚úì Full abstract: 166 words\n‚úì 2024-11-16: 7 papers\n      üìñ LLaVA-o1: Let Vision Language Models Reason Step-by-Step...\n         ‚úì Full abstract: 179 words\n      üìñ GaussianAnything: Interactive Point Cloud Latent Diffusion f...\n         ‚úì Full abstract: 139 words\n‚úì 2024-11-17: 2 papers\n      üìñ Region-Aware Text-to-Image Generation via Hard Binding and S...\n         ‚úì Full abstract: 194 words\n      üìñ The Dawn of GUI Agent: A Preliminary Case Study with Claude ...\n         ‚úì Full abstract: 172 words\n      üìñ Number it: Temporal Grounding Videos like Flipping Manga...\n         ‚úì Full abstract: 170 words\n      üìñ Xmodel-1.5: An 1B-scale Multilingual LLM...\n         ‚úì Full abstract: 120 words\n      üìñ MARS: Unleashing the Power of Variance Reduction for Trainin...\n         ‚úì Full abstract: 173 words\n      Progress: 5/5 papers processed\n‚úì 2024-11-18: 5 papers\n      üìñ Generative World Explorer...\n         ‚úì Full abstract: 196 words\n      üìñ BlueLM-V-3B: Algorithm and System Co-Design for Multimodal L...\n         ‚úì Full abstract: 212 words\n      üìñ AnimateAnything: Consistent and Controllable Animation for V...\n         ‚úì Full abstract: 121 words\n      üìñ Search, Verify and Feedback: Towards Next Generation Post-tr...\n         ‚úì Full abstract: 137 words\n      üìñ Top-nœÉ: Not All Logits Are You Need...\n         ‚úì Full abstract: 141 words\n      Progress: 5/16 papers processed\n      üìñ Drowning in Documents: Consequences of Scaling Reranker Infe...\n         ‚úì Full abstract: 108 words\n      üìñ FitDiT: Advancing the Authentic Garment Details for High-fid...\n         ‚úì Full abstract: 204 words\n      üìñ SlimLM: An Efficient Small Language Model for On-Device Docu...\n         ‚úì Full abstract: 166 words\n      üìñ StableV2V: Stablizing Shape Consistency in Video-to-Video Ed...\n         ‚úì Full abstract: 175 words\n      üìñ Awaker2.5-VL: Stably Scaling MLLMs with Parameter-Efficient ...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2411.10669\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Adaptive Decoding via Latent Preference Optimization...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2411.09661\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ LL√§Mmlein: Compact and Competitive German-Only Language Mode...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2411.11171\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ SmoothCache: A Universal Inference Acceleration Technique fo...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2411.10510\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ VeGaS: Video Gaussian Splatting...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2411.11024\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Comprehensive and Practical Evaluation of Retrieval-Augmente...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2411.09213\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Evaluating the role of `Constitutions' for learning from AI ...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2411.10168\n         ‚ö†Ô∏è Detail page failed, using preview\n‚úì 2024-11-19: 9 papers\n   ‚ùå Request error for 2024-11-20: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-20\n‚óã 2024-11-20: no papers\n   ‚ùå Request error for 2024-11-21: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-21\n‚óã 2024-11-21: no papers\n   ‚ùå Request error for 2024-11-22: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-22\n‚óã 2024-11-22: no papers\n   ‚ùå Request error for 2024-11-23: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-11-23\n‚óã 2024-11-23: no papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 40 days, 337 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n      üìñ Style-Friendly SNR Sampler for Style-Driven Generation...\n         ‚úì Full abstract: 144 words\n‚úì 2024-11-24: 1 papers\n      üìñ T√úLU 3: Pushing Frontiers in Open Language Model Post-Traini...\n         ‚úì Full abstract: 244 words\n      üìñ OminiControl: Minimal and Universal Control for Diffusion Tr...\n         ‚úì Full abstract: 196 words\n      üìñ Material Anything: Generating Materials for Any 3D Object vi...\n         ‚úì Full abstract: 136 words\n      üìñ Large-Scale Text-to-Image Model with Inpainting is a Zero-Sh...\n         ‚úì Full abstract: 194 words\n      üìñ MyTimeMachine: Personalized Facial Age Transformation...\n         ‚úì Full abstract: 214 words\n      Progress: 5/16 papers processed\n      üìñ A Flexible Large Language Models Guardrail Development Metho...\n         ‚úì Full abstract: 171 words\n      üìñ Large Multi-modal Models Can Interpret Features in Large Mul...\n         ‚úì Full abstract: 172 words\n      üìñ BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games...\n         ‚úì Full abstract: 206 words\n      üìñ VideoEspresso: A Large-Scale Chain-of-Thought Dataset for Fi...\n         ‚úì Full abstract: 205 words\n      üìñ Efficient Long Video Tokenization via Coordinated-based Patc...\n         ‚úì Full abstract: 203 words\n      Progress: 10/16 papers processed\n      üìñ Novel View Extrapolation with Video Diffusion Priors...\n         ‚úì Full abstract: 165 words\n      üìñ VideoRepair: Improving Text-to-Video Generation via Misalign...\n         ‚úì Full abstract: 190 words\n      üìñ WildLMa: Long Horizon Loco-Manipulation in the Wild...\n         ‚úì Full abstract: 191 words\n      üìñ The Impossible Test: A 2024 Unsolvable Dataset and A Chance ...\n         ‚úì Full abstract: 238 words\n      üìñ Adapting Vision Foundation Models for Robust Cloud Segmentat...\n         ‚úì Full abstract: 191 words\n      Progress: 15/16 papers processed\n      üìñ One to rule them all: natural language to bind communication...\n         ‚úì Full abstract: 268 words\n‚úì 2024-11-25: 16 papers\n      üìñ Star Attention: Efficient LLM Inference over Long Sequences...\n         ‚úì Full abstract: 109 words\n      üìñ O1 Replication Journey -- Part 2: Surpassing O1-preview thro...\n         ‚úì Full abstract: 251 words\n      üìñ From Generation to Judgment: Opportunities and Challenges of...\n         ‚úì Full abstract: 167 words\n      üìñ GMAI-VL & GMAI-VL-5.5M: A Large Vision-Language Model and A\n...\n         ‚úì Full abstract: 178 words\n      üìñ Reflections from the 2024 Large Language Model (LLM) Hackath...\n         ‚úì Full abstract: 214 words\n      Progress: 5/24 papers processed\n      üìñ One Diffusion to Generate Them All...\n         ‚úì Full abstract: 178 words\n      üìñ MH-MoE:Multi-Head Mixture-of-Experts...\n         ‚úì Full abstract: 88 words\n      üìñ Interactive Medical Image Segmentation: A Benchmark Dataset ...\n         ‚úì Full abstract: 201 words\n      üìñ SegBook: A Simple Baseline and Cookbook for Volumetric Medic...\n         ‚úì Full abstract: 239 words\n      üìñ DreamRunner: Fine-Grained Storytelling Video Generation with...\n         ‚úì Full abstract: 229 words\n      Progress: 10/24 papers processed\n      üìñ Cautious Optimizers: Improving Training with One Line of Cod...\n         ‚úì Full abstract: 115 words\n      üìñ Factorized Visual Tokenization and Generation...\n         ‚úì Full abstract: 200 words\n      üìñ VisualLens: Personalization through Visual History...\n         ‚úì Full abstract: 154 words\n      üìñ TEXGen: a Generative Diffusion Model for Mesh Textures...\n         ‚úì Full abstract: 163 words\n      üìñ Knowledge Transfer Across Modalities with Natural Language S...\n         ‚úì Full abstract: 179 words\n      Progress: 15/24 papers processed\n      üìñ From CISC to RISC: language-model guided assembly transpilat...\n         ‚úì Full abstract: 187 words\n      üìñ All Languages Matter: Evaluating LMMs on Culturally Diverse ...\n         ‚úì Full abstract: 234 words\n      üìñ SplatFlow: Multi-View Rectified Flow Model for 3D Gaussian S...\n         ‚úì Full abstract: 198 words\n      üìñ LLMs Do Not Think Step-by-step In Implicit Reasoning...\n         ‚úì Full abstract: 151 words\n      üìñ Predicting Emergent Capabilities by Finetuning...\n         ‚úì Full abstract: 220 words\n      Progress: 20/24 papers processed\n      üìñ Best of Both Worlds: Advantages of Hybrid Graph Sequence Mod...\n         ‚úì Full abstract: 271 words\n      üìñ DreamMix: Decoupling Object Attributes for Enhanced Editabil...\n         ‚úì Full abstract: 153 words\n      üìñ Find Any Part in 3D...\n         ‚úì Full abstract: 156 words\n      üìñ Edge Weight Prediction For Category-Agnostic Pose Estimation...\n         ‚úì Full abstract: 164 words\n‚úì 2024-11-26: 24 papers\n      üìñ ShowUI: One Vision-Language-Action Model for GUI Visual Agen...\n         ‚úì Full abstract: 226 words\n      üìñ ROICtrl: Boosting Instance Control for Visual Generation...\n         ‚úì Full abstract: 194 words\n      üìñ Identity-Preserving Text-to-Video Generation by Frequency De...\n         ‚úì Full abstract: 249 words\n      üìñ Pathways on the Image Manifold: Image Editing via Video Gene...\n         ‚úì Full abstract: 138 words\n      üìñ MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelit...\n         ‚úì Full abstract: 175 words\n      Progress: 5/20 papers processed\n      üìñ Interleaved Scene Graph for Interleaved Text-and-Image Gener...\n         ‚úì Full abstract: 228 words\n      üìñ MME-Survey: A Comprehensive Survey on Evaluation of Multimod...\n         ‚úì Full abstract: 206 words\n      üìñ Rethinking Token Reduction in MLLMs: Towards a Unified Parad...\n         ‚úì Full abstract: 155 words\n      üìñ SketchAgent: Language-Driven Sequential Sketch Generation...\n         ‚úì Full abstract: 175 words\n      üìñ Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws ...\n         ‚úì Full abstract: 226 words\n      Progress: 10/20 papers processed\n      üìñ SAR3D: Autoregressive 3D Object Generation and Understanding...\n         ‚úì Full abstract: 160 words\n      üìñ VLRewardBench: A Challenging Benchmark for Vision-Language G...\n         ‚úì Full abstract: 211 words\n      üìñ SALOVA: Segment-Augmented Long Video Assistant for Targeted ...\n         ‚úì Full abstract: 211 words\n      üìñ Learning 3D Representations from Procedural 3D Programs...\n         ‚úì Full abstract: 131 words\n      üìñ FINECAPTION: Compositional Image Captioning Focusing on Wher...\n         ‚úì Full abstract: 200 words\n      Progress: 15/20 papers processed\n      üìñ AnchorCrafter: Animate CyberAnchors Saling Your Products via...\n         ‚úì Full abstract: 175 words\n      üìñ EfficientViM: Efficient Vision Mamba with Hidden State Mixer...\n         ‚úì Full abstract: 199 words\n      üìñ MolReFlect: Towards In-Context Fine-grained Alignments betwe...\n         ‚úì Full abstract: 247 words\n      üìñ Controllable Human Image Generation with Personalized Multi-...\n         ‚úì Full abstract: 196 words\n      üìñ Visual Counter Turing Test (VCT^2): Discovering the Challeng...\n         ‚úì Full abstract: 242 words\n      Progress: 20/20 papers processed\n‚úì 2024-11-27: 20 papers\n      üìñ CAT4D: Create Anything in 4D with Multi-View Video Diffusion...\n         ‚úì Full abstract: 108 words\n      üìñ Large Language Model-Brained GUI Agents: A Survey...\n         ‚úì Full abstract: 271 words\n      üìñ Diffusion Self-Distillation for Zero-Shot Customized Image G...\n         ‚úì Full abstract: 163 words\n      üìñ 3D Convex Splatting: Radiance Field Rendering with 3D Smooth...\n         ‚úì Full abstract: 219 words\n      üìñ DiffusionDrive: Truncated Diffusion Model for End-to-End Aut...\n         ‚úì Full abstract: 204 words\n      Progress: 5/19 papers processed\n      üìñ Make-It-Animatable: An Efficient Framework for Authoring Ani...\n         ‚úì Full abstract: 184 words\n      üìñ UniPose: A Unified Multimodal Framework for Human Pose Compr...\n         ‚úì Full abstract: 177 words\n      üìñ Collaborative Decoding Makes Visual Auto-Regressive Modeling...\n         ‚úì Full abstract: 230 words\n      üìñ DreamCache: Finetuning-Free Lightweight Personalized Image G...\n         ‚úì Full abstract: 125 words\n      üìñ ChatRex: Taming Multimodal LLM for Joint Perception and Unde...\n         ‚úì Full abstract: 204 words\n      Progress: 10/19 papers processed\n      üìñ Video-Guided Foley Sound Generation with Multimodal Controls...\n         ‚úì Full abstract: 163 words\n      üìñ Omegance: A Single Parameter for Various Granularities in\n  ...\n         ‚úì Full abstract: 153 words\n      üìñ Draft Model Knows When to Stop: A Self-Verification Length P...\n         ‚úì Full abstract: 164 words\n      üìñ VideoLLM Knows When to Speak: Enhancing Time-Sensitive Video...\n         ‚úì Full abstract: 264 words\n      üìñ Optimizing Brain Tumor Segmentation with MedNeXt: BraTS 2024...\n         ‚úì Full abstract: 214 words\n      Progress: 15/19 papers processed\n      üìñ Adaptive Blind All-in-One Image Restoration...\n         ‚úì Full abstract: 208 words\n      üìñ Training and Evaluating Language Models with Template-based ...\n         ‚úì Full abstract: 214 words\n      üìñ Edit Away and My Face Will not Stay: Personal Biometric Defe...\n         ‚úì Full abstract: 169 words\n      üìñ Morph: A Motion-free Physics Optimization Framework for Huma...\n         ‚úì Full abstract: 159 words\n‚úì 2024-11-28: 19 papers\n      üìñ Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Re...\n         ‚úì Full abstract: 254 words\n      üìñ TryOffDiff: Virtual-Try-Off via High-Fidelity Garment Recons...\n         ‚úì Full abstract: 164 words\n      üìñ ChatGen: Automatic Text-to-Image Generation From FreeStyle C...\n         ‚úì Full abstract: 176 words\n      üìñ SelfSplat: Pose-Free and 3D Prior-Free Generalizable 3D Gaus...\n         ‚úì Full abstract: 179 words\n      üìñ Free^2Guide: Gradient-Free Path Integral Control for Enhanci...\n         ‚úì Full abstract: 154 words\n      Progress: 5/7 papers processed\n      üìñ LongKey: Keyphrase Extraction for Long Documents...\n         ‚úì Full abstract: 130 words\n      üìñ AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question...\n         ‚úì Full abstract: 180 words\n‚úì 2024-11-29: 7 papers\n      üìñ Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Re...\n         ‚úì Full abstract: 254 words\n      üìñ TryOffDiff: Virtual-Try-Off via High-Fidelity Garment Recons...\n         ‚úì Full abstract: 164 words\n      üìñ ChatGen: Automatic Text-to-Image Generation From FreeStyle C...\n         ‚úì Full abstract: 176 words\n      üìñ SelfSplat: Pose-Free and 3D Prior-Free Generalizable 3D Gaus...\n         ‚úì Full abstract: 179 words\n      üìñ Free^2Guide: Gradient-Free Path Integral Control for Enhanci...\n         ‚úì Full abstract: 154 words\n      Progress: 5/7 papers processed\n      üìñ LongKey: Keyphrase Extraction for Long Documents...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2411.17863\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2411.15640\n         ‚ö†Ô∏è Detail page failed, using preview\n‚úì 2024-11-30: 5 papers\n   ‚ùå Request error for 2024-12-01: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-01\n‚óã 2024-12-01: no papers\n   ‚ùå Request error for 2024-12-02: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-02\n‚óã 2024-12-02: no papers\n      üìñ X-Prompt: Towards Universal In-Context Image Generation in\n ...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.01824\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ FLOAT: Generative Motion Latent Flow Matching for Audio-driv...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.01064\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ o1-Coder: an o1 Replication for Coding...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.00154\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Switti: Designing Scale-Wise Transformers for Text-to-Image ...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.01819\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Open-Sora Plan: Open-Source Large Video Generation Model...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.00131\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ VISTA: Enhancing Long-Duration and High-Resolution Video Und...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.00927\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ SOLAMI: Social Vision-Language-Action Modeling for Immersive...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.00174\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ The Well: a Large-Scale Collection of Diverse Physics Simula...\n         ‚úì Full abstract: 171 words\n      üìñ TAPTRv3: Spatial and Temporal Context Foster Robust Tracking...\n         ‚úì Full abstract: 198 words\n      üìñ GATE OpenING: A Comprehensive Benchmark for Judging Open-end...\n         ‚úì Full abstract: 178 words\n      Progress: 10/29 papers processed\n      üìñ Efficient Track Anything...\n         ‚úì Full abstract: 281 words\n      üìñ Steering Rectified Flow Models in the Vector Field for Contr...\n         ‚úì Full abstract: 190 words\n      üìñ VLsI: Verbalized Layers-to-Interactions from Large to Small ...\n         ‚úì Full abstract: 179 words\n      üìñ TinyFusion: Diffusion Transformers Learned Shallow...\n         ‚úì Full abstract: 194 words\n      üìñ INCLUDE: Evaluating Multilingual Language Understanding with...\n         ‚úì Full abstract: 146 words\n      Progress: 15/29 papers processed\n      üìñ WF-VAE: Enhancing Video VAE by Wavelet-Driven Energy Flow fo...\n         ‚úì Full abstract: 191 words\n      üìñ VLSBench: Unveiling Visual Leakage in Multimodal Safety...\n         ‚úì Full abstract: 204 words\n      üìñ Long Video Diffusion Generation with Segmented Cross-Attenti...\n         ‚úì Full abstract: 157 words\n      üìñ Art-Free Generative Models: Art Creation Without Graphic Art...\n         ‚úì Full abstract: 102 words\n      üìñ VisOnlyQA: Large Vision Language Models Still Struggle with ...\n         ‚úì Full abstract: 229 words\n      Progress: 20/29 papers processed\n      üìñ PhysGame: Uncovering Physical Commonsense Violations in Game...\n         ‚úì Full abstract: 230 words\n      üìñ A Simple and Provable Scaling Law for the Test-Time Compute ...\n         ‚úì Full abstract: 217 words\n      üìñ Collaborative Instance Navigation: Leveraging Agent Self-Dia...\n         ‚úì Full abstract: 192 words\n      üìñ AMO Sampler: Enhancing Text Rendering with Overshooting...\n         ‚úì Full abstract: 191 words\n      üìñ World-consistent Video Diffusion with Explicit 3D Modeling...\n         ‚úì Full abstract: 158 words\n      Progress: 25/29 papers processed\n      üìñ Exploring the Abilities of Large Language Models to Solve Pr...\n         ‚úì Full abstract: 164 words\n      üìñ HUGSIM: A Real-Time, Photo-Realistic and Closed-Loop Simulat...\n         ‚úì Full abstract: 200 words\n      üìñ Towards Cross-Lingual Audio Abuse Detection in Low-Resource ...\n         ‚úì Full abstract: 132 words\n      üìñ Improving speaker verification robustness with synthetic emo...\n         ‚úì Full abstract: 192 words\n‚úì 2024-12-03: 22 papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 50 days, 451 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n      üìñ Critical Tokens Matter: Token-Level Contrastive Estimation E...\n         ‚úì Full abstract: 240 words\n      üìñ VideoGen-of-Thought: A Collaborative Framework for Multi-Sho...\n         ‚úì Full abstract: 252 words\n      üìñ MALT: Improving Reasoning with Multi-Agent LLM Training...\n         ‚úì Full abstract: 219 words\n      üìñ Free Process Rewards without Process Labels...\n         ‚úì Full abstract: 302 words\n      üìñ AIM: Adaptive Inference of Multi-Modal LLMs via Token Mergin...\n         ‚úì Full abstract: 204 words\n      Progress: 5/16 papers processed\n      üìñ AV-Odyssey Bench: Can Your Multimodal LLMs Really Understand...\n         ‚úì Full abstract: 186 words\n      üìñ OCR Hinders RAG: Evaluating the Cascading Impact of OCR on\n ...\n         ‚úì Full abstract: 219 words\n      üìñ Truth or Mirage? Towards End-to-End Factuality Evaluation wi...\n         ‚úì Full abstract: 224 words\n      üìñ Motion Prompting: Controlling Video Generation with Motion T...\n         ‚úì Full abstract: 196 words\n      üìñ OmniCreator: Self-Supervised Unified Generation with Univers...\n         ‚úì Full abstract: 197 words\n      Progress: 10/16 papers processed\n      üìñ LSceneLLM: Enhancing Large 3D Scene Understanding Using Adap...\n         ‚úì Full abstract: 227 words\n      üìñ Scaling Image Tokenizers with Grouped Spherical Quantization...\n         ‚úì Full abstract: 172 words\n      üìñ MaskRIS: Semantic Distortion-aware Data Augmentation for Ref...\n         ‚úì Full abstract: 184 words\n      üìñ Generating a Low-code Complete Workflow via Task Decompositi...\n         ‚úì Full abstract: 219 words\n      üìñ A dynamic parallel method for performance optimization on hy...\n         ‚úì Full abstract: 98 words\n      Progress: 15/16 papers processed\n      üìñ VideoLights: Feature Refinement and Cross-Task Alignment Tra...\n         ‚úì Full abstract: 177 words\n‚úì 2024-12-04: 16 papers\n      üìñ PaliGemma 2: A Family of Versatile VLMs for Transfer...\n         ‚úì Full abstract: 167 words\n      üìñ SNOOPI: Supercharged One-step Diffusion Distillation with Pr...\n         ‚úì Full abstract: 217 words\n      üìñ TokenFlow: Unified Image Tokenizer for Multimodal Understand...\n         ‚úì Full abstract: 181 words\n      üìñ Imagine360: Immersive 360 Video Generation from Perspective ...\n         ‚úì Full abstract: 199 words\n      üìñ Distilling Diffusion Models to Efficient 3D LiDAR Scene Comp...\n         ‚úì Full abstract: 168 words\n      Progress: 5/19 papers processed\n      üìñ One Shot, One Talk: Whole-body Talking Avatar from a Single ...\n         ‚úì Full abstract: 143 words\n      üìñ VideoICL: Confidence-based Iterative In-context Learning for...\n         ‚úì Full abstract: 210 words\n      üìñ VARCO-VISION: Expanding Frontiers in Korean Vision-Language ...\n         ‚úì Full abstract: 120 words\n      üìñ MIDI: Multi-Instance Diffusion for Single Image to 3D Scene ...\n         ‚úì Full abstract: 167 words\n      üìñ NVComposer: Boosting Generative Novel View Synthesis with Mu...\n         ‚úì Full abstract: 172 words\n      Progress: 10/19 papers processed\n      üìñ NitroFusion: High-Fidelity Single-Step Diffusion through Dyn...\n         ‚úì Full abstract: 189 words\n      üìñ U-MATH: A University-Level Benchmark for Evaluating Mathemat...\n         ‚úì Full abstract: 170 words\n      üìñ Video-3D LLM: Learning Position-Aware Video Representation f...\n         ‚úì Full abstract: 175 words\n      üìñ Surveying the Effects of Quality, Diversity, and Complexity ...\n         ‚úì Full abstract: 275 words\n      üìñ CleanDIFT: Diffusion Features without Noise...\n         ‚úì Full abstract: 151 words\n      Progress: 15/19 papers processed\n      üìñ Weighted-Reward Preference Optimization for Implicit Model F...\n         ‚úì Full abstract: 189 words\n      üìñ Mimir: Improving Video Diffusion Models for Precise Text Und...\n         ‚úì Full abstract: 190 words\n      üìñ Inst-IT: Boosting Multimodal Instance Understanding via Expl...\n         ‚úì Full abstract: 213 words\n      üìñ LumiNet: Latent Intrinsics Meets Diffusion Models for Indoor...\n         ‚úì Full abstract: 179 words\n‚úì 2024-12-05: 19 papers\n      üìñ VisionZip: Longer is Better but Not Necessary in Vision Lang...\n         ‚úì Full abstract: 198 words\n      üìñ Structured 3D Latents for Scalable and Versatile 3D Generati...\n         ‚úì Full abstract: 153 words\n      üìñ Aguvis: Unified Pure Vision Agents for Autonomous GUI Intera...\n         ‚úì Full abstract: 206 words\n      üìñ Florence-VL: Enhancing Vision-Language Models with Generativ...\n         ‚úì Full abstract: 222 words\n      üìñ NVILA: Efficient Frontier Visual Language Models...\n         ‚úì Full abstract: 161 words\n      Progress: 5/31 papers processed\n      üìñ Evaluating Language Models as Synthetic Data Generators...\n         ‚úì Full abstract: 180 words\n      üìñ Code-as-Monitor: Constraint-aware Visual Programming for Rea...\n         ‚úì Full abstract: 182 words\n      üìñ A Noise is Worth Diffusion Guidance...\n         ‚úì Full abstract: 162 words\n      üìñ MV-Adapter: Multi-view Consistent Image Generation Made Easy...\n         ‚úì Full abstract: 227 words\n      üìñ AnyDressing: Customizable Multi-Garment Virtual Dressing via...\n         ‚úì Full abstract: 232 words\n      Progress: 10/31 papers processed\n      üìñ Negative Token Merging: Image-based Adversarial Feature Guid...\n         ‚úì Full abstract: 207 words\n      üìñ Global MMLU: Understanding and Addressing Cultural and Lingu...\n         ‚úì Full abstract: 252 words\n      üìñ Densing Law of LLMs...\n         ‚úì Full abstract: 250 words\n      üìñ Infinity: Scaling Bitwise AutoRegressive Modeling for High-R...\n         ‚úì Full abstract: 165 words\n      üìñ HumanEdit: A High-Quality Human-Rewarded Dataset for Instruc...\n         ‚úì Full abstract: 199 words\n      Progress: 15/31 papers processed\n      üìñ Monet: Mixture of Monosemantic Experts for Transformers...\n         ‚úì Full abstract: 190 words\n      üìñ Personalized Multimodal Large Language Models: A Survey...\n         ‚úì Full abstract: 168 words\n      üìñ Towards Universal Soccer Video Understanding...\n         ‚úì Full abstract: 147 words\n      üìñ OmniFlow: Any-to-Any Generation with Multi-Modal Rectified F...\n         ‚úì Full abstract: 171 words\n      üìñ Discriminative Fine-tuning of LVLMs...\n         ‚úì Full abstract: 199 words\n      Progress: 20/31 papers processed\n      üìñ Marco-LLM: Bridging Languages via Massive Multilingual Train...\n         ‚úì Full abstract: 194 words\n      üìñ MEMO: Memory-Guided Diffusion for Expressive Talking Video G...\n         ‚úì Full abstract: 172 words\n      üìñ ZipAR: Accelerating Autoregressive Image Generation through ...\n         ‚úì Full abstract: 139 words\n      üìñ KV Shifting Attention Enhances Language Modeling...\n         ‚úì Full abstract: 131 words\n      üìñ 4Real-Video: Learning Generalizable Photo-Realistic 4D Video...\n         ‚úì Full abstract: 134 words\n      Progress: 25/31 papers processed\n      üìñ p-MoD: Building Mixture-of-Depths MLLMs via Progressive Rati...\n         ‚úì Full abstract: 214 words\n      üìñ Scaling Inference-Time Search with Vision Value Model for Im...\n         ‚úì Full abstract: 193 words\n      üìñ MRGen: Diffusion-based Controllable Data Engine for MRI Segm...\n         ‚úì Full abstract: 161 words\n      üìñ SynFinTabs: A Dataset of Synthetic Financial Tables for Info...\n         ‚úì Full abstract: 202 words\n      üìñ Challenges in Trustworthy Human Evaluation of Chatbots...\n         ‚úì Full abstract: 130 words\n      Progress: 30/31 papers processed\n      üìñ Establishing Task Scaling Laws via Compute-Efficient Model L...\n         ‚úì Full abstract: 211 words\n‚úì 2024-12-06: 31 papers\n      üìñ VisionZip: Longer is Better but Not Necessary in Vision Lang...\n         ‚úì Full abstract: 198 words\n      üìñ Structured 3D Latents for Scalable and Versatile 3D Generati...\n         ‚úì Full abstract: 153 words\n      üìñ Aguvis: Unified Pure Vision Agents for Autonomous GUI Intera...\n         ‚úì Full abstract: 206 words\n      üìñ Florence-VL: Enhancing Vision-Language Models with Generativ...\n         ‚úì Full abstract: 222 words\n      üìñ NVILA: Efficient Frontier Visual Language Models...\n         ‚úì Full abstract: 161 words\n      Progress: 5/31 papers processed\n      üìñ Evaluating Language Models as Synthetic Data Generators...\n         ‚úì Full abstract: 180 words\n      üìñ Code-as-Monitor: Constraint-aware Visual Programming for Rea...\n         ‚úì Full abstract: 182 words\n      üìñ A Noise is Worth Diffusion Guidance...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.03895\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ MV-Adapter: Multi-view Consistent Image Generation Made Easy...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.03632\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ AnyDressing: Customizable Multi-Garment Virtual Dressing via...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.04146\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Negative Token Merging: Image-based Adversarial Feature Guid...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.01339\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Global MMLU: Understanding and Addressing Cultural and Lingu...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.03304\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Densing Law of LLMs...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.04315\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Infinity: Scaling Bitwise AutoRegressive Modeling for High-R...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.04431\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ HumanEdit: A High-Quality Human-Rewarded Dataset for Instruc...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.04280\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Monet: Mixture of Monosemantic Experts for Transformers...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.04139\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Personalized Multimodal Large Language Models: A Survey...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.02142\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Towards Universal Soccer Video Understanding...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.01820\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ OmniFlow: Any-to-Any Generation with Multi-Modal Rectified F...\n         ‚úì Full abstract: 171 words\n      üìñ Discriminative Fine-tuning of LVLMs...\n         ‚úì Full abstract: 199 words\n      Progress: 20/31 papers processed\n      üìñ Marco-LLM: Bridging Languages via Massive Multilingual Train...\n         ‚úì Full abstract: 194 words\n      üìñ MEMO: Memory-Guided Diffusion for Expressive Talking Video G...\n         ‚úì Full abstract: 172 words\n      üìñ ZipAR: Accelerating Autoregressive Image Generation through ...\n         ‚úì Full abstract: 139 words\n      üìñ KV Shifting Attention Enhances Language Modeling...\n         ‚úì Full abstract: 131 words\n      üìñ 4Real-Video: Learning Generalizable Photo-Realistic 4D Video...\n         ‚úì Full abstract: 134 words\n      Progress: 25/31 papers processed\n      üìñ p-MoD: Building Mixture-of-Depths MLLMs via Progressive Rati...\n         ‚úì Full abstract: 214 words\n      üìñ Scaling Inference-Time Search with Vision Value Model for Im...\n         ‚úì Full abstract: 193 words\n      üìñ MRGen: Diffusion-based Controllable Data Engine for MRI Segm...\n         ‚úì Full abstract: 161 words\n      üìñ SynFinTabs: A Dataset of Synthetic Financial Tables for Info...\n         ‚úì Full abstract: 202 words\n      üìñ Challenges in Trustworthy Human Evaluation of Chatbots...\n         ‚úì Full abstract: 130 words\n      Progress: 30/31 papers processed\n      üìñ Establishing Task Scaling Laws via Compute-Efficient Model L...\n         ‚úì Full abstract: 211 words\n‚úì 2024-12-07: 20 papers\n      üìñ VisionZip: Longer is Better but Not Necessary in Vision Lang...\n         ‚úì Full abstract: 198 words\n      üìñ Structured 3D Latents for Scalable and Versatile 3D Generati...\n         ‚úì Full abstract: 153 words\n      üìñ Aguvis: Unified Pure Vision Agents for Autonomous GUI Intera...\n         ‚úì Full abstract: 206 words\n      üìñ Florence-VL: Enhancing Vision-Language Models with Generativ...\n         ‚úì Full abstract: 222 words\n      üìñ NVILA: Efficient Frontier Visual Language Models...\n         ‚úì Full abstract: 161 words\n      Progress: 5/31 papers processed\n      üìñ Evaluating Language Models as Synthetic Data Generators...\n         ‚úì Full abstract: 180 words\n      üìñ Code-as-Monitor: Constraint-aware Visual Programming for Rea...\n         ‚úì Full abstract: 182 words\n      üìñ A Noise is Worth Diffusion Guidance...\n         ‚úì Full abstract: 162 words\n      üìñ MV-Adapter: Multi-view Consistent Image Generation Made Easy...\n         ‚úì Full abstract: 227 words\n      üìñ AnyDressing: Customizable Multi-Garment Virtual Dressing via...\n         ‚úì Full abstract: 232 words\n      Progress: 10/31 papers processed\n      üìñ Negative Token Merging: Image-based Adversarial Feature Guid...\n         ‚úì Full abstract: 207 words\n      üìñ Global MMLU: Understanding and Addressing Cultural and Lingu...\n         ‚úì Full abstract: 252 words\n      üìñ Densing Law of LLMs...\n         ‚úì Full abstract: 250 words\n      üìñ Infinity: Scaling Bitwise AutoRegressive Modeling for High-R...\n         ‚úì Full abstract: 165 words\n      üìñ HumanEdit: A High-Quality Human-Rewarded Dataset for Instruc...\n         ‚úì Full abstract: 199 words\n      Progress: 15/31 papers processed\n      üìñ Monet: Mixture of Monosemantic Experts for Transformers...\n         ‚úì Full abstract: 190 words\n      üìñ Personalized Multimodal Large Language Models: A Survey...\n         ‚úì Full abstract: 168 words\n      üìñ Towards Universal Soccer Video Understanding...\n         ‚úì Full abstract: 147 words\n      üìñ OmniFlow: Any-to-Any Generation with Multi-Modal Rectified F...\n         ‚úì Full abstract: 171 words\n      üìñ Discriminative Fine-tuning of LVLMs...\n         ‚úì Full abstract: 199 words\n      Progress: 20/31 papers processed\n      üìñ Marco-LLM: Bridging Languages via Massive Multilingual Train...\n         ‚úì Full abstract: 194 words\n      üìñ MEMO: Memory-Guided Diffusion for Expressive Talking Video G...\n         ‚úì Full abstract: 172 words\n      üìñ ZipAR: Accelerating Autoregressive Image Generation through ...\n         ‚úì Full abstract: 139 words\n      üìñ KV Shifting Attention Enhances Language Modeling...\n         ‚úì Full abstract: 131 words\n      üìñ 4Real-Video: Learning Generalizable Photo-Realistic 4D Video...\n         ‚úì Full abstract: 134 words\n      Progress: 25/31 papers processed\n      üìñ p-MoD: Building Mixture-of-Depths MLLMs via Progressive Rati...\n         ‚úì Full abstract: 214 words\n      üìñ Scaling Inference-Time Search with Vision Value Model for Im...\n         ‚úì Full abstract: 193 words\n      üìñ MRGen: Diffusion-based Controllable Data Engine for MRI Segm...\n         ‚úì Full abstract: 161 words\n      üìñ SynFinTabs: A Dataset of Synthetic Financial Tables for Info...\n         ‚úì Full abstract: 202 words\n      üìñ Challenges in Trustworthy Human Evaluation of Chatbots...\n         ‚úì Full abstract: 130 words\n      Progress: 30/31 papers processed\n      üìñ Establishing Task Scaling Laws via Compute-Efficient Model L...\n         ‚úì Full abstract: 211 words\n‚úì 2024-12-08: 31 papers\n      üìñ Expanding Performance Boundaries of Open-Source Multimodal M...\n         ‚úì Full abstract: 175 words\n      üìñ EXAONE 3.5: Series of Large Language Models for Real-world U...\n         ‚úì Full abstract: 114 words\n      üìñ LiFT: Leveraging Human Feedback for Text-to-Video Model Alig...\n         ‚úì Full abstract: 176 words\n      üìñ MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction ...\n         ‚úì Full abstract: 165 words\n      üìñ SwiftEdit: Lightning Fast Text-Guided Image Editing via One-...\n         ‚úì Full abstract: 158 words\n      Progress: 5/16 papers processed\n      üìñ APOLLO: SGD-like Memory, AdamW-level Performance...\n         ‚úì Full abstract: 261 words\n      üìñ Moto: Latent Motion Token as the Bridging Language for Robot...\n         ‚úì Full abstract: 259 words\n      üìñ GenMAC: Compositional Text-to-Video Generation with Multi-Ag...\n         ‚úì Full abstract: 231 words\n      üìñ CompCap: Improving Multimodal Large Language Models with Com...\n         ‚úì Full abstract: 208 words\n      üìñ Momentum-GS: Momentum Gaussian Self-Distillation for High-Qu...\n         ‚úì Full abstract: 203 words\n      Progress: 10/16 papers processed\n      üìñ BigDocs: An Open and Permissively-Licensed Dataset for Train...\n         ‚úì Full abstract: 219 words\n      üìñ Mind the Time: Temporally-Controlled Multi-Event Video Gener...\n         ‚úì Full abstract: 182 words\n      üìñ PanoDreamer: 3D Panorama Synthesis from a Single Image...\n         ‚úì Full abstract: 112 words\n      üìñ 2DGS-Room: Seed-Guided 2D Gaussian Splatting with Geometric ...\n         ‚úì Full abstract: 144 words\n      üìñ DEMO: Reframing Dialogue Interaction with Fine-grained Eleme...\n         ‚úì Full abstract: 157 words\n      Progress: 15/16 papers processed\n      üìñ RL Zero: Zero-Shot Language to Behaviors without any Supervi...\n         ‚úì Full abstract: 249 words\n‚úì 2024-12-09: 16 papers\n      üìñ Training Large Language Models to Reason in a Continuous Lat...\n         ‚úì Full abstract: 239 words\n      üìñ ProcessBench: Identifying Process Errors in Mathematical Rea...\n         ‚úì Full abstract: 220 words\n      üìñ Unraveling the Complexity of Memory in RL Agents: an Approac...\n         ‚úì Full abstract: 178 words\n      üìñ Maya: An Instruction Finetuned Multilingual Multimodal Model...\n         ‚úì Full abstract: 144 words\n      üìñ Around the World in 80 Timesteps: A Generative Approach to G...\n         ‚úì Full abstract: 147 words\n      Progress: 5/16 papers processed\n      üìñ Exploring Multi-Grained Concept Annotations for Multimodal L...\n         ‚úì Full abstract: 187 words\n      üìñ Divot: Diffusion Powers Video Tokenizer for Comprehension an...\n         ‚úì Full abstract: 215 words\n      üìñ You See it, You Got it: Learning 3D Creation on Pose-Free Vi...\n         ‚úì Full abstract: 258 words\n      üìñ Gated Delta Networks: Improving Mamba2 with Delta Rule...\n         ‚úì Full abstract: 149 words\n      üìñ MotionShop: Zero-Shot Motion Transfer in Video Diffusion Mod...\n         ‚úì Full abstract: 150 words\n      Progress: 10/16 papers processed\n      üìñ MAtCha Gaussians: Atlas of Charts for High-Quality Geometry ...\n         ‚úì Full abstract: 199 words\n      üìñ Global and Dense Embeddings of Earth: Major TOM Floating in ...\n         ‚úì Full abstract: 142 words\n      üìñ CARP: Visuomotor Policy Learning via Coarse-to-Fine Autoregr...\n         ‚úì Full abstract: 188 words\n      üìñ Robust Multi-bit Text Watermark with LLM-based Paraphrasers...\n         ‚úì Full abstract: 144 words\n      üìñ If You Can't Use Them, Recycle Them: Optimizing Merging at S...\n         ‚úì Full abstract: 166 words\n      Progress: 15/16 papers processed\n      üìñ Turbo3D: Ultra-fast Text-to-3D Generation...\n         ‚úì Full abstract: 119 words\n‚úì 2024-12-10: 16 papers\n      üìñ STIV: Scalable Text and Image Conditioned Video Generation...\n         ‚úì Full abstract: 234 words\n      üìñ Evaluating and Aligning CodeLLMs on Human Preference...\n         ‚úì Full abstract: 222 words\n      üìñ DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models f...\n         ‚úì Full abstract: 178 words\n      üìñ ACDiT: Interpolating Autoregressive Conditional Modeling and...\n         ‚úì Full abstract: 237 words\n      üìñ Hidden in the Noise: Two-Stage Robust Watermarking for Image...\n         ‚úì Full abstract: 189 words\n      Progress: 5/26 papers processed\n      üìñ UniReal: Universal Image Generation and Editing via Learning...\n         ‚úì Full abstract: 130 words\n      üìñ OmniDocBench: Benchmarking Diverse PDF Document Parsing with...\n         ‚úì Full abstract: 176 words\n      üìñ FiVA: Fine-grained Visual Attribute Dataset for Text-to-Imag...\n         ‚úì Full abstract: 223 words\n      üìñ Mobile Video Diffusion...\n         ‚úì Full abstract: 130 words\n      üìñ 3DTrajMaster: Mastering 3D Trajectory for Multi-Entity Motio...\n         ‚úì Full abstract: 207 words\n      Progress: 10/26 papers processed\n      üìñ Granite Guardian...\n         ‚úì Full abstract: 151 words\n      üìñ MoViE: Mobile Diffusion for Video Editing...\n         ‚úì Full abstract: 125 words\n      üìñ Video Motion Transfer with Diffusion Transformers...\n         ‚úì Full abstract: 120 words\n      üìñ Frame Representation Hypothesis: Multi-Token LLM Interpretab...\n         ‚úì Full abstract: 193 words\n      üìñ Perception Tokens Enhance Visual Reasoning in Multimodal Lan...\n         ‚úì Full abstract: 244 words\n      Progress: 15/26 papers processed\n      üìñ EMOv2: Pushing 5M Vision Model Frontier...\n         ‚úì Full abstract: 241 words\n      üìñ LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subj...\n         ‚úì Full abstract: 155 words\n      üìñ ILLUME: Illuminating Your LLMs to See, Draw, and Self-Enhanc...\n         ‚úì Full abstract: 190 words\n      üìñ Fully Open Source Moxin-7B Technical Report...\n         ‚úì Full abstract: 249 words\n      üìñ Chimera: Improving Generalist Model with Domain-Specific Exp...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.05983\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ ObjCtrl-2.5D: Training-free Object Control with Camera Poses...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.07721\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ HARP: Hesitation-Aware Reframing in Transformer Inference Pa...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.07282\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ GraPE: A Generate-Plan-Edit Framework for Compositional T2I ...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.06089\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ A New Federated Learning Framework Against Gradient Inversio...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.07187\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Contextualized Counterspeech: Strategies for Adaptation,\n  P...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.07338\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Maximizing Alignment with Minimal Feedback: Efficiently Lear...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.04835\n         ‚ö†Ô∏è Detail page failed, using preview\n‚úì 2024-12-11: 19 papers\n   ‚ùå Request error for 2024-12-12: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-12\n‚óã 2024-12-12: no papers\n   ‚ùå Request error for 2024-12-13: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-13\n‚óã 2024-12-13: no papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 60 days, 619 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n   ‚ùå Request error for 2024-12-14: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-14\n‚óã 2024-12-14: no papers\n   ‚ùå Request error for 2024-12-15: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-15\n‚óã 2024-12-15: no papers\n   ‚ùå Request error for 2024-12-16: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-16\n‚óã 2024-12-16: no papers\n   ‚ùå Request error for 2024-12-17: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-17\n‚óã 2024-12-17: no papers\n   ‚ùå Request error for 2024-12-18: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-18\n‚óã 2024-12-18: no papers\n   ‚ùå Request error for 2024-12-19: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-19\n‚óã 2024-12-19: no papers\n   ‚ùå Request error for 2024-12-20: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-20\n‚óã 2024-12-20: no papers\n      üìñ Qwen2.5 Technical Report...\n         ‚úì Full abstract: 254 words\n      üìñ Progressive Multimodal Reasoning via Active Retrieval...\n         ‚úì Full abstract: 194 words\n      üìñ MegaPairs: Massive Data Synthesis For Universal Multimodal R...\n         ‚úì Full abstract: 185 words\n      üìñ How to Synthesize Text Data without Model Collapse?...\n         ‚úì Full abstract: 196 words\n      üìñ LongBench v2: Towards Deeper Understanding and Reasoning on ...\n         ‚úì Full abstract: 179 words\n      Progress: 5/17 papers processed\n      üìñ Flowing from Words to Pixels: A Framework for Cross-Modality...\n         ‚úì Full abstract: 276 words\n      üìñ LeviTor: 3D Trajectory Oriented Image-to-Video Synthesis...\n         ‚úì Full abstract: 168 words\n      üìñ Affordance-Aware Object Insertion via Mask-Aware Dual Diffus...\n         ‚úì Full abstract: 175 words\n      üìñ AceMath: Advancing Frontier Math Reasoning with Post-Trainin...\n         ‚úì Full abstract: 171 words\n      üìñ DI-PCG: Diffusion-based Efficient Inverse Procedural Content...\n         ‚úì Full abstract: 183 words\n      Progress: 10/17 papers processed\n      üìñ Descriptive Caption Enhancement with Visual Specialists for ...\n         ‚úì Full abstract: 156 words\n      üìñ UIP2P: Unsupervised Instruction-based Image Editing via Cycl...\n         ‚úì Full abstract: 169 words\n      üìñ AV-Link: Temporally-Aligned Diffusion Features for Cross-Mod...\n         ‚úì Full abstract: 128 words\n      üìñ TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Gene...\n         ‚úì Full abstract: 153 words\n      üìñ PixelMan: Consistent Object Editing with Diffusion Models vi...\n         ‚úì Full abstract: 211 words\n      Progress: 15/17 papers processed\n      üìñ DateLogicQA: Benchmarking Temporal Biases in Large Language ...\n         ‚úì Full abstract: 76 words\n      üìñ Move-in-2D: 2D-Conditioned Human Motion Generation...\n         ‚úì Full abstract: 155 words\n‚úì 2024-12-21: 17 papers\n      üìñ Qwen2.5 Technical Report...\n         ‚úì Full abstract: 254 words\n      üìñ Progressive Multimodal Reasoning via Active Retrieval...\n         ‚úì Full abstract: 194 words\n      üìñ MegaPairs: Massive Data Synthesis For Universal Multimodal R...\n         ‚úì Full abstract: 185 words\n      üìñ How to Synthesize Text Data without Model Collapse?...\n         ‚úì Full abstract: 196 words\n      üìñ LongBench v2: Towards Deeper Understanding and Reasoning on ...\n         ‚úì Full abstract: 179 words\n      Progress: 5/17 papers processed\n      üìñ Flowing from Words to Pixels: A Framework for Cross-Modality...\n         ‚úì Full abstract: 276 words\n      üìñ LeviTor: 3D Trajectory Oriented Image-to-Video Synthesis...\n         ‚úì Full abstract: 168 words\n      üìñ Affordance-Aware Object Insertion via Mask-Aware Dual Diffus...\n         ‚úì Full abstract: 175 words\n      üìñ AceMath: Advancing Frontier Math Reasoning with Post-Trainin...\n         ‚úì Full abstract: 171 words\n      üìñ DI-PCG: Diffusion-based Efficient Inverse Procedural Content...\n         ‚úì Full abstract: 183 words\n      Progress: 10/17 papers processed\n      üìñ Descriptive Caption Enhancement with Visual Specialists for ...\n         ‚úì Full abstract: 156 words\n      üìñ UIP2P: Unsupervised Instruction-based Image Editing via Cycl...\n         ‚úì Full abstract: 169 words\n      üìñ AV-Link: Temporally-Aligned Diffusion Features for Cross-Mod...\n         ‚úì Full abstract: 128 words\n      üìñ TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Gene...\n         ‚úì Full abstract: 153 words\n      üìñ PixelMan: Consistent Object Editing with Diffusion Models vi...\n         ‚úì Full abstract: 211 words\n      Progress: 15/17 papers processed\n      üìñ DateLogicQA: Benchmarking Temporal Biases in Large Language ...\n         ‚úì Full abstract: 76 words\n      üìñ Move-in-2D: 2D-Conditioned Human Motion Generation...\n         ‚úì Full abstract: 155 words\n‚úì 2024-12-22: 17 papers\n      üìñ Parallelized Autoregressive Visual Generation...\n         ‚úì Full abstract: 186 words\n      üìñ Offline Reinforcement Learning for LLM Multi-Step Reasoning...\n         ‚úì Full abstract: 215 words\n      üìñ CLEAR: Conv-Like Linearization Revs Pre-Trained Diffusion Tr...\n         ‚úì Full abstract: 220 words\n      üìñ Taming Multimodal Joint Training for High-Quality Video-to-A...\n         ‚úì Full abstract: 146 words\n      üìñ SCOPE: Optimizing Key-Value Cache Compression in Long-contex...\n         ‚úì Full abstract: 171 words\n      Progress: 5/13 papers processed\n      üìñ Toward Robust Hyper-Detailed Image Captioning: A Multiagent ...\n         ‚úì Full abstract: 169 words\n      üìñ MixLLM: LLM Quantization with Global Mixed-precision between...\n         ‚úì Full abstract: 243 words\n      üìñ TRecViT: A Recurrent Video Transformer...\n         ‚úì Full abstract: 114 words\n      üìñ Sequence Matters: Harnessing Video Models in 3D Super-Resolu...\n         ‚úì Full abstract: 184 words\n      üìñ Multi-LLM Text Summarization...\n         ‚úì Full abstract: 137 words\n      Progress: 10/13 papers processed\n      üìñ IDOL: Instant Photorealistic 3D Human Creation from a Single...\n         ‚úì Full abstract: 199 words\n      üìñ Fietje: An open, efficient LLM for Dutch...\n         ‚úì Full abstract: 187 words\n      üìñ LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic ...\n         ‚úì Full abstract: 155 words\n‚úì 2024-12-23: 13 papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 70 days, 666 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n      üìñ RobustFT: Robust Supervised Fine-tuning for Large Language M...\n         ‚úì Full abstract: 163 words\n      üìñ B-STaR: Monitoring and Balancing Exploration and Exploitatio...\n         ‚úì Full abstract: 228 words\n      üìñ Diving into Self-Evolving Training for Multimodal Reasoning...\n         ‚úì Full abstract: 256 words\n      üìñ Distilled Decoding 1: One-step Sampling of Image Auto-regres...\n         ‚úì Full abstract: 286 words\n      üìñ OpenAI o1 System Card...\n         ‚úì Full abstract: 154 words\n      Progress: 5/17 papers processed\n      üìñ Deliberation in Latent Space via Differentiable Cache Augmen...\n         ‚úì Full abstract: 215 words\n      üìñ Revisiting In-Context Learning with Long Context Language Mo...\n         ‚úì Full abstract: 204 words\n      üìñ Large Motion Video Autoencoding with Cross-modal Video VAE...\n         ‚úì Full abstract: 223 words\n      üìñ DRT-o1: Optimized Deep Reasoning Translation via Long Chain-...\n         ‚úì Full abstract: 260 words\n      üìñ LearnLM: Improving Gemini for Learning...\n         ‚úì Full abstract: 193 words\n      Progress: 10/17 papers processed\n      üìñ Outcome-Refining Process Supervision for Code Generation...\n         ‚úì Full abstract: 173 words\n      üìñ ResearchTown: Simulator of Human Research Community...\n         ‚úì Full abstract: 205 words\n      üìñ PC Agent: While You Sleep, AI Works -- A Cognitive Journey i...\n         ‚úì Full abstract: 269 words\n      üìñ Agent-SafetyBench: Evaluating the Safety of LLM Agents...\n         ‚úì Full abstract: 200 words\n      üìñ Friends-MMC: A Dataset for Multi-modal Multi-party Conversat...\n         ‚úì Full abstract: 223 words\n      Progress: 15/17 papers processed\n      üìñ OpenRFT: Adapting Reasoning Foundation Model for Domain-spec...\n         ‚úì Full abstract: 121 words\n      üìñ NILE: Internal Consistency Alignment in Large Language Model...\n         ‚úì Full abstract: 191 words\n‚úì 2024-12-24: 17 papers\n      üìñ Fourier Position Embedding: Enhancing Attention's Periodic E...\n         ‚úì Full abstract: 195 words\n      üìñ 3DGraphLLM: Combining Semantic Graphs and Large Language Mod...\n         ‚úì Full abstract: 199 words\n      üìñ DepthLab: From Partial to Complete...\n         ‚úì Full abstract: 135 words\n      üìñ DiTCtrl: Exploring Attention Control in Multi-Modal Diffusio...\n         ‚úì Full abstract: 208 words\n      üìñ PartGen: Part-level 3D Generation and Reconstruction with Mu...\n         ‚úì Full abstract: 229 words\n      Progress: 5/11 papers processed\n      üìñ Ensembling Large Language Models with Process Reward-Guided ...\n         ‚úì Full abstract: 179 words\n      üìñ In Case You Missed It: ARC 'Challenge' Is Not That Challengi...\n         ‚úì Full abstract: 115 words\n      üìñ ReMoE: Fully Differentiable Mixture-of-Experts with ReLU Rou...\n         ‚úì Full abstract: 148 words\n      üìñ SKETCH: Structured Knowledge Enhanced Text Comprehension for...\n         ‚úì Full abstract: 173 words\n      üìñ Bridging the Data Provenance Gap Across Text, Speech and Vid...\n         ‚úì Full abstract: 254 words\n      Progress: 10/11 papers processed\n      üìñ MotiF: Making Text Count in Image Animation with Motion Foca...\n         ‚úì Full abstract: 190 words\n‚úì 2024-12-25: 11 papers\n      üìñ Token-Budget-Aware LLM Reasoning...\n         ‚úì Full abstract: 150 words\n      üìñ Mulberry: Empowering MLLM with o1-like Reasoning and Reflect...\n         ‚úì Full abstract: 173 words\n      üìñ Video-Panda: Parameter-efficient Alignment for Encoder-free\n...\n         ‚úì Full abstract: 180 words\n      üìñ WavePulse: Real-time Content Analytics of Radio Livestreams...\n         ‚úì Full abstract: 170 words\n      üìñ How \"Real\" is Your Real-Time Simultaneous Speech-to-Text Tra...\n         ‚úì Full abstract: 156 words\n      Progress: 5/7 papers processed\n      üìñ VidTwin: Video VAE with Decoupled Structure and Dynamics...\n         ‚úì Full abstract: 178 words\n      üìñ PepTune: De Novo Generation of Therapeutic Peptides with\n  M...\n         ‚úì Full abstract: 247 words\n‚úì 2024-12-26: 7 papers\n      üìñ YuLan-Mini: An Open Data-efficient Language Model...\n         ‚úì Full abstract: 141 words\n      üìñ A Silver Bullet or a Compromise for Full Attention? A Compre...\n         ‚úì Full abstract: 151 words\n      üìñ MMFactory: A Universal Solution Search Engine for Vision-Lan...\n         ‚úì Full abstract: 253 words\n      üìñ Molar: Multimodal LLMs with Collaborative Filtering Alignmen...\n         ‚úì Full abstract: 194 words\n‚úì 2024-12-27: 4 papers\n      üìñ YuLan-Mini: An Open Data-efficient Language Model...\n         ‚úì Full abstract: 141 words\n      üìñ A Silver Bullet or a Compromise for Full Attention? A Compre...\n         ‚úì Full abstract: 151 words\n      üìñ MMFactory: A Universal Solution Search Engine for Vision-Lan...\n         ‚úì Full abstract: 253 words\n      üìñ Molar: Multimodal LLMs with Collaborative Filtering Alignmen...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2412.18176\n         ‚ö†Ô∏è Detail page failed, using preview\n‚úì 2024-12-28: 3 papers\n   ‚ùå Request error for 2024-12-29: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-29\n‚óã 2024-12-29: no papers\n   ‚ùå Request error for 2024-12-30: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-30\n‚óã 2024-12-30: no papers\n   ‚ùå Request error for 2024-12-31: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2024-12-31\n‚óã 2024-12-31: no papers\n   ‚ùå Request error for 2025-01-01: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-01\n‚óã 2025-01-01: no papers\n   ‚ùå Request error for 2025-01-02: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-02\n‚óã 2025-01-02: no papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 80 days, 708 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n   ‚ùå Request error for 2025-01-03: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-03\n‚óã 2025-01-03: no papers\n   ‚ùå Request error for 2025-01-04: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-04\n‚óã 2025-01-04: no papers\n      üìñ 2.5 Years in Class: A Multimodal Textbook for Vision-Languag...\n         ‚úì Full abstract: 214 words\n      üìñ VideoAnydoor: High-fidelity Video Object Insertion with Prec...\n         ‚úì Full abstract: 192 words\n      üìñ CodeElo: Benchmarking Competition-level Code Generation of L...\n         ‚úì Full abstract: 270 words\n      üìñ VideoRefer Suite: Advancing Spatial-Temporal Object Understa...\n         ‚úì Full abstract: 180 words\n      üìñ LTX-Video: Realtime Video Latent Diffusion...\n         ‚úì Full abstract: 239 words\n      Progress: 5/19 papers processed\n      üìñ Reconstruction vs. Generation: Taming Optimization Dilemma i...\n         ‚úì Full abstract: 223 words\n      üìñ MLLM-as-a-Judge for Image Safety without Human Labeling...\n         ‚úì Full abstract: 263 words\n      üìñ ProgCo: Program Helps Self-Correction of Large Language Mode...\n         ‚úì Full abstract: 122 words\n      üìñ MapEval: A Map-Based Evaluation of Geo-Spatial Reasoning in ...\n         ‚úì Full abstract: 260 words\n      üìñ A3: Android Agent Arena for Mobile GUI Agents...\n         ‚úì Full abstract: 182 words\n      Progress: 10/19 papers processed\n      üìñ Unifying Specialized Visual Encoders for Video Language Mode...\n         ‚úì Full abstract: 202 words\n      üìñ Dynamic Scaling of Unit Tests for Code Reward Modeling...\n         ‚úì Full abstract: 200 words\n      üìñ SeedVR: Seeding Infinity in Diffusion Transformer Towards Ge...\n         ‚úì Full abstract: 143 words\n      üìñ Nested Attention: Semantic-aware Attention Values for Concep...\n         ‚úì Full abstract: 174 words\n      üìñ MapQaTor: A System for Efficient Annotation of Map Query Dat...\n         ‚úì Full abstract: 211 words\n      Progress: 15/19 papers processed\n      üìñ Understanding and Mitigating Bottlenecks of State Space Mode...\n         ‚úì Full abstract: 177 words\n      üìñ Population Aware Diffusion for Time Series Generation...\n         ‚úì Full abstract: 231 words\n      üìñ Rethinking Addressing in Language Models via Contexualized E...\n         ‚úì Full abstract: 166 words\n      üìñ SeFAR: Semi-supervised Fine-grained Action Recognition with ...\n         ‚úì Full abstract: 236 words\n‚úì 2025-01-05: 19 papers\n      üìñ EnerVerse: Envisioning Embodied Future Space for Robotics Ma...\n         ‚úì Full abstract: 207 words\n      üìñ VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech I...\n         ‚úì Full abstract: 148 words\n      üìñ Virgo: A Preliminary Exploration on Reproducing o1-like MLLM...\n         ‚úì Full abstract: 187 words\n      üìñ SDPO: Segment-Level Direct Preference Optimization for Socia...\n         ‚úì Full abstract: 144 words\n      üìñ Graph Generative Pre-trained Transformer...\n         ‚úì Full abstract: 160 words\n      Progress: 5/8 papers processed\n      üìñ VisionReward: Fine-Grained Multi-Dimensional Human Preferenc...\n         ‚úì Full abstract: 145 words\n      üìñ LUSIFER: Language Universal Space Integration for Enhanced M...\n         ‚úì Full abstract: 167 words\n      üìñ BoxingGym: Benchmarking Progress in Automated Experimental D...\n         ‚úì Full abstract: 272 words\n‚úì 2025-01-06: 8 papers\n      üìñ STAR: Spatial-Temporal Augmentation with Text-to-Video Model...\n         ‚úì Full abstract: 179 words\n      üìñ Test-time Computing: from System-1 Thinking to System-2 Thin...\n         ‚úì Full abstract: 148 words\n      üìñ BoostStep: Boosting mathematical capability of Large Languag...\n         ‚úì Full abstract: 212 words\n      üìñ Dispider: Enabling Video LLMs with Active Real-Time Interact...\n         ‚úì Full abstract: 240 words\n      üìñ Personalized Graph-Based Retrieval for Large Language Models...\n         ‚úì Full abstract: 144 words\n      Progress: 5/19 papers processed\n      üìñ TransPixar: Advancing Text-to-Video Generation with Transpar...\n         ‚úì Full abstract: 148 words\n      üìñ Scaling Laws for Floating Point Quantization Training...\n         ‚úì Full abstract: 216 words\n      üìñ METAGENE-1: Metagenomic Foundation Model for Pandemic Monito...\n         ‚úì Full abstract: 224 words\n      üìñ Through-The-Mask: Mask-based Motion Trajectories for Image-t...\n         ‚úì Full abstract: 217 words\n      üìñ Auto-RT: Automatic Jailbreak Strategy Exploration for Red-Te...\n         ‚úì Full abstract: 153 words\n      Progress: 10/19 papers processed\n      üìñ GS-DiT: Advancing Video Generation with Pseudo 4D Gaussian F...\n         ‚úì Full abstract: 258 words\n      üìñ DepthMaster: Taming Diffusion Models for Monocular Depth Est...\n         ‚úì Full abstract: 209 words\n      üìñ PRMBench: A Fine-grained and Challenging Benchmark for Proce...\n         ‚úì Full abstract: 178 words\n      üìñ ToolHop: A Query-Driven Benchmark for Evaluating Large Langu...\n         ‚úì Full abstract: 167 words\n      üìñ Samba-asr state-of-the-art speech recognition leveraging str...\n         ‚úì Full abstract: 235 words\n      Progress: 15/19 papers processed\n      üìñ Ingredients: Blending Custom Photos with Video Diffusion Tra...\n         ‚úì Full abstract: 155 words\n      üìñ AutoPresent: Designing Structured Visuals from Scratch...\n         ‚úì Full abstract: 197 words\n      üìñ Automated Generation of Challenging Multiple-Choice Question...\n         ‚úì Full abstract: 143 words\n      üìñ ProTracker: Probabilistic Integration for Robust and Accurat...\n         ‚úì Full abstract: 129 words\n‚úì 2025-01-07: 19 papers\n      üìñ REINFORCE++: A Simple and Efficient Approach for Aligning La...\n         ‚úì Full abstract: 127 words\n      üìñ Cosmos World Foundation Model Platform for Physical AI...\n         ‚úì Full abstract: 129 words\n      üìñ LLaVA-Mini: Efficient Image and Video Large Multimodal Model...\n         ‚úì Full abstract: 255 words\n      üìñ Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understan...\n         ‚úì Full abstract: 172 words\n      üìñ MotionBench: Benchmarking and Improving Fine-grained Video M...\n         ‚úì Full abstract: 178 words\n      Progress: 5/15 papers processed\n      üìñ Diffusion as Shader: 3D-aware Video Diffusion for Versatile ...\n         ‚úì Full abstract: 207 words\n      üìñ PPTAgent: Generating and Evaluating Presentations Beyond Tex...\n         ‚úì Full abstract: 152 words\n      üìñ OpenOmni: Large Language Models Pivot Zero-shot Omnimodal Al...\n         ‚úì Full abstract: 138 words\n      üìñ Dolphin: Closed-loop Open-ended Auto-research through Thinki...\n         ‚úì Full abstract: 203 words\n      üìñ Magic Mirror: ID-Preserved Video Generation in Video Diffusi...\n         ‚úì Full abstract: 141 words\n      Progress: 10/15 papers processed\n      üìñ MoDec-GS: Global-to-Local Motion Decomposition and Temporal ...\n         ‚úì Full abstract: 229 words\n      üìñ Segmenting Text and Learning Their Rewards for Improved RLHF...\n         ‚úì Full abstract: 181 words\n      üìñ Graph-Aware Isomorphic Attention for Adaptive Dynamics in Tr...\n         ‚úì Full abstract: 245 words\n      üìñ MagicFace: High-Fidelity Facial Expression Editing with Acti...\n         ‚úì Full abstract: 169 words\n      üìñ Generalizable Origin Identification for Text-Guided Image-to...\n         ‚úì Full abstract: 240 words\n      Progress: 15/15 papers processed\n‚úì 2025-01-08: 15 papers\n      üìñ rStar-Math: Small LLMs Can Master Math Reasoning with Self-E...\n         ‚úì Full abstract: 223 words\n      üìñ Search-o1: Agentic Search-Enhanced Large Reasoning Models...\n         ‚úì Full abstract: 180 words\n      üìñ Towards System 2 Reasoning in LLMs: Learning How to Think Wi...\n         ‚úì Full abstract: 133 words\n      üìñ Agent Laboratory: Using LLM Agents as Research Assistants...\n         ‚úì Full abstract: 211 words\n      üìñ URSA: Understanding and Verifying Chain-of-thought Reasoning...\n         ‚úì Full abstract: 207 words\n      Progress: 5/13 papers processed\n      üìñ LLM4SR: A Survey on Large Language Models for Scientific Res...\n         ‚úì Full abstract: 130 words\n      üìñ InfiGUIAgent: A Multimodal Generalist GUI Agent with Native ...\n         ‚úì Full abstract: 117 words\n      üìñ GeAR: Generation Augmented Retrieval...\n         ‚úì Full abstract: 208 words\n      üìñ Chirpy3D: Continuous Part Latents for Creative 3D Bird Gener...\n         ‚úì Full abstract: 118 words\n      üìñ SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from...\n         ‚úì Full abstract: 176 words\n      Progress: 10/13 papers processed\n      üìñ EpiCoder: Encompassing Diversity and Complexity in Code Gene...\n         ‚úì Full abstract: 224 words\n      üìñ Multi-task retriever fine-tuning for domain-specific and eff...\n         ‚úì Full abstract: 157 words\n      üìñ DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Dive...\n         ‚úì Full abstract: 156 words\n‚úì 2025-01-09: 13 papers\n      üìñ The GAN is dead; long live the GAN! A Modern GAN Baseline...\n         ‚úì Full abstract: 156 words\n      üìñ Enhancing Human-Like Responses in Large Language Models...\n         ‚úì Full abstract: 91 words\n      üìñ An Empirical Study of Autoregressive Pre-training from Video...\n         ‚úì Full abstract: 137 words\n      üìñ Are VLMs Ready for Autonomous Driving? An Empirical Study fr...\n         ‚úì Full abstract: 212 words\n      üìñ Centurio: On Drivers of Multilingual Ability of Large Vision...\n         ‚úì Full abstract: 228 words\n      Progress: 5/9 papers processed\n      üìñ SWE-Fixer: Training Open-Source LLMs for Effective and Effic...\n         ‚úì Full abstract: 224 words\n      üìñ On Computational Limits and Provably Efficient Criteria of V...\n         ‚úì Full abstract: 180 words\n      üìñ Entropy-Guided Attention for Private LLMs...\n         ‚úì Full abstract: 222 words\n      üìñ Building Foundations for Natural Language Processing of Hist...\n         ‚úì Full abstract: 159 words\n‚úì 2025-01-10: 9 papers\n      üìñ The GAN is dead; long live the GAN! A Modern GAN Baseline...\n         ‚úì Full abstract: 156 words\n      üìñ Enhancing Human-Like Responses in Large Language Models...\n         ‚úì Full abstract: 91 words\n      üìñ An Empirical Study of Autoregressive Pre-training from Video...\n         ‚úì Full abstract: 137 words\n      üìñ Are VLMs Ready for Autonomous Driving? An Empirical Study fr...\n         ‚úì Full abstract: 212 words\n      üìñ Centurio: On Drivers of Multilingual Ability of Large Vision...\n         ‚úì Full abstract: 228 words\n      Progress: 5/9 papers processed\n      üìñ SWE-Fixer: Training Open-Source LLMs for Effective and Effic...\n         ‚úì Full abstract: 224 words\n      üìñ On Computational Limits and Provably Efficient Criteria of V...\n         ‚úì Full abstract: 180 words\n      üìñ Entropy-Guided Attention for Private LLMs...\n         ‚úì Full abstract: 222 words\n      üìñ Building Foundations for Natural Language Processing of Hist...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2501.04828\n         ‚ö†Ô∏è Detail page failed, using preview\n‚úì 2025-01-11: 8 papers\n   ‚ùå Request error for 2025-01-12: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-12\n‚óã 2025-01-12: no papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 90 days, 799 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n   ‚ùå Request error for 2025-01-13: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-13\n‚óã 2025-01-13: no papers\n   ‚ùå Request error for 2025-01-14: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-14\n‚óã 2025-01-14: no papers\n   ‚ùå Request error for 2025-01-15: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-15\n‚óã 2025-01-15: no papers\n   ‚ùå Request error for 2025-01-16: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-16\n‚óã 2025-01-16: no papers\n   ‚ùå Request error for 2025-01-17: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-17\n‚óã 2025-01-17: no papers\n   ‚ùå Request error for 2025-01-18: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-18\n‚óã 2025-01-18: no papers\n   ‚ùå Request error for 2025-01-19: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-19\n‚óã 2025-01-19: no papers\n   ‚ùå Request error for 2025-01-20: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-20\n‚óã 2025-01-20: no papers\n   ‚ùå Request error for 2025-01-21: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-21\n‚óã 2025-01-21: no papers\n      üìñ Agent-R: Training Language Model Agents to Reflect via Itera...\n         ‚úì Full abstract: 271 words\n      üìñ MMVU: Measuring Expert-Level Multi-Discipline Video Understa...\n         ‚úì Full abstract: 178 words\n      üìñ Demons in the Detail: On Implementing Load Balancing Loss fo...\n         ‚úì Full abstract: 245 words\n      üìñ UI-TARS: Pioneering Automated GUI Interaction with Native Ag...\n         ‚úì Full abstract: 247 words\n      üìñ TokenVerse: Versatile Multi-concept Personalization in Token...\n         ‚úì Full abstract: 181 words\n      Progress: 5/20 papers processed\n      üìñ Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution ...\n         ‚úì Full abstract: 188 words\n      üìñ InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-M...\n         ‚úì Full abstract: 233 words\n      üìñ Reasoning Language Models: A Blueprint...\n         ‚úì Full abstract: 273 words\n      üìñ Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex T...\n         ‚úì Full abstract: 246 words\n      üìñ Learn-by-interact: A Data-Centric Framework for Self-Adaptiv...\n         ‚úì Full abstract: 238 words\n      Progress: 10/20 papers processed\n      üìñ Video Depth Anything: Consistent Depth Estimation for Super-...\n         ‚úì Full abstract: 223 words\n      üìñ Go-with-the-Flow: Motion-Controllable Video Diffusion Models...\n         ‚úì Full abstract: 208 words\n      üìñ GPS as a Control Signal for Image Generation...\n         ‚úì Full abstract: 123 words\n      üìñ Condor: Enhance LLM Alignment with Knowledge-Driven Data Syn...\n         ‚úì Full abstract: 145 words\n      üìñ EMO2: End-Effector Guided Audio-Driven Avatar Video Generati...\n         ‚úì Full abstract: 168 words\n      Progress: 15/20 papers processed\n      üìñ Taming Teacher Forcing for Masked Autoregressive Video Gener...\n         ‚úì Full abstract: 126 words\n      üìñ MSTS: A Multimodal Safety Test Suite for Vision-Language Mod...\n         ‚úì Full abstract: 199 words\n      üìñ The Geometry of Tokens in Internal Representations of Large ...\n         ‚úì Full abstract: 137 words\n      üìñ Panoramic Interests: Stylistic-Content Aware Personalized He...\n         ‚úì Full abstract: 129 words\n      üìñ Fixing Imbalanced Attention to Mitigate In-Context Hallucina...\n         ‚úì Full abstract: 196 words\n      Progress: 20/20 papers processed\n‚úì 2025-01-22: 20 papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 100 days, 819 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n      üìñ DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\n...\n         ‚úì Full abstract: 111 words\n      üìñ Kimi k1.5: Scaling Reinforcement Learning with LLMs...\n         ‚úì Full abstract: 228 words\n      üìñ VideoLLaMA 3: Frontier Multimodal Foundation Models for Imag...\n         ‚úì Full abstract: 239 words\n      üìñ FilmAgent: A Multi-Agent Framework for End-to-End Film Autom...\n         ‚úì Full abstract: 202 words\n      üìñ Test-Time Preference Optimization: On-the-Fly Alignment via ...\n         ‚úì Full abstract: 177 words\n      Progress: 5/10 papers processed\n      üìñ Autonomy-of-Experts Models...\n         ‚úì Full abstract: 187 words\n      üìñ O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reason...\n         ‚úì Full abstract: 183 words\n      üìñ Pairwise RM: Perform Best-of-N Sampling with Knockout Tourna...\n         ‚úì Full abstract: 167 words\n      üìñ Fast3R: Towards 3D Reconstruction of 1000+ Images in One For...\n         ‚úì Full abstract: 134 words\n      üìñ IntellAgent: A Multi-Agent Framework for Evaluating Conversa...\n         ‚úì Full abstract: 236 words\n      Progress: 10/10 papers processed\n‚úì 2025-01-23: 10 papers\n      üìñ SRMT: Shared Memory for Multi-agent Lifelong Pathfinding...\n         ‚úì Full abstract: 191 words\n      üìñ Improving Video Generation with Human Feedback...\n         ‚úì Full abstract: 197 words\n      üìñ Sigma: Differential Rescaling of Query, Key and Value for Ef...\n         ‚úì Full abstract: 219 words\n      üìñ Can We Generate Images with CoT? Let's Verify and Reinforce ...\n         ‚úì Full abstract: 219 words\n      üìñ Video-MMMU: Evaluating Knowledge Acquisition from Multi-Disc...\n         ‚úì Full abstract: 160 words\n      Progress: 5/17 papers processed\n      üìñ Temporal Preference Optimization for Long-Form Video Underst...\n         ‚úì Full abstract: 179 words\n      üìñ IMAGINE-E: Image Generation Intelligence Evaluation of State...\n         ‚úì Full abstract: 242 words\n      üìñ Step-KTO: Optimizing Mathematical Reasoning through Stepwise...\n         ‚úì Full abstract: 156 words\n      üìñ DiffuEraser: A Diffusion Model for Video Inpainting...\n         ‚úì Full abstract: 178 words\n      üìñ Hallucinations Can Improve Large Language Models in Drug Dis...\n         ‚úì Full abstract: 173 words\n      Progress: 10/17 papers processed\n      üìñ One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Ge...\n         ‚úì Full abstract: 174 words\n      üìñ EchoVideo: Identity-Preserving Human Video Generation by Mul...\n         ‚úì Full abstract: 181 words\n      üìñ Debate Helps Weak-to-Strong Generalization...\n         ‚úì Full abstract: 258 words\n      üìñ EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents...\n         ‚úì Full abstract: 196 words\n      üìñ Evolution and The Knightian Blindspot of Machine Learning...\n         ‚úì Full abstract: 263 words\n      Progress: 15/17 papers processed\n      üìñ Control LLM: Controlled Evolution for Intelligence Retention...\n         ‚úì Full abstract: 221 words\n      üìñ GSTAR: Gaussian Surface Tracking and Reconstruction...\n         ‚úì Full abstract: 177 words\n‚úì 2025-01-24: 17 papers\n      üìñ SRMT: Shared Memory for Multi-agent Lifelong Pathfinding...\n         ‚úì Full abstract: 191 words\n      üìñ Improving Video Generation with Human Feedback...\n         ‚úì Full abstract: 197 words\n      üìñ Sigma: Differential Rescaling of Query, Key and Value for Ef...\n         ‚úì Full abstract: 219 words\n      üìñ Can We Generate Images with CoT? Let's Verify and Reinforce ...\n         ‚úì Full abstract: 219 words\n      üìñ Video-MMMU: Evaluating Knowledge Acquisition from Multi-Disc...\n         ‚úì Full abstract: 160 words\n      Progress: 5/17 papers processed\n      üìñ Temporal Preference Optimization for Long-Form Video Underst...\n         ‚úì Full abstract: 179 words\n      üìñ IMAGINE-E: Image Generation Intelligence Evaluation of State...\n         ‚úì Full abstract: 242 words\n      üìñ Step-KTO: Optimizing Mathematical Reasoning through Stepwise...\n         ‚úì Full abstract: 156 words\n      üìñ DiffuEraser: A Diffusion Model for Video Inpainting...\n         ‚úì Full abstract: 178 words\n      üìñ Hallucinations Can Improve Large Language Models in Drug Dis...\n         ‚úì Full abstract: 173 words\n      Progress: 10/17 papers processed\n      üìñ One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Ge...\n         ‚úì Full abstract: 174 words\n      üìñ EchoVideo: Identity-Preserving Human Video Generation by Mul...\n         ‚úì Full abstract: 181 words\n      üìñ Debate Helps Weak-to-Strong Generalization...\n         ‚úì Full abstract: 258 words\n      üìñ EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents...\n         ‚úì Full abstract: 196 words\n      üìñ Evolution and The Knightian Blindspot of Machine Learning...\n         ‚úì Full abstract: 263 words\n      Progress: 15/17 papers processed\n      üìñ Control LLM: Controlled Evolution for Intelligence Retention...\n         ‚úì Full abstract: 221 words\n      üìñ GSTAR: Gaussian Surface Tracking and Reconstruction...\n         ‚úì Full abstract: 177 words\n‚úì 2025-01-25: 17 papers\n      üìñ SRMT: Shared Memory for Multi-agent Lifelong Pathfinding...\n         ‚úì Full abstract: 191 words\n      üìñ Improving Video Generation with Human Feedback...\n         ‚úì Full abstract: 197 words\n      üìñ Sigma: Differential Rescaling of Query, Key and Value for Ef...\n         ‚úì Full abstract: 219 words\n      üìñ Can We Generate Images with CoT? Let's Verify and Reinforce ...\n         ‚úì Full abstract: 219 words\n      üìñ Video-MMMU: Evaluating Knowledge Acquisition from Multi-Disc...\n         ‚úì Full abstract: 160 words\n      Progress: 5/17 papers processed\n      üìñ Temporal Preference Optimization for Long-Form Video Underst...\n         ‚úì Full abstract: 179 words\n      üìñ IMAGINE-E: Image Generation Intelligence Evaluation of State...\n         ‚úì Full abstract: 242 words\n      üìñ Step-KTO: Optimizing Mathematical Reasoning through Stepwise...\n         ‚úì Full abstract: 156 words\n      üìñ DiffuEraser: A Diffusion Model for Video Inpainting...\n         ‚úì Full abstract: 178 words\n      üìñ Hallucinations Can Improve Large Language Models in Drug Dis...\n         ‚úì Full abstract: 173 words\n      Progress: 10/17 papers processed\n      üìñ One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Ge...\n         ‚úì Full abstract: 174 words\n      üìñ EchoVideo: Identity-Preserving Human Video Generation by Mul...\n         ‚úì Full abstract: 181 words\n      üìñ Debate Helps Weak-to-Strong Generalization...\n         ‚úì Full abstract: 258 words\n      üìñ EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents...\n         ‚úì Full abstract: 196 words\n      üìñ Evolution and The Knightian Blindspot of Machine Learning...\n         ‚úì Full abstract: 263 words\n      Progress: 15/17 papers processed\n      üìñ Control LLM: Controlled Evolution for Intelligence Retention...\n         ‚úì Full abstract: 221 words\n      üìñ GSTAR: Gaussian Surface Tracking and Reconstruction...\n         ‚úì Full abstract: 177 words\n‚úì 2025-01-26: 17 papers\n      üìñ Humanity's Last Exam...\n         ‚úì Full abstract: 174 words\n      üìñ Chain-of-Retrieval Augmented Generation...\n         ‚úì Full abstract: 201 words\n      üìñ RealCritic: Towards Effectiveness-Driven Evaluation of Langu...\n         ‚úì Full abstract: 196 words\n      üìñ Redundancy Principles for MLLMs Benchmarks...\n         ‚úì Full abstract: 146 words\n      üìñ RL + Transformer = A General-Purpose Problem Solver...\n         ‚úì Full abstract: 137 words\n      Progress: 5/12 papers processed\n      üìñ Relightable Full-Body Gaussian Codec Avatars...\n         ‚úì Full abstract: 244 words\n      üìñ Question Answering on Patient Medical Records with Private F...\n         ‚úì Full abstract: 208 words\n      üìñ GeoPixel: Pixel Grounding Large Multimodal Model in Remote S...\n         ‚úì Full abstract: 217 words\n      üìñ Multiview Equivariance Improves 3D Correspondence Understand...\n         ‚úì Full abstract: 162 words\n      üìñ CatV2TON: Taming Diffusion Transformers for Vision-Based Vir...\n         ‚úì Full abstract: 182 words\n      Progress: 10/12 papers processed\n      üìñ Denoising as Adaptation: Noise-Space Domain Adaptation for I...\n         ‚úì Full abstract: 231 words\n      üìñ AdaIR: Adaptive All-in-One Image Restoration via Frequency M...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2403.14614\n         ‚ö†Ô∏è Detail page failed, using preview\n‚úì 2025-01-27: 11 papers\n   ‚ùå Request error for 2025-01-28: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-28\n‚óã 2025-01-28: no papers\n   ‚ùå Request error for 2025-01-29: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-29\n‚óã 2025-01-29: no papers\n   ‚ùå Request error for 2025-01-30: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-30\n‚óã 2025-01-30: no papers\n   ‚ùå Request error for 2025-01-31: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-01-31\n‚óã 2025-01-31: no papers\n   ‚ùå Request error for 2025-02-01: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-02-01\n‚óã 2025-02-01: no papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 110 days, 891 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n   ‚ùå Request error for 2025-02-02: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-02-02\n‚óã 2025-02-02: no papers\n      üìñ s1: Simple test-time scaling...\n         ‚úì Full abstract: 184 words\n      üìñ Reward-Guided Speculative Decoding for Efficient LLM Reasoni...\n         ‚úì Full abstract: 160 words\n      üìñ MatAnyone: Stable Video Matting with Consistent Memory Propa...\n         ‚úì Full abstract: 128 words\n      üìñ Self-supervised Quantized Representation for Seamlessly Inte...\n         ‚úì Full abstract: 160 words\n      üìñ Scalable-Softmax Is Superior for Attention...\n         ‚úì Full abstract: 183 words\n      Progress: 5/16 papers processed\n      üìñ PixelWorld: Towards Perceiving Everything as Pixels...\n         ‚úì Full abstract: 221 words\n      üìñ DINO-WM: World Models on Pre-trained Visual Features enable ...\n         ‚úì Full abstract: 231 words\n      üìñ Constitutional Classifiers: Defending against Universal Jail...\n         ‚úì Full abstract: 156 words\n      üìñ SAeUron: Interpretable Concept Unlearning in Diffusion Model...\n         ‚úì Full abstract: 178 words\n      üìñ The Surprising Agreement Between Convex Optimization Theory ...\n         ‚úì Full abstract: 102 words\n      Progress: 10/16 papers processed\n      üìñ Zero-Shot Novel View and Depth Synthesis with Multi-View Geo...\n         ‚úì Full abstract: 198 words\n      üìñ Trading Inference-Time Compute for Adversarial Robustness...\n         ‚úì Full abstract: 150 words\n      üìñ Unraveling the Capabilities of Language Models in News Summa...\n         ‚úì Full abstract: 215 words\n      üìñ Fast Encoder-Based 3D from Casual Videos via Point Track Pro...\n         ‚úì Full abstract: 219 words\n      üìñ INT: Instance-Specific Negative Mining for Task-Generic Prom...\n         ‚úì Full abstract: 175 words\n      Progress: 15/16 papers processed\n      üìñ ChunkKV: Semantic-Preserving KV Cache Compression for Effici...\n         ‚úì Full abstract: 154 words\n‚úì 2025-02-03: 16 papers\n      üìñ OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditio...\n         ‚úì Full abstract: 177 words\n      üìñ The Differences Between Direct Alignment Algorithms are a Bl...\n         ‚úì Full abstract: 179 words\n      üìñ Process Reinforcement through Implicit Rewards...\n         ‚úì Full abstract: 201 words\n      üìñ Preference Leakage: A Contamination Problem in LLM-as-a-judg...\n         ‚úì Full abstract: 188 words\n      üìñ AlignVLM: Bridging Vision and Language Latent Spaces for Mul...\n         ‚úì Full abstract: 168 words\n      Progress: 5/26 papers processed\n      üìñ SafeRAG: Benchmarking Security in Retrieval-Augmented Genera...\n         ‚úì Full abstract: 164 words\n      üìñ SliderSpace: Decomposing the Visual Capabilities of Diffusio...\n         ‚úì Full abstract: 155 words\n      üìñ Scaling Embedding Layers in Language Models...\n         ‚úì Full abstract: 130 words\n      üìñ DeepRAG: Thinking to Retrieval Step by Step for Large Langua...\n         ‚úì Full abstract: 116 words\n      üìñ MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in ...\n         ‚úì Full abstract: 133 words\n      Progress: 10/26 papers processed\n      üìñ MakeAnything: Harnessing Diffusion Transformers for Multi-Do...\n         ‚úì Full abstract: 162 words\n      üìñ ZebraLogic: On the Scaling Limits of LLMs for Logical Reason...\n         ‚úì Full abstract: 177 words\n      üìñ FastKV: KV Cache Compression for Fast Long-Context Processin...\n         ‚úì Full abstract: 184 words\n      üìñ AIN: The Arabic INclusive Large Multimodal Model...\n         ‚úì Full abstract: 188 words\n      üìñ The Jumping Reasoning Curve? Tracking the Evolution of Reaso...\n         ‚úì Full abstract: 205 words\n      Progress: 15/26 papers processed\n      üìñ Almost Surely Safe Alignment of Large Language Models at Inf...\n         ‚úì Full abstract: 155 words\n      üìñ Improving Transformer World Models for Data-Efficient RL...\n         ‚úì Full abstract: 172 words\n      üìñ PhD Knowledge Not Required: A Reasoning Challenge for Large ...\n         ‚úì Full abstract: 183 words\n      üìñ RandLoRA: Full-rank parameter-efficient fine-tuning of large...\n         ‚úì Full abstract: 217 words\n      üìñ Improved Training Technique for Latent Consistency Models...\n         ‚úì Full abstract: 205 words\n      Progress: 20/26 papers processed\n      üìñ Lifelong Sequential Knowledge Editing without Model Degradat...\n         ‚úì Full abstract: 196 words\n      üìñ LongDPO: Unlock Better Long-form Generation Abilities for LL...\n         ‚úì Full abstract: 153 words\n      üìñ Learning to Generate Unit Tests for Automated Debugging...\n         ‚úì Full abstract: 226 words\n      üìñ Language Models Prefer What They Know: Relative Confidence E...\n         ‚úì Full abstract: 246 words\n      üìñ A Study on the Performance of U-Net Modifications in Retrope...\n         ‚úì Full abstract: 149 words\n      Progress: 25/26 papers processed\n      üìñ Current Pathology Foundation Models are unrobust to Medical ...\n         ‚úì Full abstract: 248 words\n‚úì 2025-02-04: 26 papers\n      üìñ VideoJAM: Joint Appearance-Motion Representations for Enhanc...\n         ‚úì Full abstract: 208 words\n      üìñ ACECODER: Acing Coder RL via Automated Test-Case Synthesis...\n         ‚úì Full abstract: 195 words\n      üìñ Inverse Bridge Matching Distillation...\n         ‚úì Full abstract: 168 words\n      üìñ Satori: Reinforcement Learning with Chain-of-Action-Thought ...\n         ‚úì Full abstract: 192 words\n      üìñ QLASS: Boosting Language Agent Inference via Q-Guided Stepwi...\n         ‚úì Full abstract: 197 words\n      Progress: 5/14 papers processed\n      üìñ Can LLMs Maintain Fundamental Abilities under KV Cache Compr...\n         ‚úì Full abstract: 175 words\n      üìñ Rethinking Mixture-of-Agents: Is Mixing Different Large Lang...\n         ‚úì Full abstract: 227 words\n      üìñ Concept Steerers: Leveraging K-Sparse Autoencoders for Contr...\n         ‚úì Full abstract: 163 words\n      üìñ Sample, Scrutinize and Scale: Effective Inference-Time Searc...\n         ‚úì Full abstract: 187 words\n      üìñ COCONut-PanCap: Joint Panoptic Segmentation and Grounded Cap...\n         ‚úì Full abstract: 136 words\n      Progress: 10/14 papers processed\n      üìñ Text-to-CAD Generation Through Infusing Visual Feedback in L...\n         ‚úì Full abstract: 195 words\n      üìñ Generating Multi-Image Synthetic Data for Text-to-Image Cust...\n         ‚úì Full abstract: 151 words\n      üìñ Federated Sketching LoRA: On-Device Collaborative Fine-Tunin...\n         ‚úì Full abstract: 176 words\n      üìñ Activation Approximations Can Incur Safety Vulnerabilities E...\n         ‚úì Full abstract: 159 words\n‚úì 2025-02-05: 14 papers\n      üìñ SmolLM2: When Smol Goes Big -- Data-Centric Training of a Sm...\n         ‚úì Full abstract: 184 words\n      üìñ LIMO: Less is More for Reasoning...\n         ‚úì Full abstract: 244 words\n      üìñ Demystifying Long Chain-of-Thought Reasoning in LLMs...\n         ‚úì Full abstract: 216 words\n      üìñ TwinMarket: A Scalable Behavioral and Social Simulation for ...\n         ‚úì Full abstract: 169 words\n      üìñ Boosting Multimodal Reasoning with MCTS-Automated Structured...\n         ‚úì Full abstract: 174 words\n      Progress: 5/14 papers processed\n      üìñ LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Dif...\n         ‚úì Full abstract: 131 words\n      üìñ Token Assorted: Mixing Latent and Text Tokens for Improved L...\n         ‚úì Full abstract: 166 words\n      üìñ On Teacher Hacking in Language Model Distillation...\n         ‚úì Full abstract: 234 words\n      üìñ Large Language Model Guided Self-Debugging Code Generation...\n         ‚úì Full abstract: 140 words\n      üìñ A Probabilistic Inference Approach to Inference-Time Scaling...\n         ‚úì Full abstract: 219 words\n      Progress: 10/14 papers processed\n      üìñ Jailbreaking with Universal Multi-Prompts...\n         ‚úì Full abstract: 121 words\n      üìñ Activation-Informed Merging of Large Language Models...\n         ‚úì Full abstract: 157 words\n      üìñ Riddle Me This! Stealthy Membership Inference for Retrieval-...\n         ‚úì Full abstract: 166 words\n      üìñ HackerRank-ASTRA: Evaluating Correctness & Consistency of La...\n         ‚úì Full abstract: 140 words\n‚úì 2025-02-06: 14 papers\n      üìñ Analyze Feature Flow to Enhance Interpretation and Steering ...\n         ‚úì Full abstract: 130 words\n      üìñ Gold-medalist Performance in Solving Olympiad Geometry with\n...\n         ‚úì Full abstract: 194 words\n      üìñ ConceptAttention: Diffusion Transformers Learn Highly Interp...\n         ‚úì Full abstract: 151 words\n      üìñ Great Models Think Alike and this Undermines AI Oversight...\n         ‚úì Full abstract: 176 words\n      üìñ Ola: Pushing the Frontiers of Omni-Modal Language Model with...\n         ‚úì Full abstract: 227 words\n      Progress: 5/22 papers processed\n      üìñ DynVFX: Augmenting Real Videos with Dynamic Content...\n         ‚úì Full abstract: 186 words\n      üìñ Llasa: Scaling Train-Time and Inference-Time Compute for Lla...\n         ‚úì Full abstract: 208 words\n      üìñ BOLT: Bootstrap Long Chain-of-Thought in Language Models wit...\n         ‚úì Full abstract: 245 words\n      üìñ UltraIF: Advancing Instruction Following from the Wild...\n         ‚úì Full abstract: 185 words\n      üìñ Weak-to-Strong Diffusion with Reflection...\n         ‚úì Full abstract: 229 words\n      Progress: 10/22 papers processed\n      üìñ MAGA: MAssive Genre-Audience Reformulation to Pretraining Co...\n         ‚úì Full abstract: 166 words\n      üìñ ScoreFlow: Mastering LLM Agent Workflows via Score-based Pre...\n         ‚úì Full abstract: 131 words\n      üìñ MotionLab: Unified Human Motion Generation and Editing via t...\n         ‚úì Full abstract: 225 words\n      üìñ MotionCanvas: Cinematic Shot Design with Controllable Image-...\n         ‚úì Full abstract: 215 words\n      üìñ Beyond Prompt Content: Enhancing LLM Performance via Content...\n         ‚úì Full abstract: 138 words\n      Progress: 15/22 papers processed\n      üìñ PILAF: Optimal Human Preference Sampling for Reward Modeling...\n         ‚úì Full abstract: 129 words\n      üìñ Towards Physical Understanding in Video Generation: A 3D Poi...\n         ‚úì Full abstract: 176 words\n      üìñ ChartCitor: Multi-Agent Framework for Fine-Grained Chart Vis...\n         ‚úì Full abstract: 126 words\n      üìñ Learning Real-World Action-Video Dynamics with Heterogeneous...\n         ‚úì Full abstract: 133 words\n      üìñ PlotGen: Multi-Agent LLM-based Scientific Data Visualization...\n         ‚úì Full abstract: 194 words\n      Progress: 20/22 papers processed\n      üìñ Enhancing Code Generation for Low-Resource Languages: No Sil...\n         ‚úì Full abstract: 436 words\n      üìñ Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simp...\n         ‚úì Full abstract: 178 words\n‚úì 2025-02-07: 22 papers\n      üìñ Analyze Feature Flow to Enhance Interpretation and Steering ...\n         ‚úì Full abstract: 130 words\n      üìñ Gold-medalist Performance in Solving Olympiad Geometry with\n...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.03544\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ ConceptAttention: Diffusion Transformers Learn Highly Interp...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04320\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Great Models Think Alike and this Undermines AI Oversight...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04313\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Ola: Pushing the Frontiers of Omni-Modal Language Model with...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04328\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ DynVFX: Augmenting Real Videos with Dynamic Content...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.03621\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Llasa: Scaling Train-Time and Inference-Time Compute for Lla...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04128\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ BOLT: Bootstrap Long Chain-of-Thought in Language Models wit...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.03860\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ UltraIF: Advancing Instruction Following from the Wild...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04153\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Weak-to-Strong Diffusion with Reflection...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.00473\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ MAGA: MAssive Genre-Audience Reformulation to Pretraining Co...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04235\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ ScoreFlow: Mastering LLM Agent Workflows via Score-based Pre...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04306\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ MotionLab: Unified Human Motion Generation and Editing via t...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.02358\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ MotionCanvas: Cinematic Shot Design with Controllable Image-...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04299\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Beyond Prompt Content: Enhancing LLM Performance via Content...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04295\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ PILAF: Optimal Human Preference Sampling for Reward Modeling...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04270\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Towards Physical Understanding in Video Generation: A 3D Poi...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.03639\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ ChartCitor: Multi-Agent Framework for Fine-Grained Chart Vis...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.00989\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Learning Real-World Action-Video Dynamics with Heterogeneous...\n         ‚úì Full abstract: 133 words\n      üìñ PlotGen: Multi-Agent LLM-based Scientific Data Visualization...\n         ‚úì Full abstract: 194 words\n      Progress: 20/22 papers processed\n      üìñ Enhancing Code Generation for Low-Resource Languages: No Sil...\n         ‚úì Full abstract: 436 words\n      üìñ Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simp...\n         ‚úì Full abstract: 178 words\n‚úì 2025-02-08: 5 papers\n      üìñ Analyze Feature Flow to Enhance Interpretation and Steering ...\n         ‚úì Full abstract: 130 words\n      üìñ Gold-medalist Performance in Solving Olympiad Geometry with\n...\n         ‚úì Full abstract: 194 words\n      üìñ ConceptAttention: Diffusion Transformers Learn Highly Interp...\n         ‚úì Full abstract: 151 words\n      üìñ Great Models Think Alike and this Undermines AI Oversight...\n         ‚úì Full abstract: 176 words\n      üìñ Ola: Pushing the Frontiers of Omni-Modal Language Model with...\n         ‚úì Full abstract: 227 words\n      Progress: 5/22 papers processed\n      üìñ DynVFX: Augmenting Real Videos with Dynamic Content...\n         ‚úì Full abstract: 186 words\n      üìñ Llasa: Scaling Train-Time and Inference-Time Compute for Lla...\n         ‚úì Full abstract: 208 words\n      üìñ BOLT: Bootstrap Long Chain-of-Thought in Language Models wit...\n         ‚úì Full abstract: 245 words\n      üìñ UltraIF: Advancing Instruction Following from the Wild...\n         ‚úì Full abstract: 185 words\n      üìñ Weak-to-Strong Diffusion with Reflection...\n         ‚úì Full abstract: 229 words\n      Progress: 10/22 papers processed\n      üìñ MAGA: MAssive Genre-Audience Reformulation to Pretraining Co...\n         ‚úì Full abstract: 166 words\n      üìñ ScoreFlow: Mastering LLM Agent Workflows via Score-based Pre...\n         ‚úì Full abstract: 131 words\n      üìñ MotionLab: Unified Human Motion Generation and Editing via t...\n         ‚úì Full abstract: 225 words\n      üìñ MotionCanvas: Cinematic Shot Design with Controllable Image-...\n         ‚úì Full abstract: 215 words\n      üìñ Beyond Prompt Content: Enhancing LLM Performance via Content...\n         ‚úì Full abstract: 138 words\n      Progress: 15/22 papers processed\n      üìñ PILAF: Optimal Human Preference Sampling for Reward Modeling...\n         ‚úì Full abstract: 129 words\n      üìñ Towards Physical Understanding in Video Generation: A 3D Poi...\n         ‚úì Full abstract: 176 words\n      üìñ ChartCitor: Multi-Agent Framework for Fine-Grained Chart Vis...\n         ‚úì Full abstract: 126 words\n      üìñ Learning Real-World Action-Video Dynamics with Heterogeneous...\n         ‚úì Full abstract: 133 words\n      üìñ PlotGen: Multi-Agent LLM-based Scientific Data Visualization...\n         ‚úì Full abstract: 194 words\n      Progress: 20/22 papers processed\n      üìñ Enhancing Code Generation for Low-Resource Languages: No Sil...\n         ‚úì Full abstract: 436 words\n      üìñ Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simp...\n         ‚úì Full abstract: 178 words\n‚úì 2025-02-09: 22 papers\n      üìñ Scaling up Test-Time Compute with Latent Reasoning: A Recurr...\n         ‚úì Full abstract: 126 words\n      üìñ Goku: Flow Based Video Generative Foundation Models...\n         ‚úì Full abstract: 110 words\n      üìñ VideoRoPE: What Makes for Good Video Rotary Position Embeddi...\n         ‚úì Full abstract: 184 words\n      üìñ Fast Video Generation with Sliding Tile Attention...\n         ‚úì Full abstract: 175 words\n      üìñ QuEST: Stable Training of LLMs with 1-Bit Weights and Activa...\n         ‚úì Full abstract: 241 words\n      Progress: 5/27 papers processed\n      üìñ AuraFusion360: Augmented Unseen Region Alignment for Referen...\n         ‚úì Full abstract: 138 words\n      üìñ Step Back to Leap Forward: Self-Backtracking for Boosting Re...\n         ‚úì Full abstract: 176 words\n      üìñ FlashVideo:Flowing Fidelity to Detail for Efficient High-Res...\n         ‚úì Full abstract: 184 words\n      üìñ DuoGuard: A Two-Player RL-Driven Framework for Multilingual ...\n         ‚úì Full abstract: 216 words\n      üìñ Agency Is Frame-Dependent...\n         ‚úì Full abstract: 146 words\n      Progress: 10/27 papers processed\n      üìñ Generating Symbolic World Models via Test-time Scaling of La...\n         ‚úì Full abstract: 237 words\n      üìñ CMoE: Fast Carving of Mixture-of-Experts for Efficient LLM I...\n         ‚úì Full abstract: 159 words\n      üìñ On-device Sora: Enabling Diffusion-Based Text-to-Video Gener...\n         ‚úì Full abstract: 220 words\n      üìñ No Task Left Behind: Isotropic Model Merging with Common and...\n         ‚úì Full abstract: 160 words\n      üìñ Linear Correlation in LM's Compositional Generalization and\n...\n         ‚úì Full abstract: 160 words\n      Progress: 15/27 papers processed\n      üìñ Scaling Laws in Patchification: An Image Is Worth 50,176 Tok...\n         ‚úì Full abstract: 219 words\n      üìñ CodeSteer: Symbolic-Augmented Language Models via Code/Text ...\n         ‚úì Full abstract: 182 words\n      üìñ QLIP: Text-Aligned Visual Tokenization Unifies Auto-Regressi...\n         ‚úì Full abstract: 139 words\n      üìñ Lost in Time: Clock and Calendar Understanding Challenges in...\n         ‚úì Full abstract: 148 words\n      üìñ ARR: Question Answering with Large Language Models via Analy...\n         ‚úì Full abstract: 141 words\n      Progress: 20/27 papers processed\n      üìñ Value-Based Deep RL Scales Predictably...\n         ‚úì Full abstract: 200 words\n      üìñ YINYANG-ALIGN: Benchmarking Contradictory Objectives and Pro...\n         ‚úì Full abstract: 162 words\n      üìñ Continuous 3D Perception Model with Persistent State...\n         ‚úì Full abstract: 173 words\n      üìñ Adaptive Semantic Prompt Caching with VectorQ...\n         ‚úì Full abstract: 137 words\n      üìñ MEETING DELEGATE: Benchmarking LLMs on Attending Meetings on...\n         ‚úì Full abstract: 189 words\n      Progress: 25/27 papers processed\n      üìñ SPARC: Subspace-Aware Prompt Adaptation for Robust Continual...\n         ‚úì Full abstract: 182 words\n      üìñ Intelligent Sensing-to-Action for Robust Autonomy at the Edg...\n         ‚úì Full abstract: 232 words\n‚úì 2025-02-10: 27 papers\n      üìñ Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test...\n         ‚úì Full abstract: 234 words\n      üìñ SynthDetoxM: Modern LLMs are Few-Shot Parallel Detoxificatio...\n         ‚úì Full abstract: 133 words\n      üìñ Exploring the Limit of Outcome Reward for Learning Mathemati...\n         ‚úì Full abstract: 259 words\n      üìñ The Curse of Depth in Large Language Models...\n         ‚úì Full abstract: 225 words\n      üìñ Training Language Models for Social Deduction with Multi-Age...\n         ‚úì Full abstract: 228 words\n      Progress: 5/26 papers processed\n      üìñ Matryoshka Quantization...\n         ‚úì Full abstract: 207 words\n      üìñ LM2: Large Memory Models...\n         ‚úì Full abstract: 186 words\n      üìñ CODESIM: Multi-Agent Code Generation and Problem Solving thr...\n         ‚úì Full abstract: 179 words\n      üìñ ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought T...\n         ‚úì Full abstract: 181 words\n      üìñ Show-o Turbo: Towards Accelerated Unified Multimodal Underst...\n         ‚úì Full abstract: 186 words\n      Progress: 10/26 papers processed\n      üìñ Lossless Acceleration of Large Language Models with Hierarch...\n         ‚úì Full abstract: 157 words\n      üìñ MetaChain: A Fully-Automated and Zero-Code Framework for LLM...\n         ‚úì Full abstract: 219 words\n      üìñ Lumina-Video: Efficient and Flexible Video Generation with M...\n         ‚úì Full abstract: 176 words\n      üìñ EVEv2: Improved Baselines for Encoder-Free Vision-Language M...\n         ‚úì Full abstract: 152 words\n      üìñ History-Guided Video Diffusion...\n         ‚úì Full abstract: 184 words\n      Progress: 15/26 papers processed\n      üìñ The Hidden Life of Tokens: Reducing Hallucination of Large\n ...\n         ‚úì Full abstract: 209 words\n      üìñ CustomVideoX: 3D Reference Attention Driven Dynamic Adaptati...\n         ‚úì Full abstract: 201 words\n      üìñ Efficient-vDiT: Efficient Video Diffusion Transformers With ...\n         ‚úì Full abstract: 213 words\n      üìñ InSTA: Towards Internet-Scale Training For Agents...\n         ‚úì Full abstract: 176 words\n      üìñ Dual Caption Preference Optimization for Diffusion Models...\n         ‚úì Full abstract: 200 words\n      Progress: 20/26 papers processed\n      üìñ DreamDPO: Aligning Text-to-3D Generation with Human Preferen...\n         ‚úì Full abstract: 142 words\n      üìñ Steel-LLM:From Scratch to Open Source -- A Personal Journey ...\n         ‚úì Full abstract: 158 words\n      üìñ APE: Faster and Longer Context-Augmented Generation via Adap...\n         ‚úì Full abstract: 199 words\n      üìñ Jakiro: Boosting Speculative Decoding with Decoupled Multi-H...\n         ‚úì Full abstract: 171 words\n      üìñ Embodied Red Teaming for Auditing Robotic Foundation Models...\n         ‚úì Full abstract: 153 words\n      Progress: 25/26 papers processed\n      üìñ Forbidden Science: Dual-Use AI Challenge Benchmark and Scien...\n         ‚úì Full abstract: 178 words\n‚úì 2025-02-11: 26 papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 120 days, 1063 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n      üìñ Expect the Unexpected: FailSafe Long Context QA for Finance...\n         ‚úì Full abstract: 212 words\n      üìñ Competitive Programming with Large Reasoning Models...\n         ‚úì Full abstract: 195 words\n      üìñ CodeI/O: Condensing Reasoning Patterns via Code Input-Output...\n         ‚úì Full abstract: 186 words\n      üìñ Retrieval-augmented Large Language Models for Financial Time...\n         ‚úì Full abstract: 181 words\n      üìñ LLMs Can Easily Learn to Reason from Demonstrations Structur...\n         ‚úì Full abstract: 239 words\n      Progress: 5/26 papers processed\n      üìñ Magic 1-For-1: Generating One Minute Video Clips within One ...\n         ‚úì Full abstract: 220 words\n      üìñ Scaling Pre-training to One Hundred Billion Data for Vision ...\n         ‚úì Full abstract: 147 words\n      üìñ Gemstones: A Model Suite for Multi-Faceted Scaling Laws...\n         ‚úì Full abstract: 154 words\n      üìñ Teaching Language Models to Critique via Reinforcement Learn...\n         ‚úì Full abstract: 134 words\n      üìñ Enhance-A-Video: Better Generated Video for Free...\n         ‚úì Full abstract: 103 words\n      Progress: 10/26 papers processed\n      üìñ NatureLM: Deciphering the Language of Nature for Scientific ...\n         ‚úì Full abstract: 219 words\n      üìñ Hephaestus: Improving Fundamental Agent Capabilities of Larg...\n         ‚úì Full abstract: 151 words\n      üìñ VidCRAFT3: Camera, Object, and Lighting Control for Image-to...\n         ‚úì Full abstract: 202 words\n      üìñ Pippo: High-Resolution Multi-View Humans from a Single Image...\n         ‚úì Full abstract: 174 words\n      üìñ Forget What You Know about LLMs Evaluations - LLMs are Like ...\n         ‚úì Full abstract: 201 words\n      Progress: 15/26 papers processed\n      üìñ Hypencoder: Hypernetworks for Information Retrieval...\n         ‚úì Full abstract: 228 words\n      üìñ √âclair -- Extracting Content and Layout with Integrated Read...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04223\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Goedel-Prover: A Frontier Model for Open-Source Automated Th...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.07640\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ CoS: Chain-of-Shot Prompting for Long Video Understanding...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.06428\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Mask-Enhanced Autoregressive Prediction: Pay Less Attention ...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.07490\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ CAD-Editor: A Locate-then-Infill Framework with Automated Tr...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.03997\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Sparse Autoencoders for Scientifically Rigorous Interpretati...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.06755\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Auditing Prompt Caching in Language Model APIs...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.07776\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Skill Expansion and Composition in Parameter Space...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.05932\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ FocalCodec: Low-Bitrate Speech Coding via Focal Modulation N...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.04465\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Learning Conformal Abstention Policies for Adaptive Risk Man...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.06884\n         ‚ö†Ô∏è Detail page failed, using preview\n‚úì 2025-02-12: 16 papers\n   ‚ùå Request error for 2025-02-13: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-02-13\n‚óã 2025-02-13: no papers\n   ‚ùå Request error for 2025-02-14: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-02-14\n‚óã 2025-02-14: no papers\n   ‚ùå Request error for 2025-02-15: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-02-15\n‚óã 2025-02-15: no papers\n   ‚ùå Request error for 2025-02-16: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-02-16\n‚óã 2025-02-16: no papers\n      üìñ Large Language Diffusion Models...\n         ‚úì Full abstract: 157 words\n      üìñ The Danger of Overthinking: Examining the Reasoning-Action D...\n         ‚úì Full abstract: 189 words\n      üìñ Step-Video-T2V Technical Report: The Practice, Challenges, a...\n         ‚úì Full abstract: 203 words\n      üìñ Region-Adaptive Sampling for Diffusion Transformers...\n         ‚úì Full abstract: 233 words\n      üìñ ZeroBench: An Impossible Visual Benchmark for Contemporary L...\n         ‚úì Full abstract: 125 words\n      Progress: 5/23 papers processed\n      üìñ MM-RLHF: The Next Step Forward in Multimodal LLM Alignment...\n         ‚úì Full abstract: 249 words\n      üìñ ImageRAG: Dynamic Image Retrieval for Reference-Guided Image...\n         ‚úì Full abstract: 135 words\n      üìñ Diverse Inference and Verification for Advanced Reasoning...\n         ‚úì Full abstract: 193 words\n      üìñ DarwinLM: Evolutionary Structured Pruning of Large Language ...\n         ‚úì Full abstract: 182 words\n      üìñ FoNE: Precise Single-Token Number Embeddings via Fourier Fea...\n         ‚úì Full abstract: 195 words\n      Progress: 10/23 papers processed\n      üìñ Precise Parameter Localization for Textual Generation in Dif...\n         ‚úì Full abstract: 204 words\n      üìñ We Can't Understand AI Using our Existing Vocabulary...\n         ‚úì Full abstract: 187 words\n      üìñ AdaPTS: Adapting Univariate Foundation Models to Probabilist...\n         ‚úì Full abstract: 164 words\n      üìñ Small Models, Big Impact: Efficient Corpus and Graph-Based A...\n         ‚úì Full abstract: 209 words\n      üìñ Selective Self-to-Supervised Fine-Tuning for Generalization ...\n         ‚úì Full abstract: 205 words\n      Progress: 15/23 papers processed\n      üìñ Text-guided Sparse Voxel Pruning for Efficient 3D Visual Gro...\n         ‚úì Full abstract: 226 words\n      üìñ STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodi...\n         ‚úì Full abstract: 149 words\n      üìñ V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving w...\n         ‚úì Full abstract: 210 words\n      üìñ Cluster and Predict Latents Patches for Improved Masked Imag...\n         ‚úì Full abstract: 112 words\n      üìñ MRS: A Fast Sampler for Mean Reverting Diffusion based on OD...\n         ‚úì Full abstract: 217 words\n      Progress: 20/23 papers processed\n      üìñ Jailbreaking to Jailbreak...\n         ‚úì Full abstract: 191 words\n      üìñ CLaMP 3: Universal Music Information Retrieval Across Unalig...\n         ‚úì Full abstract: 152 words\n      üìñ Agentic End-to-End De Novo Protein Design for Tailored Dynam...\n         ‚úì Full abstract: 216 words\n‚úì 2025-02-17: 23 papers\n      üìñ Native Sparse Attention: Hardware-Aligned and Natively Train...\n         ‚úì Full abstract: 169 words\n      üìñ SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-Worl...\n         ‚úì Full abstract: 129 words\n      üìñ Learning Getting-Up Policies for Real-World Humanoid Robots...\n         ‚úì Full abstract: 223 words\n      üìñ I Think, Therefore I Diffuse: Enabling Multimodal In-Context...\n         ‚úì Full abstract: 197 words\n      üìñ ReLearn: Unlearning via Learning for Large Language Models...\n         ‚úì Full abstract: 130 words\n      Progress: 5/38 papers processed\n      üìñ How Do LLMs Acquire New Knowledge? A Knowledge Circuits Pers...\n         ‚úì Full abstract: 144 words\n      üìñ CRANE: Reasoning with constrained LLM generation...\n         ‚úì Full abstract: 192 words\n      üìñ Intuitive physics understanding emerges from self-supervised...\n         ‚úì Full abstract: 159 words\n      üìñ IHEval: Evaluating Language Models on Following the Instruct...\n         ‚úì Full abstract: 149 words\n      üìñ Sailor2: Sailing in South-East Asia with Inclusive Multiling...\n         ‚úì Full abstract: 127 words\n      Progress: 10/38 papers processed\n      üìñ HermesFlow: Seamlessly Closing the Gap in Multimodal Underst...\n         ‚úì Full abstract: 169 words\n      üìñ Ask in Any Modality: A Comprehensive Survey on Multimodal\n  ...\n         ‚úì Full abstract: 179 words\n      üìñ Diffusion-Sharpening: Fine-tuning Diffusion Models with Deno...\n         ‚úì Full abstract: 131 words\n      üìñ System Message Generation for User Preferences using Open-So...\n         ‚úì Full abstract: 168 words\n      üìñ Talk Structurally, Act Hierarchically: A Collaborative Frame...\n         ‚úì Full abstract: 141 words\n      Progress: 15/38 papers processed\n      üìñ Explorer: Scaling Exploration-driven Web Trajectory Synthesi...\n         ‚úì Full abstract: 205 words\n      üìñ The Mirage of Model Editing: Revisiting Evaluation in the Wi...\n         ‚úì Full abstract: 188 words\n      üìñ SURGE: On the Potential of Large Language Models as General-...\n         ‚úì Full abstract: 188 words\n      üìñ video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Lang...\n         ‚úì Full abstract: 169 words\n      üìñ Diffusion Models without Classifier-free Guidance...\n         ‚úì Full abstract: 121 words\n      Progress: 20/38 papers processed\n      üìñ MagicArticulate: Make Your 3D Models Articulation-Ready...\n         ‚úì Full abstract: 178 words\n      üìñ SAFE-SQL: Self-Augmented In-Context Learning with Fine-grain...\n         ‚úì Full abstract: 137 words\n      üìñ EQ-VAE: Equivariance Regularized Latent Space for Improved G...\n         ‚úì Full abstract: 162 words\n      üìñ PhysReason: A Comprehensive Benchmark towards Physics-Based ...\n         ‚úì Full abstract: 169 words\n      üìñ Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM...\n         ‚úì Full abstract: 143 words\n      Progress: 25/38 papers processed\n      üìñ Dyve: Thinking Fast and Slow for Dynamic Process Verificatio...\n         ‚úì Full abstract: 95 words\n      üìñ One Example Shown, Many Concepts Known! Counterexample-Drive...\n         ‚úì Full abstract: 193 words\n      üìñ Building A Proof-Oriented Programmer That Is 64% Better Than...\n         ‚úì Full abstract: 166 words\n      üìñ Memory, Benchmark & Robots: A Benchmark for Solving Complex ...\n         ‚úì Full abstract: 170 words\n      üìñ Can a Single Model Master Both Multi-turn Conversations and ...\n         ‚úì Full abstract: 180 words\n      Progress: 30/38 papers processed\n      üìñ ILIAS: Instance-Level Image retrieval At Scale...\n         ‚úì Full abstract: 201 words\n      üìñ Show Me the Work: Fact-Checkers' Requirements for Explainabl...\n         ‚úì Full abstract: 149 words\n      üìñ Large Language Models and Mathematical Reasoning Failures...\n         ‚úì Full abstract: 171 words\n      üìñ Towards Data-Efficient Pretraining for Atomic Property Predi...\n         ‚úì Full abstract: 156 words\n      üìñ Better Embeddings with Coupled Adam...\n         ‚úì Full abstract: 75 words\n      Progress: 35/38 papers processed\n      üìñ Data Valuation using Neural Networks for Efficient Instructi...\n         ‚úì Full abstract: 208 words\n      üìñ Language Complexity Measurement as a Noisy Zero-Shot Proxy f...\n         ‚úì Full abstract: 173 words\n      üìñ ExaGPT: Example-Based Machine-Generated Text Detection for H...\n         ‚úì Full abstract: 208 words\n‚úì 2025-02-18: 38 papers\n      üìñ Soundwave: Less is More for Speech-Text Alignment in LLMs...\n         ‚úì Full abstract: 103 words\n      üìñ Cramming 1568 Tokens into a Single Vector and Back Again: Ex...\n         ‚úì Full abstract: 200 words\n      üìñ Phantom: Subject-consistent video generation via cross-modal...\n         ‚úì Full abstract: 137 words\n      üìñ Magma: A Foundation Model for Multimodal AI Agents...\n         ‚úì Full abstract: 228 words\n      üìñ Continuous Diffusion Model for Language Modeling...\n         ‚úì Full abstract: 186 words\n      Progress: 5/32 papers processed\n      üìñ Multimodal Mamba: Decoder-only Multimodal State Space Model ...\n         ‚úì Full abstract: 191 words\n      üìñ Rethinking Diverse Human Preference Learning through Princip...\n         ‚úì Full abstract: 174 words\n      üìñ You Do Not Fully Utilize Transformer's Representation Capaci...\n         ‚úì Full abstract: 137 words\n      üìñ FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcem...\n         ‚úì Full abstract: 126 words\n      üìñ SoFar: Language-Grounded Orientation Bridges Spatial Reasoni...\n         ‚úì Full abstract: 204 words\n      Progress: 10/32 papers processed\n      üìñ SafeRoute: Adaptive Model Selection for Efficient and Accura...\n         ‚úì Full abstract: 150 words\n      üìñ OctoTools: An Agentic Framework with Extensible Tools for Co...\n         ‚úì Full abstract: 160 words\n      üìñ Atom of Thoughts for Markov LLM Test-Time Scaling...\n         ‚úì Full abstract: 236 words\n      üìñ RealSyn: An Effective and Scalable Multimodal Interleaved Do...\n         ‚úì Full abstract: 174 words\n      üìñ Revisiting the Test-Time Scaling of o1-like Models: Do they ...\n         ‚úì Full abstract: 158 words\n      Progress: 15/32 papers processed\n      üìñ PAFT: Prompt-Agnostic Fine-Tuning...\n         ‚úì Full abstract: 147 words\n      üìñ Text2World: Benchmarking Large Language Models for Symbolic ...\n         ‚úì Full abstract: 166 words\n      üìñ HeadInfer: Memory-Efficient LLM Inference by Head-wise Offlo...\n         ‚úì Full abstract: 178 words\n      üìñ YOLOv12: Attention-Centric Real-Time Object Detectors...\n         ‚úì Full abstract: 166 words\n      üìñ MUDDFormer: Breaking Residual Bottlenecks in Transformers vi...\n         ‚úì Full abstract: 151 words\n      Progress: 20/32 papers processed\n      üìñ HealthGPT: A Medical Large Vision-Language Model for Unifyin...\n         ‚úì Full abstract: 111 words\n      üìñ Eager Updates For Overlapped Communication and Computation i...\n         ‚úì Full abstract: 161 words\n      üìñ Flow-of-Options: Diversified and Improved LLM Reasoning by T...\n         ‚úì Full abstract: 163 words\n      üìñ The Hidden Risks of Large Reasoning Models: A Safety Assessm...\n         ‚úì Full abstract: 213 words\n      üìñ Pre-training Auto-regressive Robotic Models with 4D Represen...\n         ‚úì Full abstract: 164 words\n      Progress: 25/32 papers processed\n      üìñ Crowd Comparative Reasoning: Unlocking Comprehensive Evaluat...\n         ‚úì Full abstract: 170 words\n      üìñ FinMTEB: Finance Massive Text Embedding Benchmark...\n         ‚úì Full abstract: 211 words\n      üìñ Injecting Domain-Specific Knowledge into Large Language Mode...\n         ‚úì Full abstract: 188 words\n      üìñ Perovskite-LLM: Knowledge-Enhanced Large Language Models for...\n         ‚úì Full abstract: 145 words\n      üìñ Scaling Autonomous Agents via Automatic Reward Modeling And ...\n         ‚úì Full abstract: 261 words\n      Progress: 30/32 papers processed\n      üìñ Multilingual Encoder Knows more than You Realize: Shared Wei...\n         ‚úì Full abstract: 136 words\n      üìñ Harnessing Vision Models for Time Series Analysis: A Survey...\n         ‚úì Full abstract: 196 words\n‚úì 2025-02-19: 32 papers\n      üìñ Qwen2.5-VL Technical Report...\n         ‚úì Full abstract: 253 words\n      üìñ On the Trustworthiness of Generative Foundation Models: Guid...\n         ‚úì Full abstract: 244 words\n      üìñ MMTEB: Massive Multilingual Text Embedding Benchmark...\n         ‚úì Full abstract: 225 words\n      üìñ SongGen: A Single Stage Auto-regressive Transformer for Text...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13128\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Small Models Struggle to Learn from Strong Reasoners...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.12143\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ RAD: Training an End-to-End Driving Policy via Large-Scale 3...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13144\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ MoM: Linear Sequence Modeling with Mixture-of-Memories...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13685\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Is That Your Final Answer? Test-Time Scaling Improves Select...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13962\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Craw4LLM: Efficient Web Crawling for LLM Pretraining...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13347\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ LongPO: Long Context Self-Evolution of Large Language Models...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13922\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Autellix: An Efficient Serving Engine for LLM Agents as Gene...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13965\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Thinking Preference Optimization...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13173\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ SearchRAG: Can Search Engines Be Helpful for LLM-based Medic...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13233\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Train Small, Infer Large: Memory-Efficient LoRA Training for...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13533\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Presumed Cultural Identity: How Names Shape LLM Responses...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.11995\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Why Safeguarded Ships Run Aground? Aligned Large Language Mo...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13946\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ InfiR : Crafting Effective Small Language Models and Multimo...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.11573\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ AdaptiveStep: Automatically Dividing Reasoning Step through ...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13943\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ AIDE: AI-Driven Exploration in the Space of Code...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13138\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Mol...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.12638\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ TESS 2: A Large-Scale Generalist Diffusion Language Model...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13917\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ REALTALK: A 21-Day Real-World Dataset for Long-Term Conversa...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.13270\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Judging the Judges: A Collection of LLM-Generated Relevance ...\n         ‚úì Full abstract: 241 words\n      üìñ From Tools to Teammates: Evaluating LLMs in Multi-Session Co...\n         ‚úì Full abstract: 131 words\n      üìñ ActionPiece: Contextually Tokenizing Action Sequences for Ge...\n         ‚úì Full abstract: 173 words\n      Progress: 25/32 papers processed\n      üìñ REFIND: Retrieval-Augmented Factuality Hallucination Detecti...\n         ‚úì Full abstract: 141 words\n      üìñ Which of These Best Describes Multiple Choice Evaluation wit...\n         ‚úì Full abstract: 174 words\n      üìñ GIMMICK -- Globally Inclusive Multimodal Multitask Cultural ...\n         ‚úì Full abstract: 222 words\n      üìñ MVL-SIB: A Massively Multilingual Vision-Language Benchmark ...\n         ‚úì Full abstract: 194 words\n      üìñ High-Fidelity Novel View Synthesis via Splatting-Guided Diff...\n         ‚úì Full abstract: 159 words\n      Progress: 30/32 papers processed\n      üìñ Noise May Contain Transferable Knowledge: Understanding Semi...\n         ‚úì Full abstract: 234 words\n      üìñ Reducing Hallucinations in Language Model-based SPARQL Query...\n         ‚úì Full abstract: 160 words\n‚úì 2025-02-20: 13 papers\n      üìñ MLGym: A New Framework and Benchmark for Advancing AI Resear...\n         ‚úì Full abstract: 227 words\n      üìñ SigLIP 2: Multilingual Vision-Language Encoders with Improve...\n         ‚úì Full abstract: 203 words\n      üìñ SuperGPQA: Scaling LLM Evaluation across 285 Graduate Discip...\n         ‚úì Full abstract: 182 words\n      üìñ How Much Knowledge Can You Pack into a LoRA Adapter without ...\n         ‚úì Full abstract: 193 words\n      üìñ S*: Test Time Scaling for Code Generation...\n         ‚úì Full abstract: 159 words\n      Progress: 5/29 papers processed\n      üìñ Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforce...\n         ‚úì Full abstract: 130 words\n      üìñ Discovering highly efficient low-weight quantum error-correc...\n         ‚úì Full abstract: 229 words\n      üìñ PC-Agent: A Hierarchical Multi-Agent Collaboration Framework...\n         ‚úì Full abstract: 175 words\n      üìñ S^2R: Teaching LLMs to Self-verify and Self-correct via Rein...\n         ‚úì Full abstract: 176 words\n      üìñ Does Time Have Its Place? Temporal Heads: Where Language Mod...\n         ‚úì Full abstract: 145 words\n      Progress: 10/29 papers processed\n      üìñ LongWriter-V: Enabling Ultra-Long and High-Fidelity Generati...\n         ‚úì Full abstract: 176 words\n      üìñ How to Get Your LLM to Generate Challenging Problems for Eva...\n         ‚úì Full abstract: 152 words\n      üìñ Dynamic Concepts Personalization from Single Videos...\n         ‚úì Full abstract: 183 words\n      üìñ Scaling Text-Rich Image Understanding via Code-Guided Synthe...\n         ‚úì Full abstract: 194 words\n      üìñ AlphaMaze: Enhancing Large Language Models' Spatial Intellig...\n         ‚úì Full abstract: 180 words\n      Progress: 15/29 papers processed\n      üìñ LServe: Efficient Long-sequence LLM Serving with Unified Spa...\n         ‚úì Full abstract: 199 words\n      üìñ From RAG to Memory: Non-Parametric Continual Learning for La...\n         ‚úì Full abstract: 211 words\n      üìñ RelaCtrl: Relevance-Guided Efficient Control for Diffusion T...\n         ‚úì Full abstract: 219 words\n      üìñ CLIPPER: Compression enables long-context synthetic data gen...\n         ‚úì Full abstract: 191 words\n      üìñ NAVIG: Natural Language-guided Analysis with Vision Language...\n         ‚úì Full abstract: 121 words\n      Progress: 20/29 papers processed\n      üìñ Enhancing Cognition and Explainability of Multimodal Foundat...\n         ‚úì Full abstract: 159 words\n      üìñ Multimodal RewardBench: Holistic Evaluation of Reward Models...\n         ‚úì Full abstract: 149 words\n      üìñ Generating Skyline Datasets for Data Science Models...\n         ‚úì Full abstract: 179 words\n      üìñ LLM-based User Profile Management for Recommender System...\n         ‚úì Full abstract: 162 words\n      üìñ Generating œÄ-Functional Molecules Using STGG+ with Active Le...\n         ‚úì Full abstract: 195 words\n      Progress: 25/29 papers processed\n      üìñ Symmetrical Visual Contrastive Optimization: Aligning Vision...\n         ‚úì Full abstract: 198 words\n      üìñ Geolocation with Real Human Gameplay Data: A Large-Scale Dat...\n         ‚úì Full abstract: 259 words\n      üìñ Unstructured Evidence Attribution for Long Context Query Foc...\n         ‚úì Full abstract: 203 words\n      üìñ How Much Do LLMs Hallucinate across Languages? On Multilingu...\n         ‚úì Full abstract: 239 words\n‚úì 2025-02-21: 29 papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 130 days, 1214 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n      üìñ MLGym: A New Framework and Benchmark for Advancing AI Resear...\n         ‚úì Full abstract: 227 words\n      üìñ SigLIP 2: Multilingual Vision-Language Encoders with Improve...\n         ‚úì Full abstract: 203 words\n      üìñ SuperGPQA: Scaling LLM Evaluation across 285 Graduate Discip...\n         ‚úì Full abstract: 182 words\n      üìñ How Much Knowledge Can You Pack into a LoRA Adapter without ...\n         ‚úì Full abstract: 193 words\n      üìñ S*: Test Time Scaling for Code Generation...\n         ‚úì Full abstract: 159 words\n      Progress: 5/29 papers processed\n      üìñ Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforce...\n         ‚úì Full abstract: 130 words\n      üìñ Discovering highly efficient low-weight quantum error-correc...\n         ‚úì Full abstract: 229 words\n      üìñ PC-Agent: A Hierarchical Multi-Agent Collaboration Framework...\n         ‚úì Full abstract: 175 words\n      üìñ S^2R: Teaching LLMs to Self-verify and Self-correct via Rein...\n         ‚úì Full abstract: 176 words\n      üìñ Does Time Have Its Place? Temporal Heads: Where Language Mod...\n         ‚úì Full abstract: 145 words\n      Progress: 10/29 papers processed\n      üìñ LongWriter-V: Enabling Ultra-Long and High-Fidelity Generati...\n         ‚úì Full abstract: 176 words\n      üìñ How to Get Your LLM to Generate Challenging Problems for Eva...\n         ‚úì Full abstract: 152 words\n      üìñ Dynamic Concepts Personalization from Single Videos...\n         ‚úì Full abstract: 183 words\n      üìñ Scaling Text-Rich Image Understanding via Code-Guided Synthe...\n         ‚úì Full abstract: 194 words\n      üìñ AlphaMaze: Enhancing Large Language Models' Spatial Intellig...\n         ‚úì Full abstract: 180 words\n      Progress: 15/29 papers processed\n      üìñ LServe: Efficient Long-sequence LLM Serving with Unified Spa...\n         ‚úì Full abstract: 199 words\n      üìñ From RAG to Memory: Non-Parametric Continual Learning for La...\n         ‚úì Full abstract: 211 words\n      üìñ RelaCtrl: Relevance-Guided Efficient Control for Diffusion T...\n         ‚úì Full abstract: 219 words\n      üìñ CLIPPER: Compression enables long-context synthetic data gen...\n         ‚úì Full abstract: 191 words\n      üìñ NAVIG: Natural Language-guided Analysis with Vision Language...\n         ‚úì Full abstract: 121 words\n      Progress: 20/29 papers processed\n      üìñ Enhancing Cognition and Explainability of Multimodal Foundat...\n         ‚úì Full abstract: 159 words\n      üìñ Multimodal RewardBench: Holistic Evaluation of Reward Models...\n         ‚úì Full abstract: 149 words\n      üìñ Generating Skyline Datasets for Data Science Models...\n         ‚úì Full abstract: 179 words\n      üìñ LLM-based User Profile Management for Recommender System...\n         ‚úì Full abstract: 162 words\n      üìñ Generating œÄ-Functional Molecules Using STGG+ with Active Le...\n         ‚úì Full abstract: 195 words\n      Progress: 25/29 papers processed\n      üìñ Symmetrical Visual Contrastive Optimization: Aligning Vision...\n         ‚úì Full abstract: 198 words\n      üìñ Geolocation with Real Human Gameplay Data: A Large-Scale Dat...\n         ‚úì Full abstract: 259 words\n      üìñ Unstructured Evidence Attribution for Long Context Query Foc...\n         ‚úì Full abstract: 203 words\n      üìñ How Much Do LLMs Hallucinate across Languages? On Multilingu...\n         ‚úì Full abstract: 239 words\n‚úì 2025-02-22: 29 papers\n      üìñ MLGym: A New Framework and Benchmark for Advancing AI Resear...\n         ‚úì Full abstract: 227 words\n      üìñ SigLIP 2: Multilingual Vision-Language Encoders with Improve...\n         ‚úì Full abstract: 203 words\n      üìñ SuperGPQA: Scaling LLM Evaluation across 285 Graduate Discip...\n         ‚úì Full abstract: 182 words\n      üìñ How Much Knowledge Can You Pack into a LoRA Adapter without ...\n         ‚úì Full abstract: 193 words\n      üìñ S*: Test Time Scaling for Code Generation...\n         ‚úì Full abstract: 159 words\n      Progress: 5/29 papers processed\n      üìñ Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforce...\n         ‚úì Full abstract: 130 words\n      üìñ Discovering highly efficient low-weight quantum error-correc...\n         ‚úì Full abstract: 229 words\n      üìñ PC-Agent: A Hierarchical Multi-Agent Collaboration Framework...\n         ‚úì Full abstract: 175 words\n      üìñ S^2R: Teaching LLMs to Self-verify and Self-correct via Rein...\n         ‚úì Full abstract: 176 words\n      üìñ Does Time Have Its Place? Temporal Heads: Where Language Mod...\n         ‚úì Full abstract: 145 words\n      Progress: 10/29 papers processed\n      üìñ LongWriter-V: Enabling Ultra-Long and High-Fidelity Generati...\n         ‚úì Full abstract: 176 words\n      üìñ How to Get Your LLM to Generate Challenging Problems for Eva...\n         ‚úì Full abstract: 152 words\n      üìñ Dynamic Concepts Personalization from Single Videos...\n         ‚úì Full abstract: 183 words\n      üìñ Scaling Text-Rich Image Understanding via Code-Guided Synthe...\n         ‚úì Full abstract: 194 words\n      üìñ AlphaMaze: Enhancing Large Language Models' Spatial Intellig...\n         ‚úì Full abstract: 180 words\n      Progress: 15/29 papers processed\n      üìñ LServe: Efficient Long-sequence LLM Serving with Unified Spa...\n         ‚úì Full abstract: 199 words\n      üìñ From RAG to Memory: Non-Parametric Continual Learning for La...\n         ‚úì Full abstract: 211 words\n      üìñ RelaCtrl: Relevance-Guided Efficient Control for Diffusion T...\n         ‚úì Full abstract: 219 words\n      üìñ CLIPPER: Compression enables long-context synthetic data gen...\n         ‚úì Full abstract: 191 words\n      üìñ NAVIG: Natural Language-guided Analysis with Vision Language...\n         ‚úì Full abstract: 121 words\n      Progress: 20/29 papers processed\n      üìñ Enhancing Cognition and Explainability of Multimodal Foundat...\n         ‚úì Full abstract: 159 words\n      üìñ Multimodal RewardBench: Holistic Evaluation of Reward Models...\n         ‚úì Full abstract: 149 words\n      üìñ Generating Skyline Datasets for Data Science Models...\n         ‚úì Full abstract: 179 words\n      üìñ LLM-based User Profile Management for Recommender System...\n         ‚úì Full abstract: 162 words\n      üìñ Generating œÄ-Functional Molecules Using STGG+ with Active Le...\n         ‚úì Full abstract: 195 words\n      Progress: 25/29 papers processed\n      üìñ Symmetrical Visual Contrastive Optimization: Aligning Vision...\n         ‚úì Full abstract: 198 words\n      üìñ Geolocation with Real Human Gameplay Data: A Large-Scale Dat...\n         ‚úì Full abstract: 259 words\n      üìñ Unstructured Evidence Attribution for Long Context Query Foc...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.14409\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ How Much Do LLMs Hallucinate across Languages? On Multilingu...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2502.12769\n         ‚ö†Ô∏è Detail page failed, using preview\n‚úì 2025-02-23: 27 papers\n   ‚ùå Request error for 2025-02-24: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-02-24\n‚óã 2025-02-24: no papers\n   ‚ùå Request error for 2025-02-25: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-02-25\n‚óã 2025-02-25: no papers\n   ‚ùå Request error for 2025-02-26: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-02-26\n‚óã 2025-02-26: no papers\n   ‚ùå Request error for 2025-02-27: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-02-27\n‚óã 2025-02-27: no papers\n   ‚ùå Request error for 2025-02-28: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-02-28\n‚óã 2025-02-28: no papers\n   ‚ùå Request error for 2025-03-01: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-03-01\n‚óã 2025-03-01: no papers\n   ‚ùå Request error for 2025-03-02: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-03-02\n‚óã 2025-03-02: no papers\n   ‚ùå Request error for 2025-03-03: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-03-03\n‚óã 2025-03-03: no papers\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nüìä Progress: 140 days, 1270 papers total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n   ‚ùå Request error for 2025-03-04: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/date/2025-03-04\n‚óã 2025-03-04: no papers\n      üìñ MultiAgentBench: Evaluating the Collaboration and Competitio...\n         ‚úì Full abstract: 146 words\n      üìñ SemViQA: A Semantic Question Answering System for Vietnamese...\n         ‚úì Full abstract: 126 words\n      üìñ MPO: Boosting LLM Agents with Meta Plan Optimization...\n         ‚úì Full abstract: 143 words\n      üìñ LADDER: Self-Improving LLMs Through Recursive Problem Decomp...\n         ‚úì Full abstract: 166 words\n      üìñ Wikipedia in the Era of LLMs: Evolution and Risks...\n         ‚úì Full abstract: 173 words\n      Progress: 5/26 papers processed\n      üìñ Mask-DPO: Generalizable Fine-grained Factuality Alignment of...\n         ‚úì Full abstract: 252 words\n      üìñ Societal Alignment Frameworks Can Improve LLM Alignment...\n         ‚úì Full abstract: 180 words\n      üìñ DoraCycle: Domain-Oriented Adaptation of Unified Generative ...\n         ‚úì Full abstract: 182 words\n      üìñ PipeOffload: Improving Scalability of Pipeline Parallelism w...\n         ‚úì Full abstract: 163 words\n      üìñ Iterative Value Function Optimization for Guided Decoding...\n         ‚úì Full abstract: 171 words\n      Progress: 10/26 papers processed\n      üìñ Unified Video Action Model...\n         ‚úì Full abstract: 234 words\n      üìñ RectifiedHR: Enable Efficient High-Resolution Image Generati...\n         ‚úì Full abstract: 161 words\n      üìñ AppAgentX: Evolving GUI Agents as Proficient Smartphone User...\n         ‚úì Full abstract: 182 words\n      üìñ Language Models can Self-Improve at State-Value Estimation f...\n         ‚úì Full abstract: 112 words\n      üìñ Q-Filters: Leveraging QK Geometry for Efficient KV Cache Com...\n         ‚úì Full abstract: 179 words\n      Progress: 15/26 papers processed\n      üìñ ATLaS: Agent Tuning via Learning Critical Steps...\n         ‚úì Full abstract: 178 words\n      üìñ UFO: A Unified Approach to Fine-grained Visual Perception vi...\n         ‚úì Full abstract: 216 words\n      üìñ FR-Spec: Accelerating Large-Vocabulary Language Models via\n ...\n         ‚úì Full abstract: 140 words\n      üìñ Q-Eval-100K: Evaluating Visual Quality and Alignment Level f...\n         ‚úì Full abstract: 197 words\n      üìñ IterPref: Focal Preference Learning for Code Generation via ...\n         ‚úì Full abstract: 183 words\n      Progress: 20/26 papers processed\n      üìñ Improve Representation for Imbalanced Regression through Geo...\n         ‚úì Full abstract: 171 words\n      üìñ SPIDER: A Comprehensive Multi-Organ Supervised Pathology Dat...\n         ‚úì Full abstract: 168 words\n      üìñ A Token-level Text Image Foundation Model for Document Under...\n         ‚úì Full abstract: 168 words\n      üìñ Tabby: Tabular Data Synthesis with Language Models...\n         ‚úì Full abstract: 134 words\n      üìñ A Multimodal Symphony: Integrating Taste and Sound through G...\n         ‚úì Full abstract: 148 words\n      Progress: 25/26 papers processed\n      üìñ Discrete-Time Hybrid Automata Learning: Legged Locomotion Me...\n         ‚úì Full abstract: 128 words\n‚úì 2025-03-05: 26 papers\n      üìñ Babel: Open Multilingual Large Language Models Serving Over ...\n         ‚úì Full abstract: 178 words\n      üìñ HoT: Highlighted Chain of Thought for Referencing Supporting...\n         ‚úì Full abstract: 166 words\n      üìñ Process-based Self-Rewarding Language Models...\n         ‚úì Full abstract: 139 words\n      üìñ KodCode: A Diverse, Challenging, and Verifiable Synthetic Da...\n         ‚úì Full abstract: 183 words\n      üìñ GEN3C: 3D-Informed World-Consistent Video Generation with Pr...\n         ‚úì Full abstract: 217 words\n      Progress: 5/21 papers processed\n      üìñ ABC: Achieving Better Control of Multimodal Embeddings using...\n         ‚úì Full abstract: 191 words\n      üìñ Enhancing Abnormality Grounding for Vision Language Models w...\n         ‚úì Full abstract: 193 words\n      üìñ CrowdSelect: Synthetic Instruction Data Selection with Multi...\n         ‚úì Full abstract: 175 words\n      üìñ Fine-Tuning Small Language Models for Domain-Specific AI: An...\n         ‚úì Full abstract: 121 words\n      üìñ Remasking Discrete Diffusion Models with Inference-Time Scal...\n         ‚úì Full abstract: 194 words\n      Progress: 10/21 papers processed\n      üìñ Mixture of Structural-and-Textual Retrieval over Text-rich G...\n         ‚úì Full abstract: 169 words\n      üìñ QE4PE: Word-level Quality Estimation for Human Post-Editing...\n         ‚úì Full abstract: 152 words\n      üìñ Exploring Rewriting Approaches for Different Conversational ...\n         ‚úì Full abstract: 199 words\n      üìñ FLAME: A Federated Learning Benchmark for Robotic Manipulati...\n         ‚úì Full abstract: 145 words\n      üìñ CognitiveDrone: A VLA Model and Evaluation Benchmark for Rea...\n         ‚úì Full abstract: 179 words\n      Progress: 15/21 papers processed\n      üìñ Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrie...\n         ‚úì Full abstract: 175 words\n      üìñ Benchmarking Large Language Models for Multi-Language Softwa...\n         ‚úì Full abstract: 248 words\n      üìñ Reliable and Efficient Multi-Agent Coordination via Graph Ne...\n         ‚úì Full abstract: 220 words\n      üìñ Diverse Controllable Diffusion Policy with Signal Temporal L...\n         ‚úì Full abstract: 214 words\n      üìñ SwiLTra-Bench: The Swiss Legal Translation Benchmark...\n         ‚úì Full abstract: 159 words\n      Progress: 20/21 papers processed\n      üìñ Interact, Instruct to Improve: A LLM-Driven Parallel Actor-R...\n         ‚úì Full abstract: 185 words\n‚úì 2025-03-06: 21 papers\n      üìñ START: Self-taught Reasoner with Tools...\n         ‚úì Full abstract: 270 words\n      üìñ Token-Efficient Long Video Understanding for Multimodal LLMs...\n         ‚úì Full abstract: 221 words\n      üìñ LLMVoX: Autoregressive Streaming Text-to-Speech Model for An...\n         ‚úì Full abstract: 195 words\n      üìñ EgoLife: Towards Egocentric Life Assistant...\n         ‚úì Full abstract: 235 words\n      üìñ LLM as a Broken Telephone: Iterative Generation Distorts Inf...\n         ‚úì Full abstract: 97 words\n      Progress: 5/21 papers processed\n      üìñ Audio Flamingo 2: An Audio-Language Model with Long-Audio Un...\n         ‚úì Full abstract: 165 words\n      üìñ LINGOLY-TOO: Disentangling Memorisation from Reasoning with ...\n         ‚úì Full abstract: 174 words\n      üìñ L^2M: Mutual Information Scaling Law for Long-Context Langua...\n         ‚úì Full abstract: 110 words\n      üìñ IFIR: A Comprehensive Benchmark for Evaluating Instruction-F...\n         ‚úì Full abstract: 140 words\n      üìñ HybridNorm: Towards Stable and Efficient Transformer Trainin...\n         ‚úì Full abstract: 183 words\n      Progress: 10/21 papers processed\n      üìñ FuseChat-3.0: Preference Optimization Meets Heterogeneous Mo...\n         ‚úì Full abstract: 196 words\n      üìñ Pok√©Champ: an Expert-level Minimax Language Agent...\n         ‚úì Full abstract: 255 words\n      üìñ How to Steer LLM Latents for Hallucination Detection?...\n         ‚úì Full abstract: 153 words\n      üìñ The Best of Both Worlds: Integrating Language Models and Dif...\n         ‚úì Full abstract: 179 words\n      üìñ Union of Experts: Adapting Hierarchical Routing to Equivalen...\n         ‚úì Full abstract: 194 words\n      Progress: 15/21 papers processed\n      üìñ Identifying Sensitive Weights via Post-quantization Integral...\n         ‚úì Full abstract: 202 words\n      üìñ Dedicated Feedback and Edit Models Empower Inference-Time Sc...\n         ‚úì Full abstract: 202 words\n      üìñ Lost in Literalism: How Supervised Training Shapes Translati...\n         ‚úì Full abstract: 156 words\n      üìñ Combining Flow Matching and Transformers for Efficient Solut...\n         ‚úì Full abstract: 74 words\n      üìñ On the Acquisition of Shared Grammatical Representations in ...\n         ‚úì Full abstract: 158 words\n      Progress: 20/21 papers processed\n      üìñ Understanding and Predicting Derailment in Toxic Conversatio...\n         ‚úì Full abstract: 206 words\n‚úì 2025-03-07: 21 papers\n      üìñ START: Self-taught Reasoner with Tools...\n         ‚úì Full abstract: 270 words\n      üìñ Token-Efficient Long Video Understanding for Multimodal LLMs...\n         ‚úì Full abstract: 221 words\n      üìñ LLMVoX: Autoregressive Streaming Text-to-Speech Model for An...\n         ‚úì Full abstract: 195 words\n      üìñ EgoLife: Towards Egocentric Life Assistant...\n         ‚úì Full abstract: 235 words\n      üìñ LLM as a Broken Telephone: Iterative Generation Distorts Inf...\n         ‚úì Full abstract: 97 words\n      Progress: 5/21 papers processed\n      üìñ Audio Flamingo 2: An Audio-Language Model with Long-Audio Un...\n         ‚úì Full abstract: 165 words\n      üìñ LINGOLY-TOO: Disentangling Memorisation from Reasoning with ...\n         ‚úì Full abstract: 174 words\n      üìñ L^2M: Mutual Information Scaling Law for Long-Context Langua...\n         ‚úì Full abstract: 110 words\n      üìñ IFIR: A Comprehensive Benchmark for Evaluating Instruction-F...\n         ‚úì Full abstract: 140 words\n      üìñ HybridNorm: Towards Stable and Efficient Transformer Trainin...\n         ‚úì Full abstract: 183 words\n      Progress: 10/21 papers processed\n      üìñ FuseChat-3.0: Preference Optimization Meets Heterogeneous Mo...\n         ‚úì Full abstract: 196 words\n      üìñ Pok√©Champ: an Expert-level Minimax Language Agent...\n         ‚úì Full abstract: 255 words\n      üìñ How to Steer LLM Latents for Hallucination Detection?...\n         ‚úì Full abstract: 153 words\n      üìñ The Best of Both Worlds: Integrating Language Models and Dif...\n         ‚úì Full abstract: 179 words\n      üìñ Union of Experts: Adapting Hierarchical Routing to Equivalen...\n         ‚úì Full abstract: 194 words\n      Progress: 15/21 papers processed\n      üìñ Identifying Sensitive Weights via Post-quantization Integral...\n         ‚úì Full abstract: 202 words\n      üìñ Dedicated Feedback and Edit Models Empower Inference-Time Sc...\n         ‚úì Full abstract: 202 words\n      üìñ Lost in Literalism: How Supervised Training Shapes Translati...\n         ‚úì Full abstract: 156 words\n      üìñ Combining Flow Matching and Transformers for Efficient Solut...\n         ‚úì Full abstract: 74 words\n      üìñ On the Acquisition of Shared Grammatical Representations in ...\n         ‚úì Full abstract: 158 words\n      Progress: 20/21 papers processed\n      üìñ Understanding and Predicting Derailment in Toxic Conversatio...\n         ‚úì Full abstract: 206 words\n‚úì 2025-03-08: 21 papers\n      üìñ Unified Reward Model for Multimodal Understanding and Genera...\n         ‚úì Full abstract: 208 words\n      üìñ Sketch-of-Thought: Efficient LLM Reasoning with Adaptive\n  C...\n         ‚úì Full abstract: 159 words\n      üìñ Forgetting Transformer: Softmax Attention with a Forget Gate...\n         ‚úì Full abstract: 171 words\n‚úì 2025-03-09: 3 papers\n      üìñ RuCCoD: Towards Automated ICD Coding in Russian...\n         ‚úì Full abstract: 171 words\n      üìñ Unified Reward Model for Multimodal Understanding and Genera...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05236\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ EuroBERT: Scaling Multilingual Encoders for European Languag...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05500\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ R1-Zero's \"Aha Moment\" in Visual Reasoning on a 2B Non-SFT M...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05132\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ S2S-Arena, Evaluating Speech2Speech Protocols on Instruction...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05085\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Sketch-of-Thought: Efficient LLM Reasoning with Adaptive\n  C...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05179\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ R1-Omni: Explainable Omni-Multimodal Emotion Recognition wit...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05379\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Forgetting Transformer: Softmax Attention with a Forget Gate...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.02130\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ R1-Searcher: Incentivizing the Search Capability in LLMs via...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05592\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ VideoPainter: Any-length Video Inpainting and Editing with P...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05639\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ SafeArena: Evaluating the Safety of Autonomous Web Agents...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.04957\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ TrajectoryCrafter: Redirecting Camera Trajectory for Monocul...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05638\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Learning from Failures in Multi-Attempt Reinforcement Learni...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.04808\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ TinyR1-32B-Preview: Boosting Accuracy with Branch-Merge Dist...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.04872\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ LoRACode: LoRA Adapters for Code Embeddings...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05315\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Man...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05652\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ ProReflow: Progressive Reflow with Decomposed Velocity...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.04824\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Expert...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05447\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ An Empirical Study on Eliciting and Improving R1-like Reason...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.04548\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ SAGE: A Framework of Precise Retrieval for RAG...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.01713\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ LONGCODEU: Benchmarking Long-Context Language Models on Long...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.04359\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ EAGLE-3: Scaling up Inference Acceleration of Large Language...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.01840\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection w...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.04504\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Know You First and Be You Better: Modeling Human-Like User S...\n         ‚úì Full abstract: 184 words\n‚úì 2025-03-10: 2 papers\n      üìñ Feature-Level Insights into Artificial Text Detection with S...\n         ‚úì Full abstract: 134 words\n      üìñ SEAP: Training-free Sparse Expert Activation Pruning Unlock ...\n         ‚úì Full abstract: 136 words\n      üìñ MM-Eureka: Exploring Visual Aha Moment with Rule-based Large...\n         ‚úì Full abstract: 124 words\n      üìñ VACE: All-in-One Video Creation and Editing...\n         ‚úì Full abstract: 184 words\n      üìñ Automated Movie Generation via Multi-Agent CoT Planning...\n         ‚úì Full abstract: 183 words\n      Progress: 5/50 papers processed\n      üìñ Taking Notes Brings Focus? Towards Multi-Turn Multimodal Dia...\n         ‚úì Full abstract: 176 words\n      üìñ FedRand: Enhancing Privacy in Federated Learning with Random...\n         ‚úì Full abstract: 196 words\n      üìñ DistiLLM-2: A Contrastive Approach Boosts the Distillation o...\n         ‚úì Full abstract: 135 words\n      üìñ Vision-R1: Incentivizing Reasoning Capability in Multimodal ...\n         ‚úì Full abstract: 232 words\n      üìñ EasyControl: Adding Efficient and Flexible Control for Diffu...\n         ‚úì Full abstract: 246 words\n      Progress: 10/50 papers processed\n      üìñ Beyond RAG: Task-Aware KV Cache Compression for Comprehensiv...\n         ‚úì Full abstract: 154 words\n      üìñ AlphaDrive: Unleashing the Power of VLMs in Autonomous Drivi...\n         ‚úì Full abstract: 207 words\n      üìñ FEA-Bench: A Benchmark for Evaluating Repository-Level Code ...\n         ‚úì Full abstract: 153 words\n      üìñ WritingBench: A Comprehensive Benchmark for Generative Writi...\n         ‚úì Full abstract: 154 words\n      üìñ Agent models: Internalizing Chain-of-Action Generation into ...\n         ‚úì Full abstract: 133 words\n      Progress: 15/50 papers processed\n      üìñ SurveyForge: On the Outline Heuristics, Memory-Driven Genera...\n         ‚úì Full abstract: 150 words\n      üìñ MedAgentsBench: Benchmarking Thinking Models and Agent Frame...\n         ‚úì Full abstract: 187 words\n      üìñ Unleashing the Potential of Large Language Models for Text-t...\n         ‚úì Full abstract: 193 words\n      üìñ YOLOE: Real-Time Seeing Anything...\n         ‚úì Full abstract: 244 words\n      üìñ LLaVE: Large Language and Vision Embedding Models with Hardn...\n         ‚úì Full abstract: 189 words\n      Progress: 20/50 papers processed\n      üìñ DreamRelation: Relation-Centric Video Customization...\n         ‚úì Full abstract: 227 words\n      üìñ Effective and Efficient Masked Image Generation Models...\n         ‚úì Full abstract: 149 words\n      üìñ Seg-Zero: Reasoning-Chain Guided Segmentation via Cognitive\n...\n         ‚úì Full abstract: 174 words\n      üìñ PE3R: Perception-Efficient 3D Reconstruction...\n         ‚úì Full abstract: 135 words\n      üìñ Words or Vision: Do Vision-Language Models Have Blind Faith ...\n         ‚úì Full abstract: 223 words\n      Progress: 25/50 papers processed\n      üìñ This Is Your Doge, If It Please You: Exploring Deception and...\n         ‚úì Full abstract: 189 words\n      üìñ Zero-AVSR: Zero-Shot Audio-Visual Speech Recognition with LL...\n         ‚úì Full abstract: 194 words\n      üìñ DiffCLIP: Differential Attention Meets CLIP...\n         ‚úì Full abstract: 103 words\n      üìñ BlackGoose Rimer: Harnessing RWKV-7 as a Simple yet Superior...\n         ‚úì Full abstract: 134 words\n      üìñ State-offset Tuning: State-based Parameter-Efficient Fine-Tu...\n         ‚úì Full abstract: 137 words\n      Progress: 30/50 papers processed\n      üìñ Detection Avoidance Techniques for Large Language Models...\n         ‚úì Full abstract: 121 words\n      üìñ Efficient Distillation of Classifier-Free Guidance using Ada...\n         ‚úì Full abstract: 210 words\n      üìñ WISE: A World Knowledge-Informed Semantic Evaluation for Tex...\n         ‚úì Full abstract: 176 words\n      üìñ ProBench: Judging Multimodal Foundation Models on Open-ended...\n         ‚úì Full abstract: 137 words\n      üìñ What's in a Latent? Leveraging Diffusion Latent Space for Do...\n         ‚úì Full abstract: 171 words\n      Progress: 35/50 papers processed\n      üìñ Next Token Is Enough: Realistic Image Quality and Aesthetic ...\n         ‚úì Full abstract: 231 words\n      üìñ Escaping Plato's Cave: Towards the Alignment of 3D and Text ...\n         ‚úì Full abstract: 206 words\n      üìñ Should VLMs be Pre-trained with Image Data?...\n         ‚úì Full abstract: 157 words\n      üìñ TRCE: Towards Reliable Malicious Concept Erasure in Text-to-...\n         ‚úì Full abstract: 237 words\n      üìñ A Data-Centric Revisit of Pre-Trained Vision Models for Robo...\n         ‚úì Full abstract: 180 words\n      Progress: 40/50 papers processed\n      üìñ Adaptive Audio-Visual Speech Recognition via Matryoshka-Base...\n         ‚úì Full abstract: 191 words\n      üìñ Novel Object 6D Pose Estimation with a Single Reference View...\n         ‚úì Full abstract: 188 words\n      üìñ Promote, Suppress, Iterate: How Language Models Answer One-t...\n         ‚úì Full abstract: 174 words\n      üìñ HumanMM: Global Human Motion Recovery from Multi-shot Videos...\n         ‚úì Full abstract: 173 words\n      üìñ RePO: ReLU-based Preference Optimization...\n         ‚úì Full abstract: 139 words\n      Progress: 45/50 papers processed\n      üìñ REF-VLM: Triplet-Based Referring Paradigm for Unified Visual...\n         ‚úì Full abstract: 239 words\n      üìñ Symbolic Mixture-of-Experts: Adaptive Skill-based Routing fo...\n         ‚úì Full abstract: 280 words\n      üìñ PhiloBERTA: A Transformer-Based Cross-Lingual Analysis of Gr...\n         ‚úì Full abstract: 112 words\n      üìñ NeuGrasp: Generalizable Neural Surface Reconstruction with B...\n         ‚úì Full abstract: 118 words\n      üìñ Feynman-Kac Correctors in Diffusion: Annealing, Guidance, an...\n         ‚úì Full abstract: 178 words\n      Progress: 50/50 papers processed\n‚úì 2025-03-11: 50 papers\n      üìñ Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicul...\n         ‚úì Full abstract: 199 words\n      üìñ LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities T...\n         ‚úì Full abstract: 185 words\n      üìñ YuE: Scaling Open Foundation Models for Long-Form Music Gene...\n         ‚úì Full abstract: 194 words\n      üìñ Optimizing Test-Time Compute via Meta Reinforcement Fine-Tun...\n         ‚úì Full abstract: 264 words\n      üìñ Gemini Embedding: Generalizable Embeddings from Gemini...\n         ‚úì Full abstract: 135 words\n      Progress: 5/40 papers processed\n      üìñ Seedream 2.0: A Native Chinese-English Bilingual Image Gener...\n         ‚úì Full abstract: 257 words\n      üìñ MagicInfinite: Generating Infinite Talking Videos with Your ...\n         ‚úì Full abstract: 212 words\n      üìñ Video Action Differencing...\n         ‚úì Full abstract: 184 words\n      üìñ UniF^2ace: Fine-grained Face Understanding and Generation\n  ...\n         ‚úì Full abstract: 194 words\n      üìñ SegAgent: Exploring Pixel Understanding Capabilities in MLLM...\n         ‚úì Full abstract: 229 words\n      Progress: 10/40 papers processed\n      üìñ Tuning-Free Multi-Event Long Video Generation via Synchroniz...\n         ‚úì Full abstract: 217 words\n      üìñ Implicit Reasoning in Transformers is Reasoning through Shor...\n         ‚úì Full abstract: 186 words\n      üìñ LightGen: Efficient Image Generation through Knowledge Disti...\n         ‚úì Full abstract: 193 words\n      üìñ OmniMamba: Efficient and Unified Multimodal Understanding an...\n         ‚úì Full abstract: 181 words\n      üìñ Exploiting Instruction-Following Retrievers for Malicious In...\n         ‚úì Full abstract: 150 words\n      Progress: 15/40 papers processed\n      üìñ LocAgent: Graph-Guided LLM Agents for Code Localization...\n         ‚úì Full abstract: 172 words\n      üìñ AI-native Memory 2.0: Second Me...\n         ‚úì Full abstract: 227 words\n      üìñ \"Principal Components\" Enable A New Language of Images...\n         ‚úì Full abstract: 173 words\n      üìñ Robusto-1 Dataset: Comparing Humans and VLMs on real out-of-...\n         ‚úì Full abstract: 212 words\n      üìñ CineBrain: A Large-Scale Multi-Modal Brain Dataset During Na...\n         ‚úì Full abstract: 153 words\n      Progress: 20/40 papers processed\n      üìñ VisualSimpleQA: A Benchmark for Decoupled Evaluation of Larg...\n         ‚úì Full abstract: 147 words\n      üìñ Benchmarking AI Models in Software Engineering: A Review, Se...\n         ‚úì Full abstract: 237 words\n      üìñ Mixture of Experts Made Intrinsically Interpretable...\n         ‚úì Full abstract: 205 words\n      üìñ ^RFLAV: Rolling Flow matching for infinite Audio Video gener...\n         ‚úì Full abstract: 115 words\n      üìñ AnyMoLe: Any Character Motion In-betweening Leveraging Video...\n         ‚úì Full abstract: 129 words\n      Progress: 25/40 papers processed\n      üìñ BiasEdit: Debiasing Stereotyped Language Models via Model Ed...\n         ‚úì Full abstract: 164 words\n      üìñ Referring to Any Person...\n         ‚úì Full abstract: 199 words\n      üìñ Inductive Moment Matching...\n         ‚úì Full abstract: 115 words\n      üìñ Perplexity Trap: PLM-Based Retrievers Overrate Low Perplexit...\n         ‚úì Full abstract: 186 words\n      üìñ RayFlow: Instance-Aware Diffusion Acceleration via Adaptive ...\n         ‚úì Full abstract: 117 words\n      Progress: 30/40 papers processed\n      üìñ Beyond Decoder-only: Large Language Models Can be Good Encod...\n         ‚úì Full abstract: 190 words\n      üìñ QuoTA: Query-oriented Token Assignment via CoT Query Decoupl...\n         ‚úì Full abstract: 186 words\n      üìñ ObjectMover: Generative Object Movement with Video Prior...\n         ‚úì Full abstract: 179 words\n      üìñ Capacity-Aware Inference: Mitigating the Straggler Effect in...\n         ‚úì Full abstract: 172 words\n      üìñ Collapse of Dense Retrievers: Short, Early, and Literal Bias...\n         ‚úì Full abstract: 177 words\n      Progress: 35/40 papers processed\n      üìñ Evaluating Intelligence via Trial and Error...\n         ‚úì Full abstract: 294 words\n      üìñ PlainQAFact: Automatic Factuality Evaluation Metric for Biom...\n         ‚úì Full abstract: 162 words\n      üìñ NullFace: Training-Free Localized Face Anonymization...\n         ‚úì Full abstract: 154 words\n      üìñ Ideas in Inference-time Scaling can Benefit Generative Pre-t...\n         ‚úì Full abstract: 128 words\n      üìñ OTTER: A Vision-Language-Action Model with Text-Aware Visual...\n         ‚úì Full abstract: 149 words\n      Progress: 40/40 papers processed\n‚úì 2025-03-12: 40 papers\n      üìñ Block Diffusion: Interpolating Between Autoregressive and Di...\n         ‚úì Full abstract: 144 words\n      üìñ TPDiff: Temporal Pyramid Video Diffusion Model...\n         ‚úì Full abstract: 164 words\n      üìñ Search-R1: Training LLMs to Reason and Leverage Search Engin...\n         ‚úì Full abstract: 179 words\n      üìñ Motion Anything: Any to Motion Generation...\n         ‚úì Full abstract: 176 words\n      üìñ Reangle-A-Video: 4D Video Generation as Video-to-Video Trans...\n         ‚úì Full abstract: 151 words\n      Progress: 5/22 papers processed\n      üìñ GTR: Guided Thought Reinforcement Prevents Thought Collapse ...\n         ‚úì Full abstract: 202 words\n      üìñ More Documents, Same Length: Isolating the Challenge of Mult...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.04388\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ RewardSDS: Aligning Score Distillation via Reward-Weighted S...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.09601\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Self-Taught Self-Correction for Small Language Models...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.08681\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ WildIFEval: Instruction Following in the Wild...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.06573\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ VLog: Video-Language Models by Generative Retrieval of Narra...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.09402\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Quantizing Large Language Models for Code Generation: A Diff...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.07103\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Multi Agent based Medical Assistant for Edge Devices...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05397\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ PhysicsGen: Can Generative Models Learn from Images to Predi...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.05333\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ When Large Vision-Language Model Meets Large Remote Sensing ...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.07588\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Alias-Free Latent Diffusion Models:Improving Fractional Shif...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.09419\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Cost-Optimal Grouped-Query Attention for Long-Context LLMs...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.09579\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Multimodal Language Modeling for High-Accuracy Single Cell\n ...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.09427\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ MoC: Mixtures of Text Chunking Learners for Retrieval-Augmen...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.09600\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ BIMBA: Selective-Scan Compression for Long-Range Video Quest...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.09590\n         ‚ö†Ô∏è Detail page failed, using preview\n      üìñ Monte Carlo Diffusion for Generalizable Learning-Based RANSA...\n         ‚ùå Request error: 429 Client Error: Too Many Requests for url: https://huggingface.co/papers/2503.09410\n         ‚ö†Ô∏è Detail page failed, using preview\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Loading dataset after crawling"
      ],
      "metadata": {
        "id": "bxSD7lxEc_62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1wS4NdhyQG76eHTUR5-BNq0pO6QGqxcCJ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFkzgN5R_LMI",
        "outputId": "f22efa37-4f41-45ee-b730-b4c3946f83c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wS4NdhyQG76eHTUR5-BNq0pO6QGqxcCJ\n",
            "To: /content/papers_365_days.json\n",
            "100% 7.55M/7.55M [00:00<00:00, 137MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scraper = HuggingFaceScraper()\n",
        "papers = scraper.load(\"papers_365_days.json\")\n",
        "print(f\"Loaded {len(papers)} papers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV7_pWpBBH2p",
        "outputId": "3c4f883c-9d5b-4885-f99c-7fd7a4ac1e49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÇ Loaded from: papers_365_days.json\n",
            "   Scraped at: 2025-10-13T18:36:22.412767\n",
            "   Total papers: 4251\n",
            "Loaded 4251 papers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nüìä Scraping Results:\")\n",
        "print(f\"   Total papers: {len(papers)}\")\n",
        "\n",
        "# Count papers with complete info\n",
        "papers_with_abstract = sum(1 for p in papers if p.get('abstract'))\n",
        "papers_with_id = sum(1 for p in papers if p.get('paper_id'))\n",
        "papers_with_authors = sum(1 for p in papers if p.get('authors_count'))\n",
        "papers_with_upvotes = sum(1 for p in papers if p.get('upvotes'))\n",
        "\n",
        "print(f\"   With abstracts: {papers_with_abstract}\")\n",
        "print(f\"   With paper IDs: {papers_with_id}\")\n",
        "print(f\"   With author count: {papers_with_authors}\")\n",
        "print(f\"   With upvotes: {papers_with_upvotes}\")"
      ],
      "metadata": {
        "id": "wx0sYQ9zJLnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408ff3c9-add2-4b9b-897e-51982052175e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Scraping Results:\n",
            "   Total papers: 4251\n",
            "   With abstracts: 4251\n",
            "   With paper IDs: 4251\n",
            "   With author count: 3995\n",
            "   With upvotes: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deduplicate\n",
        "seen = set()\n",
        "unique_papers = []\n",
        "for p in papers:\n",
        "    key = p.get('paper_id') or p.get('title')\n",
        "    if key and key not in seen:\n",
        "        seen.add(key)\n",
        "        unique_papers.append(p)\n",
        "\n",
        "print(f\"\\n‚úÖ Total papers after merge: {len(unique_papers)}\")\n",
        "\n",
        "# Save combined dataset\n",
        "scraper.save(papers, \"papers_jan_preview.json\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚úÖ RESUME COMPLETE\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total unique: {len(unique_papers)} papers\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_jwRwt1BqcH",
        "outputId": "9c44c73e-64f7-4941-d3ba-83a2ce18e714"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Total papers after merge: 4251\n",
            "\n",
            "================================================================================\n",
            "üíæ SAVED TO: papers_jan_preview.json\n",
            "================================================================================\n",
            "üìä Statistics:\n",
            "   Total papers: 4251\n",
            "   With abstracts: 4251\n",
            "   - Full abstracts: 4251\n",
            "   - Preview abstracts: 0\n",
            "   With upvotes: 1 (avg: 2.0)\n",
            "   With author names: 0\n",
            "   Average abstract length: 188.4 words\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "‚úÖ RESUME COMPLETE\n",
            "================================================================================\n",
            "Total unique: 4251 papers\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample papers with all available info\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìÑ SAMPLE PAPERS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, paper in enumerate(papers[:5], 1):\n",
        "    print(f\"\\n{i}. {paper['title']}\")\n",
        "    print(f\"   Paper ID: {paper.get('paper_id', 'N/A')}\")\n",
        "    print(f\"   Date: {paper.get('date', 'N/A')}\")\n",
        "    print(f\"   Year: {paper.get('year', 'N/A')}\")\n",
        "    print(f\"   Number of Authors: {paper.get('authors_count', 'N/A')}\")\n",
        "    print(f\"   Abstract: {paper.get('abstract', 'N/A')[:120]}...\")\n",
        "    if paper.get('link'):\n",
        "        print(f\"   Link: {paper['link']}\")"
      ],
      "metadata": {
        "id": "QAHtrGdG1s5o",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a4cca1-12df-4b21-e295-094d0a27f756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìÑ SAMPLE PAPERS\n",
            "================================================================================\n",
            "\n",
            "1. WALL-E: World Alignment by Rule Learning Improves World Model-based LLM\n",
            "  Agents\n",
            "   Paper ID: 2410.07484\n",
            "   Date: 2024-10-13\n",
            "   Year: 2024\n",
            "   Number of Authors: 7\n",
            "   Abstract: Can large language models (LLMs) directly serve as powerful world models for model-based agents ? While the gaps between...\n",
            "   Link: https://huggingface.co/papers/2410.07484\n",
            "\n",
            "2. MathCoder2: Better Math Reasoning from Continued Pretraining on\n",
            "  Model-translated Mathematical Code\n",
            "   Paper ID: 2410.08196\n",
            "   Date: 2024-10-13\n",
            "   Year: 2024\n",
            "   Number of Authors: 8\n",
            "   Abstract: Code has been shown to be effective in enhancing the mathematical reasoning abilities of large language models due to it...\n",
            "   Link: https://huggingface.co/papers/2410.08196\n",
            "\n",
            "3. MLLM as Retriever: Interactively Learning Multimodal Retrieval for\n",
            "  Embodied Agents\n",
            "   Paper ID: 2410.03450\n",
            "   Date: 2024-10-13\n",
            "   Year: 2024\n",
            "   Number of Authors: 4\n",
            "   Abstract: MLLM agents demonstrate potential for complex embodied tasks by retrieving\n",
            "multimodal task-relevant trajectory data. How...\n",
            "   Link: https://huggingface.co/papers/2410.03450\n",
            "\n",
            "4. PrefixQuant: Static Quantization Beats Dynamic through Prefixed Outliers\n",
            "  in LLMs\n",
            "   Paper ID: 2410.05265\n",
            "   Date: 2024-10-13\n",
            "   Year: 2024\n",
            "   Number of Authors: 6\n",
            "   Abstract: Quantization is essential for deploying Large Language Models (LLMs) by\n",
            "enhancing memory efficiency and inference speed ...\n",
            "   Link: https://huggingface.co/papers/2410.05265\n",
            "\n",
            "5. Benchmarking Agentic Workflow Generation\n",
            "   Paper ID: 2410.07869\n",
            "   Date: 2024-10-13\n",
            "   Year: 2024\n",
            "   Number of Authors: 9\n",
            "   Abstract: Large Language Models (LLMs) , with their exceptional ability to handle a wide\n",
            "range of tasks, have driven significant a...\n",
            "   Link: https://huggingface.co/papers/2410.07869\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"Clean and normalize text\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "CN6demvxb3Tc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(json_path):\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    papers = []\n",
        "    for paper in data['papers']:\n",
        "        # Ch·ªâ l·∫•y papers c√≥ abstract v√† title\n",
        "        if paper.get('abstract') and paper.get('title'):\n",
        "            abstract = paper['abstract'].strip()\n",
        "            title = paper['title'].strip()\n",
        "\n",
        "            # Filter too short/long\n",
        "            if len(abstract) > 50 and len(title) > 10:\n",
        "                papers.append({\n",
        "                    'abstract': abstract,\n",
        "                    'title': title,\n",
        "                    'paper_id': paper.get('paper_id', '')\n",
        "                })\n",
        "\n",
        "    print(f\"‚úì Loaded {len(papers)} valid papers\")\n",
        "    return papers"
      ],
      "metadata": {
        "id": "8TfE03-3d2rL"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SummarizationDataset(Dataset):\n",
        "    def __init__(self, papers, tokenizer, max_input_len, max_target_len):\n",
        "        self.papers = papers\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_len = max_input_len\n",
        "        self.max_target_len = max_target_len\n",
        "\n",
        "        # Build vocabulary from titles\n",
        "        self.word2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n",
        "        self.idx2word = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n",
        "        self._build_vocab()\n",
        "\n",
        "    def _build_vocab(self):\n",
        "        idx = 4\n",
        "        for paper in self.papers:\n",
        "            words = paper['title'].lower().split()\n",
        "            for word in words:\n",
        "                if word not in self.word2idx:\n",
        "                    self.word2idx[word] = idx\n",
        "                    self.idx2word[idx] = word\n",
        "                    idx += 1\n",
        "\n",
        "    def encode_title(self, title):\n",
        "        words = title.lower().split()\n",
        "        indices = [self.word2idx.get(w, self.word2idx['<UNK>']) for w in words]\n",
        "        indices = [self.word2idx['<SOS>']] + indices + [self.word2idx['<EOS>']]\n",
        "\n",
        "        # Padding\n",
        "        if len(indices) < self.max_target_len:\n",
        "            indices += [self.word2idx['<PAD>']] * (self.max_target_len - len(indices))\n",
        "        else:\n",
        "            indices = indices[:self.max_target_len-1] + [self.word2idx['<EOS>']]\n",
        "\n",
        "        return torch.tensor(indices)\n",
        "\n",
        "    def decode_title(self, indices):\n",
        "        words = []\n",
        "        for idx in indices:\n",
        "            if idx == self.word2idx['<EOS>']:\n",
        "                break\n",
        "            if idx not in [self.word2idx['<PAD>'], self.word2idx['<SOS>']]:\n",
        "                words.append(self.idx2word.get(idx, '<UNK>'))\n",
        "        return ' '.join(words)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.papers)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        paper = self.papers[idx]\n",
        "\n",
        "        # Encode abstract with BERT tokenizer\n",
        "        encoding = self.tokenizer(\n",
        "            paper['abstract'],\n",
        "            max_length=self.max_input_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Encode title\n",
        "        title_indices = self.encode_title(paper['title'])\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'target': title_indices,\n",
        "            'title_text': paper['title']\n",
        "        }"
      ],
      "metadata": {
        "id": "gRt0ON5TmN2A"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Attention Mechanism Architecture"
      ],
      "metadata": {
        "id": "1PxoASM23smO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Bahdanau (Additive) Attention\n",
        "    score(h_t, h_s) = v^T * tanh(W1*h_t + W2*h_s)\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, decoder_hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = nn.Linear(hidden_size, decoder_hidden_size, bias=False)\n",
        "        self.W2 = nn.Linear(decoder_hidden_size, decoder_hidden_size, bias=False)\n",
        "        self.v = nn.Linear(decoder_hidden_size, 1, bias=False)\n",
        "\n",
        "    def forward(self, encoder_outputs, decoder_hidden):\n",
        "        \"\"\"\n",
        "        encoder_outputs: (batch, seq_len, hidden_size)\n",
        "        decoder_hidden: (batch, decoder_hidden_size)\n",
        "        \"\"\"\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        seq_len = encoder_outputs.size(1)\n",
        "\n",
        "        # Expand decoder hidden to match encoder outputs\n",
        "        decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        energy = torch.tanh(self.W1(encoder_outputs) + self.W2(decoder_hidden))\n",
        "        attention_scores = self.v(energy).squeeze(2)  # (batch, seq_len)\n",
        "\n",
        "        # Apply softmax\n",
        "        attention_weights = F.softmax(attention_scores, dim=1)\n",
        "\n",
        "        # Calculate context vector\n",
        "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
        "        context = context.squeeze(1)  # (batch, hidden_size)\n",
        "\n",
        "        return context, attention_weights"
      ],
      "metadata": {
        "id": "24NKgU0CjsQD"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTEncoder(nn.Module):\n",
        "    def __init__(self, model_name, freeze_bert=False):\n",
        "        super(BERTEncoder, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "\n",
        "        # C√≥ th·ªÉ freeze BERT ƒë·ªÉ train nhanh h∆°n\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state"
      ],
      "metadata": {
        "id": "WcQszYsNjx02"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, encoder_hidden_size,\n",
        "                 decoder_hidden_size, dropout=0.3):\n",
        "        super(AttentionDecoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.decoder_hidden_size = decoder_hidden_size\n",
        "\n",
        "        # Layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
        "        self.attention = BahdanauAttention(encoder_hidden_size, decoder_hidden_size)\n",
        "        self.lstm = nn.LSTM(embed_size + encoder_hidden_size, decoder_hidden_size,\n",
        "                           batch_first=True, num_layers=1, dropout=0)  # Kh√¥ng d√πng LSTM dropout v√¨ ch·ªâ 1 layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(decoder_hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
        "        \"\"\"\n",
        "        input_token: (batch, 1)\n",
        "        hidden: (1, batch, decoder_hidden_size)\n",
        "        cell: (1, batch, decoder_hidden_size)\n",
        "        encoder_outputs: (batch, seq_len, encoder_hidden_size)\n",
        "        \"\"\"\n",
        "        # Embedding v·ªõi dropout\n",
        "        embedded = self.dropout(self.embedding(input_token))  # (batch, 1, embed_size)\n",
        "\n",
        "        # Attention\n",
        "        decoder_hidden = hidden.squeeze(0)  # (batch, decoder_hidden_size)\n",
        "        context, attention_weights = self.attention(encoder_outputs, decoder_hidden)\n",
        "        context = context.unsqueeze(1)  # (batch, 1, encoder_hidden_size)\n",
        "\n",
        "        # Concatenate embedding and context\n",
        "        lstm_input = torch.cat([embedded, context], dim=2)\n",
        "\n",
        "        # LSTM\n",
        "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
        "\n",
        "        # Dropout tr∆∞·ªõc FC layer\n",
        "        output = self.dropout(output.squeeze(1))\n",
        "\n",
        "        # Prediction\n",
        "        prediction = self.fc(output)  # (batch, vocab_size)\n",
        "\n",
        "        return prediction, hidden, cell, attention_weights"
      ],
      "metadata": {
        "id": "dLo9T0Gzjzz6"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqWithAttention(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2SeqWithAttention, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, src_mask, trg, teacher_forcing_ratio=0.5):\n",
        "        \"\"\"\n",
        "        src: (batch, src_len)\n",
        "        trg: (batch, trg_len)\n",
        "        \"\"\"\n",
        "        batch_size = src.size(0)\n",
        "        trg_len = trg.size(1)\n",
        "        vocab_size = self.decoder.vocab_size\n",
        "\n",
        "        # Encoder\n",
        "        encoder_outputs = self.encoder(src, src_mask)\n",
        "\n",
        "        # Initialize decoder hidden state\n",
        "        hidden = torch.zeros(1, batch_size, self.decoder.decoder_hidden_size).to(self.device)\n",
        "        cell = torch.zeros(1, batch_size, self.decoder.decoder_hidden_size).to(self.device)\n",
        "\n",
        "        # Store outputs\n",
        "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n",
        "\n",
        "        # First input is <SOS> token\n",
        "        input_token = trg[:, 0].unsqueeze(1)\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell, _ = self.decoder(input_token, hidden, cell, encoder_outputs)\n",
        "            outputs[:, t, :] = output\n",
        "\n",
        "            # Teacher forcing\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1).unsqueeze(1)\n",
        "            input_token = trg[:, t].unsqueeze(1) if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "TuGOfDANj1ne"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes, smoothing=0.0, ignore_index=-100):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=-1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
        "            true_dist[:, self.ignore_index] = 0\n",
        "            mask = torch.nonzero(target == self.ignore_index, as_tuple=False)\n",
        "            if mask.dim() > 0 and mask.size(0) > 0:\n",
        "                true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=-1))"
      ],
      "metadata": {
        "id": "OkST1kAPq5op"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_rouge(predictions, references):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        score = scorer.score(ref, pred)\n",
        "        scores['rouge1'].append(score['rouge1'].fmeasure)\n",
        "        scores['rouge2'].append(score['rouge2'].fmeasure)\n",
        "        scores['rougeL'].append(score['rougeL'].fmeasure)\n",
        "\n",
        "    return {k: np.mean(v) for k, v in scores.items()}\n",
        "\n",
        "def calculate_bleu(predictions, references):\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    scores = []\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        pred_tokens = pred.lower().split()\n",
        "        ref_tokens = [ref.lower().split()]\n",
        "        score = sentence_bleu(ref_tokens, pred_tokens, smoothing_function=smoothie)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)"
      ],
      "metadata": {
        "id": "SkMJ-A_Vd_zl"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion, device, teacher_forcing_ratio):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in tqdm(loader, desc='Training'):\n",
        "        src = batch['input_ids'].to(device)\n",
        "        src_mask = batch['attention_mask'].to(device)\n",
        "        trg = batch['target'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_mask, trg, teacher_forcing_ratio)\n",
        "\n",
        "        # Calculate loss (ignore padding)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)\n",
        "        trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, criterion, dataset, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc='Evaluating'):\n",
        "            src = batch['input_ids'].to(device)\n",
        "            src_mask = batch['attention_mask'].to(device)\n",
        "            trg = batch['target'].to(device)\n",
        "\n",
        "            output = model(src, src_mask, trg, 0)  # No teacher forcing\n",
        "\n",
        "            # Loss\n",
        "            output_dim = output.shape[-1]\n",
        "            output_flat = output[:, 1:].reshape(-1, output_dim)\n",
        "            trg_flat = trg[:, 1:].reshape(-1)\n",
        "            loss = criterion(output_flat, trg_flat)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Generate predictions\n",
        "            pred_indices = output.argmax(2)\n",
        "            for i in range(len(pred_indices)):\n",
        "                pred_text = dataset.decode_title(pred_indices[i].cpu().numpy())\n",
        "                ref_text = batch['title_text'][i]\n",
        "                predictions.append(pred_text)\n",
        "                references.append(ref_text)\n",
        "\n",
        "    avg_loss = epoch_loss / len(loader)\n",
        "    rouge_scores = calculate_rouge(predictions, references)\n",
        "    bleu_score = calculate_bleu(predictions, references)\n",
        "\n",
        "    return avg_loss, rouge_scores, bleu_score"
      ],
      "metadata": {
        "id": "FzyRPEpSmZdg"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Full pipeline training"
      ],
      "metadata": {
        "id": "246ltyBxdd4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    'encoder_model': 'bert-base-uncased',  # Pre-trained encoder\n",
        "    'max_input_length': 256,\n",
        "    'max_target_length': 32,\n",
        "    'hidden_size': 768,  # BERT hidden size\n",
        "    'decoder_hidden_size': 256,  # Gi·∫£m t·ª´ 512 ‚Üí 256\n",
        "    'embed_size': 256,  # Gi·∫£m t·ª´ 300 ‚Üí 256\n",
        "    'dropout': 0.5,  # TƒÉng t·ª´ 0.3 ‚Üí 0.5\n",
        "    'batch_size': 16,\n",
        "    'learning_rate': 5e-4,  # Gi·∫£m t·ª´ 1e-3 ‚Üí 5e-4\n",
        "    'encoder_lr': 1e-5,\n",
        "    'num_epochs': 30,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'teacher_forcing_ratio': 0.7,\n",
        "    'weight_decay': 1e-4,  # L2 regularization\n",
        "    'label_smoothing': 0.1,  # Label smoothing\n",
        "    'patience': 5,  # Early stopping patience\n",
        "    'freeze_bert': True  # Freeze BERT ƒë·ªÉ gi·∫£m overfitting\n",
        "}"
      ],
      "metadata": {
        "id": "lbJ31X-mmjzg"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load data\n",
        "papers = load_data('papers_365_days.json')\n",
        "train_papers, temp = train_test_split(papers, test_size=0.3, random_state=42)\n",
        "val_papers, test_papers = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "print(f\"Train: {len(train_papers)}, Val: {len(val_papers)}, Test: {len(test_papers)}\\n\")\n",
        "\n",
        "# 2. Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(CONFIG['encoder_model'])\n",
        "\n",
        "# 3. Datasets\n",
        "train_dataset = SummarizationDataset(train_papers, tokenizer,\n",
        "                                    CONFIG['max_input_length'], CONFIG['max_target_length'])\n",
        "val_dataset = SummarizationDataset(val_papers, tokenizer,\n",
        "                                  CONFIG['max_input_length'], CONFIG['max_target_length'])\n",
        "test_dataset = SummarizationDataset(test_papers, tokenizer,\n",
        "                                   CONFIG['max_input_length'], CONFIG['max_target_length'])\n",
        "\n",
        "train_dataset.word2idx = val_dataset.word2idx = test_dataset.word2idx = train_dataset.word2idx\n",
        "train_dataset.idx2word = val_dataset.idx2word = test_dataset.idx2word = train_dataset.idx2word\n",
        "\n",
        "vocab_size = len(train_dataset.word2idx)\n",
        "print(f\"Vocabulary size: {vocab_size}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJDz18jbbwn",
        "outputId": "58294b6d-9897-4481-b616-c608cd85b8bc"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Loaded 4249 valid papers\n",
            "Train: 2974, Val: 637, Test: 638\n",
            "\n",
            "Vocabulary size: 6759\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'])\n",
        "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'])\n",
        "\n",
        "# 5. Model\n",
        "encoder = BERTEncoder(CONFIG['encoder_model'], freeze_bert=CONFIG['freeze_bert'])\n",
        "decoder = AttentionDecoder(\n",
        "    vocab_size, CONFIG['embed_size'],\n",
        "    CONFIG['hidden_size'], CONFIG['decoder_hidden_size'],\n",
        "    CONFIG['dropout']\n",
        ")\n",
        "model = Seq2SeqWithAttention(encoder, decoder, CONFIG['device']).to(CONFIG['device'])\n",
        "\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIdR6vyzb1vJ",
        "outputId": "a843148c-77a1-4b6f-9384-bbe18b192e95"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 5,042,535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Training setup v·ªõi Label Smoothing v√† Weight Decay\n",
        "criterion = LabelSmoothingLoss(\n",
        "    classes=vocab_size,\n",
        "    smoothing=CONFIG['label_smoothing'],\n",
        "    ignore_index=train_dataset.word2idx['<PAD>']\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam([\n",
        "    {'params': encoder.parameters(), 'lr': CONFIG['encoder_lr'], 'weight_decay': CONFIG['weight_decay']},\n",
        "    {'params': decoder.parameters(), 'lr': CONFIG['learning_rate'], 'weight_decay': CONFIG['weight_decay']}\n",
        "])\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=2\n",
        ")"
      ],
      "metadata": {
        "id": "8rsA_f-tqHPV"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Training loop\n",
        "best_val_loss = float('inf')\n",
        "history = {'train_loss': [], 'val_loss': [], 'rouge1': [], 'rouge2': [], 'rougeL': [], 'bleu': []}\n",
        "\n",
        "print(\"Starting training...\\n\")\n",
        "for epoch in range(CONFIG['num_epochs']):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion,\n",
        "                            CONFIG['device'], CONFIG['teacher_forcing_ratio'])\n",
        "    val_loss, rouge, bleu = evaluate(model, val_loader, criterion, val_dataset, CONFIG['device'])\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['rouge1'].append(rouge['rouge1'])\n",
        "    history['rouge2'].append(rouge['rouge2'])\n",
        "    history['rougeL'].append(rouge['rougeL'])\n",
        "    history['bleu'].append(bleu)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"  ROUGE-1: {rouge['rouge1']:.4f} | ROUGE-2: {rouge['rouge2']:.4f} | ROUGE-L: {rouge['rougeL']:.4f}\")\n",
        "    print(f\"  BLEU: {bleu:.4f}\\n\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_attention_model.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1vuHH0PcEvu",
        "outputId": "8fea006e-6b0c-4690-81b1-bd877e5c2d50"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.78it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "  Train Loss: 2.3855 | Val Loss: 2.3259\n",
            "  ROUGE-1: 0.0675 | ROUGE-2: 0.0000 | ROUGE-L: 0.0662\n",
            "  BLEU: 0.0082\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.78it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30\n",
            "  Train Loss: 2.2539 | Val Loss: 2.3040\n",
            "  ROUGE-1: 0.0741 | ROUGE-2: 0.0000 | ROUGE-L: 0.0718\n",
            "  BLEU: 0.0104\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.76it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30\n",
            "  Train Loss: 2.2146 | Val Loss: 2.2937\n",
            "  ROUGE-1: 0.0946 | ROUGE-2: 0.0062 | ROUGE-L: 0.0903\n",
            "  BLEU: 0.0126\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.76it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30\n",
            "  Train Loss: 2.1848 | Val Loss: 2.2838\n",
            "  ROUGE-1: 0.1194 | ROUGE-2: 0.0171 | ROUGE-L: 0.1128\n",
            "  BLEU: 0.0177\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.77it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30\n",
            "  Train Loss: 2.1560 | Val Loss: 2.2788\n",
            "  ROUGE-1: 0.1351 | ROUGE-2: 0.0254 | ROUGE-L: 0.1281\n",
            "  BLEU: 0.0224\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.76it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30\n",
            "  Train Loss: 2.1325 | Val Loss: 2.2726\n",
            "  ROUGE-1: 0.1409 | ROUGE-2: 0.0268 | ROUGE-L: 0.1332\n",
            "  BLEU: 0.0221\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.77it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30\n",
            "  Train Loss: 2.1053 | Val Loss: 2.2672\n",
            "  ROUGE-1: 0.1494 | ROUGE-2: 0.0324 | ROUGE-L: 0.1409\n",
            "  BLEU: 0.0255\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.77it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30\n",
            "  Train Loss: 2.0816 | Val Loss: 2.2671\n",
            "  ROUGE-1: 0.1527 | ROUGE-2: 0.0336 | ROUGE-L: 0.1436\n",
            "  BLEU: 0.0251\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.78it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30\n",
            "  Train Loss: 2.0634 | Val Loss: 2.2588\n",
            "  ROUGE-1: 0.1603 | ROUGE-2: 0.0373 | ROUGE-L: 0.1516\n",
            "  BLEU: 0.0265\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.77it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30\n",
            "  Train Loss: 2.0404 | Val Loss: 2.2562\n",
            "  ROUGE-1: 0.1598 | ROUGE-2: 0.0351 | ROUGE-L: 0.1496\n",
            "  BLEU: 0.0264\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.78it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30\n",
            "  Train Loss: 2.0211 | Val Loss: 2.2481\n",
            "  ROUGE-1: 0.1587 | ROUGE-2: 0.0347 | ROUGE-L: 0.1502\n",
            "  BLEU: 0.0261\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.77it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30\n",
            "  Train Loss: 2.0021 | Val Loss: 2.2484\n",
            "  ROUGE-1: 0.1609 | ROUGE-2: 0.0336 | ROUGE-L: 0.1512\n",
            "  BLEU: 0.0255\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.78it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30\n",
            "  Train Loss: 1.9801 | Val Loss: 2.2489\n",
            "  ROUGE-1: 0.1712 | ROUGE-2: 0.0410 | ROUGE-L: 0.1600\n",
            "  BLEU: 0.0278\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.80it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30\n",
            "  Train Loss: 1.9659 | Val Loss: 2.2460\n",
            "  ROUGE-1: 0.1702 | ROUGE-2: 0.0377 | ROUGE-L: 0.1594\n",
            "  BLEU: 0.0279\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.80it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30\n",
            "  Train Loss: 1.9476 | Val Loss: 2.2424\n",
            "  ROUGE-1: 0.1709 | ROUGE-2: 0.0384 | ROUGE-L: 0.1600\n",
            "  BLEU: 0.0284\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.79it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30\n",
            "  Train Loss: 1.9324 | Val Loss: 2.2484\n",
            "  ROUGE-1: 0.1739 | ROUGE-2: 0.0440 | ROUGE-L: 0.1628\n",
            "  BLEU: 0.0301\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.78it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30\n",
            "  Train Loss: 1.9149 | Val Loss: 2.2425\n",
            "  ROUGE-1: 0.1765 | ROUGE-2: 0.0423 | ROUGE-L: 0.1653\n",
            "  BLEU: 0.0293\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.80it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30\n",
            "  Train Loss: 1.8985 | Val Loss: 2.2395\n",
            "  ROUGE-1: 0.1764 | ROUGE-2: 0.0416 | ROUGE-L: 0.1642\n",
            "  BLEU: 0.0284\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.78it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30\n",
            "  Train Loss: 1.8882 | Val Loss: 2.2405\n",
            "  ROUGE-1: 0.1729 | ROUGE-2: 0.0407 | ROUGE-L: 0.1604\n",
            "  BLEU: 0.0270\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.80it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30\n",
            "  Train Loss: 1.8715 | Val Loss: 2.2419\n",
            "  ROUGE-1: 0.1783 | ROUGE-2: 0.0421 | ROUGE-L: 0.1654\n",
            "  BLEU: 0.0292\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.77it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30\n",
            "  Train Loss: 1.8615 | Val Loss: 2.2409\n",
            "  ROUGE-1: 0.1836 | ROUGE-2: 0.0454 | ROUGE-L: 0.1705\n",
            "  BLEU: 0.0301\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.80it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30\n",
            "  Train Loss: 1.8448 | Val Loss: 2.2413\n",
            "  ROUGE-1: 0.1832 | ROUGE-2: 0.0443 | ROUGE-L: 0.1690\n",
            "  BLEU: 0.0314\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.79it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/30\n",
            "  Train Loss: 1.8277 | Val Loss: 2.2485\n",
            "  ROUGE-1: 0.1868 | ROUGE-2: 0.0458 | ROUGE-L: 0.1731\n",
            "  BLEU: 0.0311\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.80it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/30\n",
            "  Train Loss: 1.8212 | Val Loss: 2.2366\n",
            "  ROUGE-1: 0.1792 | ROUGE-2: 0.0430 | ROUGE-L: 0.1672\n",
            "  BLEU: 0.0289\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.76it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/30\n",
            "  Train Loss: 1.8082 | Val Loss: 2.2402\n",
            "  ROUGE-1: 0.1803 | ROUGE-2: 0.0450 | ROUGE-L: 0.1674\n",
            "  BLEU: 0.0292\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.80it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/30\n",
            "  Train Loss: 1.7948 | Val Loss: 2.2391\n",
            "  ROUGE-1: 0.1771 | ROUGE-2: 0.0421 | ROUGE-L: 0.1641\n",
            "  BLEU: 0.0296\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.79it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/30\n",
            "  Train Loss: 1.7840 | Val Loss: 2.2329\n",
            "  ROUGE-1: 0.1857 | ROUGE-2: 0.0429 | ROUGE-L: 0.1728\n",
            "  BLEU: 0.0305\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.78it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/30\n",
            "  Train Loss: 1.7753 | Val Loss: 2.2387\n",
            "  ROUGE-1: 0.1809 | ROUGE-2: 0.0415 | ROUGE-L: 0.1660\n",
            "  BLEU: 0.0293\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:07<00:00,  2.76it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/30\n",
            "  Train Loss: 1.7669 | Val Loss: 2.2376\n",
            "  ROUGE-1: 0.1864 | ROUGE-2: 0.0449 | ROUGE-L: 0.1738\n",
            "  BLEU: 0.0312\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [01:06<00:00,  2.78it/s]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/30\n",
            "  Train Loss: 1.7561 | Val Loss: 2.2356\n",
            "  ROUGE-1: 0.1872 | ROUGE-2: 0.0397 | ROUGE-L: 0.1705\n",
            "  BLEU: 0.0289\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Test evaluation\n",
        "print(\"Testing on test set...\")\n",
        "model.load_state_dict(torch.load('best_attention_model.pt'))\n",
        "test_loss, test_rouge, test_bleu = evaluate(model, test_loader, criterion, test_dataset, CONFIG['device'])\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"FINAL TEST RESULTS\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"ROUGE-1: {test_rouge['rouge1']:.4f}\")\n",
        "print(f\"ROUGE-2: {test_rouge['rouge2']:.4f}\")\n",
        "print(f\"ROUGE-L: {test_rouge['rougeL']:.4f}\")\n",
        "print(f\"BLEU: {test_bleu:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuKI66aYcGo0",
        "outputId": "497619ca-b263-4420-f194-409bba68f2ba"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL TEST RESULTS\n",
            "============================================================\n",
            "Test Loss: 2.1919\n",
            "ROUGE-1: 0.1967\n",
            "ROUGE-2: 0.0457\n",
            "ROUGE-L: 0.1835\n",
            "BLEU: 0.0314\n"
          ]
        }
      ]
    }
  ]
}