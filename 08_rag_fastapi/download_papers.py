#!/usr/bin/env python3
"""
Script ƒë·ªÉ t·∫£i c√°c AI papers ph·ªï bi·∫øn cho RAG pipeline
"""

import os
import requests
from pathlib import Path

# Th∆∞ m·ª•c l∆∞u PDFs
PDF_DIR = Path("data/pdfs")
PDF_DIR.mkdir(parents=True, exist_ok=True)

# Danh s√°ch c√°c papers
PAPERS = [
    {
        "name": "Attention Is All You Need (Transformer)",
        "url": "https://arxiv.org/pdf/1706.03762.pdf",
        "filename": "attention_is_all_you_need.pdf"
    },
    {
        "name": "BERT: Pre-training of Deep Bidirectional Transformers",
        "url": "https://arxiv.org/pdf/1810.04805.pdf",
        "filename": "bert_paper.pdf"
    },
    {
        "name": "GPT-3: Language Models are Few-Shot Learners",
        "url": "https://arxiv.org/pdf/2005.14165.pdf",
        "filename": "gpt3_paper.pdf"
    },
    {
        "name": "ResNet: Deep Residual Learning for Image Recognition",
        "url": "https://arxiv.org/pdf/1512.03385.pdf",
        "filename": "resnet_paper.pdf"
    },
    {
        "name": "Vision Transformer (ViT)",
        "url": "https://arxiv.org/pdf/2010.11929.pdf",
        "filename": "vision_transformer.pdf"
    },
    {
        "name": "CLIP: Learning Transferable Visual Models",
        "url": "https://arxiv.org/pdf/2103.00020.pdf",
        "filename": "clip_paper.pdf"
    },
    {
        "name": "Stable Diffusion: High-Resolution Image Synthesis",
        "url": "https://arxiv.org/pdf/2112.10752.pdf",
        "filename": "stable_diffusion.pdf"
    },
    {
        "name": "LLaMA: Open and Efficient Foundation Language Models",
        "url": "https://arxiv.org/pdf/2302.13971.pdf",
        "filename": "llama_paper.pdf"
    }
]


def download_paper(paper_info):
    """Download m·ªôt paper t·ª´ URL"""
    url = paper_info["url"]
    filename = paper_info["filename"]
    name = paper_info["name"]
    filepath = PDF_DIR / filename
    
    # Ki·ªÉm tra n·∫øu ƒë√£ t·ªìn t·∫°i
    if filepath.exists():
        print(f"‚úì {name} - ƒê√£ t·ªìn t·∫°i, b·ªè qua")
        return True
    
    print(f"‚¨áÔ∏è  ƒêang t·∫£i: {name}...")
    
    try:
        # Download v·ªõi stream ƒë·ªÉ x·ª≠ l√Ω files l·ªõn
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()
        
        # L∆∞u file
        with open(filepath, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        file_size_mb = filepath.stat().st_size / (1024 * 1024)
        print(f"‚úì {name} - Ho√†n th√†nh ({file_size_mb:.2f} MB)")
        return True
        
    except requests.exceptions.RequestException as e:
        print(f"‚úó {name} - L·ªói: {str(e)}")
        # X√≥a file n·∫øu download kh√¥ng ho√†n ch·ªânh
        if filepath.exists():
            filepath.unlink()
        return False
    except Exception as e:
        print(f"‚úó {name} - L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}")
        if filepath.exists():
            filepath.unlink()
        return False


def main():
    """Main function"""
    print("=" * 70)
    print("üìö DOWNLOAD AI RESEARCH PAPERS")
    print("=" * 70)
    print()
    
    print(f"Th∆∞ m·ª•c l∆∞u tr·ªØ: {PDF_DIR.absolute()}")
    print(f"S·ªë l∆∞·ª£ng papers: {len(PAPERS)}")
    print()
    
    # H·ªèi user mu·ªën download papers n√†o
    print("Ch·ªçn papers mu·ªën download:")
    print("0. T·∫•t c·∫£ papers")
    for idx, paper in enumerate(PAPERS, 1):
        print(f"{idx}. {paper['name']}")
    print()
    
    choice = input("Nh·∫≠p l·ª±a ch·ªçn (0 ho·∫∑c s·ªë paper, c√°ch nhau b·ªüi d·∫•u ph·∫©y): ").strip()
    
    # Parse choices
    if choice == "0":
        selected_papers = PAPERS
    else:
        try:
            indices = [int(x.strip()) for x in choice.split(",")]
            selected_papers = [PAPERS[i-1] for i in indices if 1 <= i <= len(PAPERS)]
        except (ValueError, IndexError):
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")
            return
    
    if not selected_papers:
        print("‚ùå Kh√¥ng c√≥ paper n√†o ƒë∆∞·ª£c ch·ªçn!")
        return
    
    print()
    print(f"S·∫Ω download {len(selected_papers)} paper(s)...")
    print()
    
    # Download papers
    success_count = 0
    for paper in selected_papers:
        if download_paper(paper):
            success_count += 1
        print()
    
    # Summary
    print("=" * 70)
    print(f"‚úì Ho√†n th√†nh: {success_count}/{len(selected_papers)} papers")
    print(f"üìÅ V·ªã tr√≠: {PDF_DIR.absolute()}")
    print()
    print("B∆∞·ªõc ti·∫øp theo:")
    print("1. Kh·ªüi ƒë·ªông server: cd src && python main.py")
    print("2. Truy c·∫≠p: http://localhost:8000")
    print("3. Nh·∫•n 'Index Documents' ƒë·ªÉ x·ª≠ l√Ω papers")
    print("4. B·∫Øt ƒë·∫ßu ƒë·∫∑t c√¢u h·ªèi!")
    print("=" * 70)


if __name__ == "__main__":
    main()