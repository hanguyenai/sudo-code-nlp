{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanguyenai/sudo-code-nlp/blob/main/06_transformer_machine_translation/EVBCorpus_English_Vietnamese_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OoHhVOe0lQ8"
      },
      "source": [
        "# 1 Importing dependencies\n",
        "Initialize the workspace for Transformer NMT on **EVBCorpus** — import libraries, define constants, fix random seeds for reproducibility, select device (GPU/CPU), and fetch the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DtVc1jn0yRG",
        "outputId": "91cd6fa5-f3f6-4641-e848-92ad6ed51496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (5.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.32.4)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.3)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: rarfile, portalocker, colorama, sacrebleu, torchtext\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 rarfile-4.2 sacrebleu-2.5.1 torchtext-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu sentencepiece torchtext rarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vT1sRK5P0Ayy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import sacrebleu\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import os\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "import rarfile\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsor3--k10Ks",
        "outputId": "93d278f0-709f-4250-fabb-bc322ab397d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Special tokens\n",
        "PAD = '<pad>'\n",
        "UNK = '<unk>'\n",
        "BOS = '<sos>'\n",
        "EOS = '<eos>'\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wFwRgYABDbh",
        "outputId": "c65435e9-42da-4c7b-879b-ea930e396fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EVBCorpus'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Total 35 (delta 0), reused 0 (delta 0), pack-reused 35 (from 1)\u001b[K\n",
            "Receiving objects: 100% (35/35), 35.37 MiB | 34.33 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/qhungngo/EVBCorpus.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  2 Data Ingestion & SGML Parsing\n",
        "Extract clean English–Vietnamese sentence pairs from EVBCorpus SGML/XML files into a tidy `pandas.DataFrame` for training.\n"
      ],
      "metadata": {
        "id": "NjX-Ucscxs3z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ClVlsL2L6Ld8"
      },
      "outputs": [],
      "source": [
        "def parse_sgml_file(sgml_path):\n",
        "    \"\"\"Parse a single SGML file and extract English-Vietnamese sentence pairs\"\"\"\n",
        "    try:\n",
        "        # Read file content\n",
        "        with open(sgml_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Parse with BeautifulSoup (handles SGML/XML-like formats)\n",
        "        soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "        pairs = []\n",
        "\n",
        "        # Find all sentence pairs\n",
        "        for spair in soup.find_all('spair'):\n",
        "            en_text = \"\"\n",
        "            vi_text = \"\"\n",
        "\n",
        "            # Get all <s> tags in this spair\n",
        "            s_tags = spair.find_all('s')\n",
        "\n",
        "            for s in s_tags:\n",
        "                s_id = s.get('id', '')\n",
        "                text = s.get_text(strip=True)\n",
        "\n",
        "                # Identify English vs Vietnamese by id prefix\n",
        "                if s_id.startswith('en'):\n",
        "                    en_text = text\n",
        "                elif s_id.startswith('vn'):\n",
        "                    vi_text = text\n",
        "\n",
        "            # Only add if both sentences exist and are non-empty\n",
        "            if en_text and vi_text:\n",
        "                pairs.append({\n",
        "                    'english': en_text,\n",
        "                    'vietnamese': vi_text\n",
        "                })\n",
        "\n",
        "        return pairs\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Error parsing {os.path.basename(sgml_path)}: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cceqdx78KvPv"
      },
      "outputs": [],
      "source": [
        "def load_evbcorpus_to_dataframe(extract_dir):\n",
        "    \"\"\"Load all SGML files from EVBCorpus and create pandas DataFrame\"\"\"\n",
        "    print(\"\\n📖 Parsing SGML files...\")\n",
        "\n",
        "    # Find all SGML/XML files\n",
        "    sgml_files = []\n",
        "    for root, dirs, files in os.walk(extract_dir):\n",
        "        for f in files:\n",
        "            if f.endswith('.xml') or f.endswith('.sgml'):\n",
        "                sgml_files.append(os.path.join(root, f))\n",
        "\n",
        "    if not sgml_files:\n",
        "        print(\"⚠️  No SGML/XML files found!\")\n",
        "        print(f\"Searched in: {extract_dir}\")\n",
        "        print(\"\\nTrying to find all files...\")\n",
        "        all_files = []\n",
        "        for root, dirs, files in os.walk(extract_dir):\n",
        "            all_files.extend([os.path.join(root, f) for f in files[:5]])\n",
        "        print(f\"Found files: {all_files[:10]}\")\n",
        "        raise FileNotFoundError(\"No SGML/XML files found in extracted directory\")\n",
        "\n",
        "    print(f\"Found {len(sgml_files)} SGML/XML files\")\n",
        "\n",
        "    # Parse all SGML files\n",
        "    all_pairs = []\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    for sgml_file in tqdm(sgml_files, desc=\"Parsing SGML\"):\n",
        "        pairs = parse_sgml_file(sgml_file)\n",
        "        all_pairs.extend(pairs)\n",
        "\n",
        "    if not all_pairs:\n",
        "        raise ValueError(\"No sentence pairs found! Check SGML file format.\")\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(all_pairs)\n",
        "\n",
        "    # Remove duplicates\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    print(f\"\\n✓ Loaded {len(df):,} sentence pairs\")\n",
        "    print(f\"  Unique pairs: {len(df):,}\")\n",
        "    print(f\"\\nDataFrame Info:\")\n",
        "    print(f\"  Shape: {df.shape}\")\n",
        "    print(f\"  Columns: {df.columns.tolist()}\")\n",
        "\n",
        "    # Show statistics\n",
        "    print(f\"\\nSentence Length Statistics:\")\n",
        "    df['en_words'] = df['english'].str.split().str.len()\n",
        "    df['vi_words'] = df['vietnamese'].str.split().str.len()\n",
        "    print(f\"  English words: mean={df['en_words'].mean():.1f}, max={df['en_words'].max()}\")\n",
        "    print(f\"  Vietnamese words: mean={df['vi_words'].mean():.1f}, max={df['vi_words'].max()}\")\n",
        "\n",
        "    # Drop temporary columns\n",
        "    df = df.drop(['en_words', 'vi_words'], axis=1)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RBiVuqFKLvSF"
      },
      "outputs": [],
      "source": [
        "rar_path = \"/content/EVBCorpus/EVBCorpus_EVBNews_v2.0.rar\"\n",
        "out_dir = \"/content/evbcorpus_data/EVBCorpus_v2\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "with rarfile.RarFile(rar_path) as rf:\n",
        "    # rf.printdir()  # xem list file\n",
        "    rf.extractall(path=out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq8HgnFIKzC4",
        "outputId": "2efe7c88-7cbf-4a0d-e78f-968a784534ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "EVBCorpus v2.0 - SGML Parser\n",
            "================================================================================\n",
            "\n",
            "📖 Parsing SGML files...\n",
            "Found 1000 SGML/XML files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parsing SGML: 100%|██████████| 1000/1000 [00:11<00:00, 84.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Loaded 43,695 sentence pairs\n",
            "  Unique pairs: 43,695\n",
            "\n",
            "DataFrame Info:\n",
            "  Shape: (43695, 2)\n",
            "  Columns: ['english', 'vietnamese']\n",
            "\n",
            "Sentence Length Statistics:\n",
            "  English words: mean=19.6, max=149\n",
            "  Vietnamese words: mean=26.8, max=185\n",
            "\n",
            "📊 Sample data from DataFrame:\n",
            "================================================================================\n",
            "                                                           english                                                       vietnamese\n",
            "0                   Tattoos linked to rare skin infection , CDC...            Xăm mình gây ra một nhiễm trùng da hiếm , theo CDC...\n",
            "1  At least two otherwise healthy men appear to have acquired a...  Ít nhất hai người đàn ông đáng lẽ khỏe mạnh dường như đã mắc...\n",
            "2  Although no evidence was found to link the use of tap water ...  Mặc dù không tìm thấy bằng chứng liên hệ việc sử dụng nước m...\n",
            "3  One case is confirmed , the other is as yet unconfirmed say ...  Một trường hợp đã được xác nhận , và một trường hợp khác cho...\n",
            "4  The confirmed case is of a healthy 44-year-old man who recei...  Trường hợp xác nhận là người đàn ông 44 tuổi khoẻ mạnh , xăm...\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Download and parse corpus\n",
        "print(\"=\" * 80)\n",
        "print(\"EVBCorpus v2.0 - SGML Parser\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "extract_dir = out_dir\n",
        "corpus_df = load_evbcorpus_to_dataframe(extract_dir)\n",
        "\n",
        "# Display sample data\n",
        "print(\"\\n📊 Sample data from DataFrame:\")\n",
        "print(\"=\" * 80)\n",
        "display_df = corpus_df.head(5).copy()\n",
        "display_df['english'] = display_df['english'].str[:60] + '...'\n",
        "display_df['vietnamese'] = display_df['vietnamese'].str[:60] + '...'\n",
        "print(display_df.to_string(index=True))\n",
        "print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AQbOADRhNJ29"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(w, max_length=None):\n",
        "    \"\"\"Preprocess a sentence (TensorFlow/Keras style)\"\"\"\n",
        "    w = w.lower().strip()\n",
        "\n",
        "    # Add space around punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # Replace multiple spaces with single space\n",
        "    w = re.sub(r'\\s+', ' ', w)\n",
        "    w = w.strip()\n",
        "\n",
        "    # Truncate to max_length if specified\n",
        "    if max_length:\n",
        "        w = \" \".join(w.split()[:max_length])\n",
        "\n",
        "    # Add start and end tokens\n",
        "    w = '{} {} {}'.format(BOS, w, EOS)\n",
        "\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sMA8TOumNLQh"
      },
      "outputs": [],
      "source": [
        "def display_samples(inp_lines, targ_lines, num_of_pairs=5):\n",
        "    \"\"\"Display sample data pairs\"\"\"\n",
        "    pairs = list(zip(inp_lines[:num_of_pairs], targ_lines[:num_of_pairs]))\n",
        "\n",
        "    print('=' * 70)\n",
        "    print('SAMPLE DATA')\n",
        "    print('=' * 70)\n",
        "\n",
        "    for i, (inp, targ) in enumerate(pairs):\n",
        "        print(f'\\n--> Sample {i + 1}:')\n",
        "        print(f'    Input:  {inp}')\n",
        "        print(f'    Target: {targ}')\n",
        "\n",
        "    print('\\n' + '=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Data Preparation & Tokenization\n",
        "Define reusable utilities to go from a clean `DataFrame` of EN–VI sentence pairs → token IDs & padded mini-batches, ready for a Transformer."
      ],
      "metadata": {
        "id": "U2mksPRBzZWn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rkHVqFTuNOmO"
      },
      "outputs": [],
      "source": [
        "def load_data_from_dataframe(df, max_samples=None, max_length=100):\n",
        "    \"\"\"Load and preprocess data from pandas DataFrame\"\"\"\n",
        "    print(f\"\\n📖 Loading data from DataFrame...\")\n",
        "    print(f\"  Total pairs: {len(df):,}\")\n",
        "\n",
        "    # Get English and Vietnamese sentences\n",
        "    en_sentences = df['english'].tolist()\n",
        "    vi_sentences = df['vietnamese'].tolist()\n",
        "\n",
        "    print(f\"\\n🧹 Preprocessing sentences...\")\n",
        "    en_preprocessed = []\n",
        "    vi_preprocessed = []\n",
        "\n",
        "    for en, vi in tqdm(zip(en_sentences, vi_sentences), total=len(en_sentences), desc=\"Processing\"):\n",
        "        en_prep = preprocess_sentence(en, max_length=max_length)\n",
        "        vi_prep = preprocess_sentence(vi, max_length=max_length)\n",
        "\n",
        "        # Filter out empty sentences\n",
        "        if len(en_prep.split()) > 2 and len(vi_prep.split()) > 2:  # More than BOS+EOS\n",
        "            en_preprocessed.append(en_prep)\n",
        "            vi_preprocessed.append(vi_prep)\n",
        "\n",
        "    print(f\"✓ After preprocessing: {len(en_preprocessed):,} sentences\")\n",
        "\n",
        "    if max_samples:\n",
        "        en_preprocessed = en_preprocessed[:max_samples]\n",
        "        vi_preprocessed = vi_preprocessed[:max_samples]\n",
        "        print(f\"✓ Using {max_samples:,} samples\")\n",
        "\n",
        "    # Display samples\n",
        "    display_samples(en_preprocessed, vi_preprocessed, num_of_pairs=3)\n",
        "\n",
        "    return en_preprocessed, vi_preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "b1lEeM9X6v30"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "    \"\"\"Tokenizer similar to TensorFlow/Keras Tokenizer\"\"\"\n",
        "    def __init__(self, num_words=None, oov_token='<unk>'):\n",
        "        self.num_words = num_words\n",
        "        self.oov_token = oov_token\n",
        "\n",
        "        self.word_index = {}  # word -> index mapping\n",
        "        self.index_word = {}  # index -> word mapping\n",
        "        self.word_counts = Counter()\n",
        "\n",
        "        # Initialize with special tokens\n",
        "        self.word_index = {\n",
        "            PAD: 0,\n",
        "            BOS: 1,\n",
        "            EOS: 2,\n",
        "            UNK: 3\n",
        "        }\n",
        "        self.index_word = {v: k for k, v in self.word_index.items()}\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        \"\"\"Build vocabulary from texts\"\"\"\n",
        "        print(f\"🔧 Building vocabulary...\")\n",
        "\n",
        "        # Count words\n",
        "        for text in tqdm(texts, desc=\"Counting words\"):\n",
        "            words = text.split()\n",
        "            self.word_counts.update(words)\n",
        "\n",
        "        # Build word_index based on frequency\n",
        "        sorted_words = sorted(self.word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Start from index 4 (after special tokens)\n",
        "        idx = 4\n",
        "        for word, count in sorted_words:\n",
        "            if word not in self.word_index:\n",
        "                if self.num_words is None or idx < self.num_words:\n",
        "                    self.word_index[word] = idx\n",
        "                    self.index_word[idx] = word\n",
        "                    idx += 1\n",
        "\n",
        "        vocab_size = len(self.word_index)\n",
        "        print(f\"✓ Vocabulary size: {vocab_size:,}\")\n",
        "        print(f\"  Total unique words: {len(self.word_counts):,}\")\n",
        "        if self.num_words:\n",
        "            print(f\"  Kept top {self.num_words:,} words\")\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        \"\"\"Convert texts to sequences of integers\"\"\"\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            words = text.split()\n",
        "            sequence = []\n",
        "            for word in words:\n",
        "                if word in self.word_index:\n",
        "                    sequence.append(self.word_index[word])\n",
        "                else:\n",
        "                    sequence.append(self.word_index[UNK])\n",
        "            sequences.append(sequence)\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        \"\"\"Convert sequences of integers back to texts\"\"\"\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            words = []\n",
        "            for idx in sequence:\n",
        "                if idx in self.index_word:\n",
        "                    word = self.index_word[idx]\n",
        "                    # Skip special tokens except for visualization\n",
        "                    if word not in [PAD, BOS, EOS]:\n",
        "                        words.append(word)\n",
        "                else:\n",
        "                    words.append(UNK)\n",
        "            texts.append(' '.join(words))\n",
        "        return texts\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        \"\"\"Get vocabulary size\"\"\"\n",
        "        return len(self.word_index)\n",
        "\n",
        "    def save(self, filepath):\n",
        "        \"\"\"Save tokenizer\"\"\"\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'word_index': self.word_index,\n",
        "                'index_word': self.index_word,\n",
        "                'word_counts': self.word_counts,\n",
        "                'num_words': self.num_words,\n",
        "                'oov_token': self.oov_token\n",
        "            }, f)\n",
        "\n",
        "    def load(self, filepath):\n",
        "        \"\"\"Load tokenizer\"\"\"\n",
        "        with open(filepath, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self.word_index = data['word_index']\n",
        "            self.index_word = data['index_word']\n",
        "            self.word_counts = data['word_counts']\n",
        "            self.num_words = data['num_words']\n",
        "            self.oov_token = data['oov_token']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-2kjrgxN71xc"
      },
      "outputs": [],
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    \"\"\"Dataset for translation task\"\"\"\n",
        "    def __init__(self, src_sequences, trg_sequences, max_len=None):\n",
        "        self.src_sequences = src_sequences\n",
        "        self.trg_sequences = trg_sequences\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src_sequences[idx]\n",
        "        trg = self.trg_sequences[idx]\n",
        "\n",
        "        # Truncate if too long\n",
        "        if self.max_len:\n",
        "            src = src[:self.max_len]\n",
        "            trg = trg[:self.max_len]\n",
        "\n",
        "        src = torch.tensor(src, dtype=torch.long)\n",
        "        trg = torch.tensor(trg, dtype=torch.long)\n",
        "        return src, trg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "etGSHqXpc2M-"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for DataLoader with padding\"\"\"\n",
        "    src_batch, trg_batch = zip(*batch)\n",
        "\n",
        "    # Pad sequences\n",
        "    src_batch = nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    trg_batch = nn.utils.rnn.pad_sequence(trg_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    return src_batch, trg_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Transformer Model & Training Utilities\n",
        "Build an end-to-end Transformer model for English–Vietnamese translation with key components: positional encoding, transformer encoder-decoder, training loop, evaluation, translation, and BLEU scoring.  "
      ],
      "metadata": {
        "id": "H2PdAex30GQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Positional Encoding\n",
        "Adds position information to token embeddings using sinusoidal encoding, followed by dropout.\n"
      ],
      "metadata": {
        "id": "dqWQlldH1Ry1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "e6-c9uxiOXiT"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Positional encoding for Transformer\"\"\"\n",
        "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # FIX: Use torch.arange instead of torch.range (deprecated)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add positional encoding and apply dropout\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Transformer Translator\n",
        "Implements an encoder-decoder Transformer for sequence-to-sequence translation.\n"
      ],
      "metadata": {
        "id": "c43qJihZ1tSb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9eC40b5UO_CN"
      },
      "outputs": [],
      "source": [
        "class TransformerTranslator(nn.Module):\n",
        "    \"\"\"Transformer model for translation\"\"\"\n",
        "    def __init__(self, src_vocab_size, trg_vocab_size, d_model=512, nhead=8,\n",
        "                 num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048,\n",
        "                 dropout=0.1, max_len=200):\n",
        "        super(TransformerTranslator, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.trg_embedding = nn.Embedding(trg_vocab_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len=max_len, dropout=dropout)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"Initialize weights\"\"\"\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        \"\"\"Generate mask for target sequence\"\"\"\n",
        "        mask = torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n",
        "        return mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \"\"\"Forward pass\"\"\"\n",
        "        # Create masks\n",
        "        trg_mask = self.generate_square_subsequent_mask(trg.size(1)).to(src.device)\n",
        "        src_padding_mask = (src == 0)\n",
        "        trg_padding_mask = (trg == 0)\n",
        "\n",
        "        # Embeddings with scaling\n",
        "        src_emb = self.pos_encoder(self.src_embedding(src) * math.sqrt(self.d_model))\n",
        "        trg_emb = self.pos_encoder(self.trg_embedding(trg) * math.sqrt(self.d_model))\n",
        "\n",
        "        # Transformer\n",
        "        output = self.transformer(\n",
        "            src_emb, trg_emb,\n",
        "            tgt_mask=trg_mask,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_key_padding_mask=trg_padding_mask\n",
        "        )\n",
        "\n",
        "        return self.fc_out(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Training, Evaluation & Inference Utilities\n",
        "This section defines the helper functions used for **training**, **validation**, **translation inference**, and **BLEU evaluation**.  \n",
        "Together, they handle the full workflow from optimization to model assessment."
      ],
      "metadata": {
        "id": "lKO42fFF2QFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the Transformer for a single epoch."
      ],
      "metadata": {
        "id": "_2bgkvj626yY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "q_3TiwXGY0n5"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer, criterion, clip=1.0):\n",
        "  \"\"\"Train for one epoch\"\"\"\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  progress_bar = tqdm(dataloader, desc=\"Training\")\n",
        "  for src, trg in progress_bar:\n",
        "    src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(src, trg[:, :-1])\n",
        "\n",
        "    # Reshape for loss calculation\n",
        "    output = output.reshape(-1, output.shape[-1])\n",
        "    trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "    loss = criterion(output, trg)\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "  return epoch_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate validation or test loss without gradient updates.\n"
      ],
      "metadata": {
        "id": "fAcN4b5K28Sb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "crgy3IrqZi-5"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    \"\"\"Evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, trg in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output = model(src, trg[:, :-1])\n",
        "            output = output.reshape(-1, output.shape[-1])\n",
        "            trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform greedy decoding to translate a single input sentence.\n"
      ],
      "metadata": {
        "id": "mVTGwJ253Dl-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NLM1t15PZkch"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(model, sentence, src_tokenizer, trg_tokenizer, max_len=50):\n",
        "    \"\"\"Translate a single sentence\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Preprocess and tokenize source sentence\n",
        "    preprocessed = preprocess_sentence(sentence, max_length=max_len)\n",
        "    src_sequence = src_tokenizer.texts_to_sequences([preprocessed])[0]\n",
        "    src_tensor = torch.tensor(src_sequence).unsqueeze(0).to(device)\n",
        "\n",
        "    # Start with BOS token\n",
        "    trg_indices = [trg_tokenizer.word_index[BOS]]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            trg_tensor = torch.tensor(trg_indices).unsqueeze(0).to(device)\n",
        "\n",
        "            output = model(src_tensor, trg_tensor)\n",
        "            next_token = output.argmax(dim=-1)[:, -1].item()\n",
        "\n",
        "            trg_indices.append(next_token)\n",
        "\n",
        "            # Stop if EOS token\n",
        "            if next_token == trg_tokenizer.word_index[EOS]:\n",
        "                break\n",
        "\n",
        "    # Decode to text\n",
        "    translation = trg_tokenizer.sequences_to_texts([trg_indices])[0]\n",
        "    return translation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute corpus-level BLEU to evaluate translation quality.\n"
      ],
      "metadata": {
        "id": "8_zSBeTr3YC-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BGOX51v3Zo3X"
      },
      "outputs": [],
      "source": [
        "def calculate_bleu(model, test_texts, src_tokenizer, trg_tokenizer, sample_size=None):\n",
        "    \"\"\"Calculate BLEU score on test data\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    src_texts, trg_texts = test_texts\n",
        "\n",
        "    if sample_size:\n",
        "        indices = random.sample(range(len(src_texts)), min(sample_size, len(src_texts)))\n",
        "        src_texts = [src_texts[i] for i in indices]\n",
        "        trg_texts = [trg_texts[i] for i in indices]\n",
        "\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    print(\"Generating translations for BLEU calculation...\")\n",
        "    for src, trg in tqdm(zip(src_texts, trg_texts), total=len(src_texts)):\n",
        "        # Translate (src is already preprocessed with BOS/EOS)\n",
        "        # Remove BOS/EOS for input to translate_sentence\n",
        "        src_clean = src.replace(BOS, '').replace(EOS, '').strip()\n",
        "        pred = translate_sentence(model, src_clean, src_tokenizer, trg_tokenizer)\n",
        "\n",
        "        # Clean reference (remove BOS/EOS)\n",
        "        trg_clean = trg.replace(BOS, '').replace(EOS, '').strip()\n",
        "\n",
        "        predictions.append(pred)\n",
        "        references.append(trg_clean)\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    bleu = sacrebleu.corpus_bleu(predictions, [references])\n",
        "\n",
        "    return bleu.score, predictions, references"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Full Training & Evaluation Pipeline"
      ],
      "metadata": {
        "id": "q-3ONd3f4Gnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section integrates all components into a complete **Transformer translation workflow** — from configuration and data loading to model training, BLEU evaluation, and visualization."
      ],
      "metadata": {
        "id": "q7KP-Tlf4IcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Configuration & Data Loading\n"
      ],
      "metadata": {
        "id": "wq2aWhct4KdE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sApPKs6nZr23",
        "outputId": "ed0fcaec-c590-4b7b-be9d-dddb4e3b74cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TRANSFORMER MODEL FOR ENGLISH-VIETNAMESE TRANSLATION\n",
            "======================================================================\n",
            "\n",
            "📋 Configuration:\n",
            "  d_model: 256\n",
            "  nhead: 8\n",
            "  num_encoder_layers: 3\n",
            "  num_decoder_layers: 3\n",
            "  dim_feedforward: 512\n",
            "  dropout: 0.1\n",
            "  batch_size: 32\n",
            "  num_epochs: 50\n",
            "  learning_rate: 0.0001\n",
            "  max_len: 150\n",
            "  max_samples: None\n",
            "  max_sentence_length: 100\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"TRANSFORMER MODEL FOR ENGLISH-VIETNAMESE TRANSLATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Model configuration\n",
        "config = {\n",
        "    'd_model': 256,\n",
        "    'nhead': 8,\n",
        "    'num_encoder_layers': 3,\n",
        "    'num_decoder_layers': 3,\n",
        "    'dim_feedforward': 512,\n",
        "    'dropout': 0.1,\n",
        "    'batch_size': 32,\n",
        "    'num_epochs': 50,\n",
        "    'learning_rate': 0.0001,\n",
        "    'max_len': 150,\n",
        "    'max_samples': None,  # None for full dataset, or number like 5000 for testing\n",
        "    'max_sentence_length': 100  # Max words per sentence\n",
        "}\n",
        "\n",
        "print(\"\\n📋 Configuration:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into:\n",
        "- 80% train  \n",
        "- 10% validation  \n",
        "- 10% test  "
      ],
      "metadata": {
        "id": "tx0Ecx4U4kAc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaTw14kgZ5F3",
        "outputId": "cf685924-1faa-4070-b285-1c13934ca6e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "LOADING DATA\n",
            "======================================================================\n",
            "\n",
            "📖 Loading data from DataFrame...\n",
            "  Total pairs: 43,695\n",
            "\n",
            "🧹 Preprocessing sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 43695/43695 [00:02<00:00, 18472.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ After preprocessing: 43,695 sentences\n",
            "======================================================================\n",
            "SAMPLE DATA\n",
            "======================================================================\n",
            "\n",
            "--> Sample 1:\n",
            "    Input:  <sos> tattoos linked to rare skin infection , cdc <eos>\n",
            "    Target: <sos> xăm mình gây ra một nhiễm trùng da hiếm , theo cdc <eos>\n",
            "\n",
            "--> Sample 2:\n",
            "    Input:  <sos> at least two otherwise healthy men appear to have acquired a rare bacterial skin infection that is hard to treat with antibiotics after receiving tattoos at a parlor in seattle in the state of washington in the us , according to a report in the emerging infectious diseases journal that was e-published ahead of print on 10 august by the centers for disease control and prevention ( cdc ) . <eos>\n",
            "    Target: <sos> ít nhất hai người đàn ông đáng lẽ khỏe mạnh dường như đã mắc phải một nhiễm trùng da hiếm gặp , do vi khuẩn gây ra , và khó chữa trị bằng thuốc kháng sinh , sau khi xăm mình tại một cửa hiệu ở seattle bang washington , hoa kỳ , theo một báo cáo trên tạp chí các bệnh truyền nhiễm mới đã được xuất bản trực tuyến trước khi in vào ngày 10 tháng tám bởi trung tâm kiểm soát và phòng ngừa dịch bệnh hoa kỳ . <eos>\n",
            "\n",
            "--> Sample 3:\n",
            "    Input:  <sos> although no evidence was found to link the use of tap water to the infections , the report authors recommend that tattoo operators avoid using tap water and use sterilized water throughout their procedures . <eos>\n",
            "    Target: <sos> mặc dù không tìm thấy bằng chứng liên hệ việc sử dụng nước máy với các bệnh nhiễm trùng , các tác giả báo cáo đề nghị rằng các cửa hiệu xăm mình nên tránh sử dụng nước máy và sử dụng nước tiệt trùng trong suốt quá trình thực hiện hình xăm của họ . <eos>\n",
            "\n",
            "======================================================================\n",
            "\n",
            "📊 Data split:\n",
            "  Train: 34,956 sentences\n",
            "  Val:   4,369 sentences\n",
            "  Test:  4,370 sentences\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"LOADING DATA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Load data from DataFrame\n",
        "en_data, vi_data = load_data_from_dataframe(\n",
        "    corpus_df,\n",
        "    max_samples=config['max_samples'],\n",
        "    max_length=config['max_sentence_length']\n",
        ")\n",
        "\n",
        "# Split data: 80% train, 10% val, 10% test\n",
        "train_size = int(0.8 * len(en_data))\n",
        "val_size = int(0.1 * len(en_data))\n",
        "\n",
        "train_en = en_data[:train_size]\n",
        "train_vi = vi_data[:train_size]\n",
        "val_en = en_data[train_size:train_size+val_size]\n",
        "val_vi = vi_data[train_size:train_size+val_size]\n",
        "test_en = en_data[train_size+val_size:]\n",
        "test_vi = vi_data[train_size+val_size:]\n",
        "\n",
        "print(f\"\\n📊 Data split:\")\n",
        "print(f\"  Train: {len(train_en):,} sentences\")\n",
        "print(f\"  Val:   {len(val_en):,} sentences\")\n",
        "print(f\"  Test:  {len(test_en):,} sentences\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Tokenizer Construction\n",
        "Use TensorFlow/Keras-style tokenizers for both languages:\n",
        "- `Tokenizer(num_words=50000)` keeps top 50K tokens.  \n",
        "- Fit on training corpus (`fit_on_texts`).\n",
        "- Display sample tokenized sentences."
      ],
      "metadata": {
        "id": "AowYYD5l4vNr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhEeEAdKZ7SC",
        "outputId": "d70f2fe2-9337-46e9-8649-2a9a112b169a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "BUILDING VOCABULARIES (Keras/TensorFlow style)\n",
            "======================================================================\n",
            "\n",
            "🔤 Fitting English tokenizer...\n",
            "🔧 Building vocabulary...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting words: 100%|██████████| 34956/34956 [00:00<00:00, 240237.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Vocabulary size: 30,354\n",
            "  Total unique words: 30,352\n",
            "  Kept top 50,000 words\n",
            "🔤 Fitting Vietnamese tokenizer...\n",
            "🔧 Building vocabulary...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting words: 100%|██████████| 34956/34956 [00:00<00:00, 148170.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Vocabulary size: 13,152\n",
            "  Total unique words: 13,150\n",
            "  Kept top 50,000 words\n",
            "\n",
            "✓ English vocab size: 30,354\n",
            "✓ Vietnamese vocab size: 13,152\n",
            "\n",
            "📝 Tokenization examples:\n",
            "\n",
            "English text: <sos> tattoos linked to rare skin infection , cdc <eos>\n",
            "Sequence:     [1, 10902, 982, 7, 1368, 292, 448, 6, 3244, 2]...\n",
            "Decoded back: tattoos linked to rare skin infection , cdc\n",
            "\n",
            "Vietnamese text: <sos> xăm mình gây ra một nhiễm trùng da hiếm , theo cdc <eos>\n",
            "Sequence:        [1, 2266, 74, 164, 28, 9, 358, 516, 405, 1029, 5, 95, 2405, 2]...\n",
            "Decoded back:    xăm mình gây ra một nhiễm trùng da hiếm , theo cdc\n",
            "\n",
            "🔄 Converting texts to sequences...\n",
            "✓ Converted all texts to sequences\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BUILDING VOCABULARIES (Keras/TensorFlow style)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Initialize tokenizers\n",
        "en_tokenizer = Tokenizer(num_words=50000)  # Keep top 50K words\n",
        "vi_tokenizer = Tokenizer(num_words=50000)\n",
        "\n",
        "# Fit on training data\n",
        "print(\"\\n🔤 Fitting English tokenizer...\")\n",
        "en_tokenizer.fit_on_texts(train_en)\n",
        "\n",
        "print(\"🔤 Fitting Vietnamese tokenizer...\")\n",
        "vi_tokenizer.fit_on_texts(train_vi)\n",
        "\n",
        "print(f\"\\n✓ English vocab size: {en_tokenizer.get_vocab_size():,}\")\n",
        "print(f\"✓ Vietnamese vocab size: {vi_tokenizer.get_vocab_size():,}\")\n",
        "\n",
        "# Show tokenization examples\n",
        "print(\"\\n📝 Tokenization examples:\")\n",
        "sample_en = train_en[0]\n",
        "sample_vi = train_vi[0]\n",
        "\n",
        "en_seq = en_tokenizer.texts_to_sequences([sample_en])[0]\n",
        "vi_seq = vi_tokenizer.texts_to_sequences([sample_vi])[0]\n",
        "\n",
        "print(f\"\\nEnglish text: {sample_en}\")\n",
        "print(f\"Sequence:     {en_seq[:20]}...\")  # Show first 20 tokens\n",
        "print(f\"Decoded back: {en_tokenizer.sequences_to_texts([en_seq])[0]}\")\n",
        "\n",
        "print(f\"\\nVietnamese text: {sample_vi}\")\n",
        "print(f\"Sequence:        {vi_seq[:20]}...\")\n",
        "print(f\"Decoded back:    {vi_tokenizer.sequences_to_texts([vi_seq])[0]}\")\n",
        "\n",
        "# Convert all texts to sequences\n",
        "print(\"\\n🔄 Converting texts to sequences...\")\n",
        "train_en_seq = en_tokenizer.texts_to_sequences(train_en)\n",
        "train_vi_seq = vi_tokenizer.texts_to_sequences(train_vi)\n",
        "val_en_seq = en_tokenizer.texts_to_sequences(val_en)\n",
        "val_vi_seq = vi_tokenizer.texts_to_sequences(val_vi)\n",
        "test_en_seq = en_tokenizer.texts_to_sequences(test_en)\n",
        "test_vi_seq = vi_tokenizer.texts_to_sequences(test_vi)\n",
        "\n",
        "print(f\"✓ Converted all texts to sequences\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Dataset Preparation\n",
        "- Convert token sequences into `TranslationDataset`.\n",
        "- Apply padding and truncation (`max_len`).\n",
        "- Build DataLoaders for train, val, and test splits."
      ],
      "metadata": {
        "id": "nMKM51Hv4z7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWAv2wmWaYoy",
        "outputId": "e7aa8c63-7226-4ccc-f5c1-afed4ca12773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "CREATING DATASETS\n",
            "======================================================================\n",
            "✓ Train batches: 1093\n",
            "✓ Val batches:   137\n",
            "✓ Test batches:  137\n",
            "✓ Max sequence length: 150\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CREATING DATASETS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create datasets from sequences with max_len truncation\n",
        "train_dataset = TranslationDataset(train_en_seq, train_vi_seq, max_len=config['max_len'])\n",
        "val_dataset = TranslationDataset(val_en_seq, val_vi_seq, max_len=config['max_len'])\n",
        "test_dataset = TranslationDataset(test_en_seq, test_vi_seq, max_len=config['max_len'])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'],\n",
        "                         shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'],\n",
        "                       collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'],\n",
        "                        collate_fn=collate_fn)\n",
        "\n",
        "print(f\"✓ Train batches: {len(train_loader)}\")\n",
        "print(f\"✓ Val batches:   {len(val_loader)}\")\n",
        "print(f\"✓ Test batches:  {len(test_loader)}\")\n",
        "print(f\"✓ Max sequence length: {config['max_len']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 Model Initialization\n",
        "Instantiate `TransformerTranslator`:"
      ],
      "metadata": {
        "id": "LUZ_SRJz5LEC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G95MbOnabMS",
        "outputId": "42f0718b-e1d3-42f9-8bf7-3140521700a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "INITIALIZING MODEL\n",
            "======================================================================\n",
            "\n",
            "🤖 Model Architecture:\n",
            "  Total parameters:     18,472,288\n",
            "  Trainable parameters: 18,472,288\n",
            "  Model size:           ~73.89 MB\n",
            "✓ Loss function: CrossEntropyLoss\n",
            "✓ Optimizer: Adam (lr=0.0001)\n",
            "✓ Scheduler: ReduceLROnPlateau\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"INITIALIZING MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "model = TransformerTranslator(\n",
        "    src_vocab_size=en_tokenizer.get_vocab_size(),\n",
        "    trg_vocab_size=vi_tokenizer.get_vocab_size(),\n",
        "    d_model=config['d_model'],\n",
        "    nhead=config['nhead'],\n",
        "    num_encoder_layers=config['num_encoder_layers'],\n",
        "    num_decoder_layers=config['num_decoder_layers'],\n",
        "    dim_feedforward=config['dim_feedforward'],\n",
        "    dropout=config['dropout'],\n",
        "    max_len=config['max_len']\n",
        ").to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\n🤖 Model Architecture:\")\n",
        "print(f\"  Total parameters:     {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"  Model size:           ~{total_params * 4 / 1e6:.2f} MB\")\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "print(f\"✓ Loss function: CrossEntropyLoss\")\n",
        "print(f\"✓ Optimizer: Adam (lr={config['learning_rate']})\")\n",
        "print(f\"✓ Scheduler: ReduceLROnPlateau\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 Training Loop"
      ],
      "metadata": {
        "id": "v1qXRmmV5Ndm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orOgGL1kaeAb",
        "outputId": "18d7edb7-99d1-4ece-f433-8f5a173896b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING MODEL\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Epoch 1/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:56<00:00, 19.51it/s, loss=5.51]\n",
            "Evaluating:   0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 68.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 6.2882 | Train PPL: 538.20\n",
            "  Val Loss:   5.5721 | Val PPL:   262.97\n",
            "  Time:       58.04s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 2/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.15it/s, loss=4.81]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 73.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 5.1216 | Train PPL: 167.60\n",
            "  Val Loss:   4.9282 | Val PPL:   138.13\n",
            "  Time:       58.95s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 3/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.01it/s, loss=4.56]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 4.5395 | Train PPL: 93.64\n",
            "  Val Loss:   4.5006 | Val PPL:   90.07\n",
            "  Time:       59.35s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 4/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.98it/s, loss=3.81]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 75.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 4.1099 | Train PPL: 60.94\n",
            "  Val Loss:   4.2167 | Val PPL:   67.81\n",
            "  Time:       59.42s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 5/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.04it/s, loss=3.52]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 3.7642 | Train PPL: 43.13\n",
            "  Val Loss:   4.0176 | Val PPL:   55.57\n",
            "  Time:       59.25s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 6/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.99it/s, loss=3.31]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 75.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 3.4741 | Train PPL: 32.27\n",
            "  Val Loss:   3.8827 | Val PPL:   48.55\n",
            "  Time:       59.39s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 7/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.93it/s, loss=3.02]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 3.2190 | Train PPL: 25.00\n",
            "  Val Loss:   3.7653 | Val PPL:   43.18\n",
            "  Time:       59.59s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 8/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.08it/s, loss=3.2]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 2.9947 | Train PPL: 19.98\n",
            "  Val Loss:   3.6591 | Val PPL:   38.83\n",
            "  Time:       59.14s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 9/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.99it/s, loss=2.46]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 2.7972 | Train PPL: 16.40\n",
            "  Val Loss:   3.6296 | Val PPL:   37.70\n",
            "  Time:       59.39s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 10/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.12it/s, loss=2.91]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 2.6218 | Train PPL: 13.76\n",
            "  Val Loss:   3.5655 | Val PPL:   35.36\n",
            "  Time:       59.04s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 11/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.07it/s, loss=2.49]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 2.4644 | Train PPL: 11.76\n",
            "  Val Loss:   3.5296 | Val PPL:   34.11\n",
            "  Time:       59.18s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 12/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.05it/s, loss=2.35]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 73.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 2.3232 | Train PPL: 10.21\n",
            "  Val Loss:   3.5414 | Val PPL:   34.52\n",
            "  Time:       59.27s\n",
            "\n",
            "======================================================================\n",
            "Epoch 13/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.04it/s, loss=2.41]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 2.1978 | Train PPL: 9.01\n",
            "  Val Loss:   3.5459 | Val PPL:   34.67\n",
            "  Time:       59.26s\n",
            "\n",
            "======================================================================\n",
            "Epoch 14/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.00it/s, loss=2.15]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 2.0818 | Train PPL: 8.02\n",
            "  Val Loss:   3.4942 | Val PPL:   32.92\n",
            "  Time:       59.36s\n",
            "  ✓ Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 15/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.98it/s, loss=2.03]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.9753 | Train PPL: 7.21\n",
            "  Val Loss:   3.5054 | Val PPL:   33.30\n",
            "  Time:       59.42s\n",
            "\n",
            "======================================================================\n",
            "Epoch 16/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.97it/s, loss=2.11]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.8821 | Train PPL: 6.57\n",
            "  Val Loss:   3.5382 | Val PPL:   34.41\n",
            "  Time:       59.45s\n",
            "\n",
            "======================================================================\n",
            "Epoch 17/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.95it/s, loss=1.76]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 73.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.7913 | Train PPL: 6.00\n",
            "  Val Loss:   3.5260 | Val PPL:   33.99\n",
            "  Time:       59.55s\n",
            "\n",
            "======================================================================\n",
            "Epoch 18/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.97it/s, loss=1.51]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.6609 | Train PPL: 5.26\n",
            "  Val Loss:   3.5602 | Val PPL:   35.17\n",
            "  Time:       59.45s\n",
            "\n",
            "======================================================================\n",
            "Epoch 19/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.97it/s, loss=1.28]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 73.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.6048 | Train PPL: 4.98\n",
            "  Val Loss:   3.5950 | Val PPL:   36.41\n",
            "  Time:       59.49s\n",
            "\n",
            "======================================================================\n",
            "Epoch 20/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.99it/s, loss=1.6]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 70.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.5594 | Train PPL: 4.76\n",
            "  Val Loss:   3.5807 | Val PPL:   35.90\n",
            "  Time:       59.53s\n",
            "\n",
            "======================================================================\n",
            "Epoch 21/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.96it/s, loss=1.49]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 69.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.4943 | Train PPL: 4.46\n",
            "  Val Loss:   3.6153 | Val PPL:   37.16\n",
            "  Time:       59.63s\n",
            "\n",
            "======================================================================\n",
            "Epoch 22/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.06it/s, loss=1.65]\n",
            "Evaluating: 100%|██████████| 137/137 [00:02<00:00, 67.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.4687 | Train PPL: 4.34\n",
            "  Val Loss:   3.6206 | Val PPL:   37.36\n",
            "  Time:       59.38s\n",
            "\n",
            "======================================================================\n",
            "Epoch 23/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.02it/s, loss=1.63]\n",
            "Evaluating: 100%|██████████| 137/137 [00:02<00:00, 67.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.4462 | Train PPL: 4.25\n",
            "  Val Loss:   3.6303 | Val PPL:   37.72\n",
            "  Time:       59.52s\n",
            "\n",
            "======================================================================\n",
            "Epoch 24/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.97it/s, loss=1.44]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 69.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.4137 | Train PPL: 4.11\n",
            "  Val Loss:   3.6581 | Val PPL:   38.79\n",
            "  Time:       59.58s\n",
            "\n",
            "======================================================================\n",
            "Epoch 25/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.00it/s, loss=1.48]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 71.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.4002 | Train PPL: 4.06\n",
            "  Val Loss:   3.6547 | Val PPL:   38.65\n",
            "  Time:       59.44s\n",
            "\n",
            "======================================================================\n",
            "Epoch 26/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.02it/s, loss=1.4]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3894 | Train PPL: 4.01\n",
            "  Val Loss:   3.6691 | Val PPL:   39.22\n",
            "  Time:       59.30s\n",
            "\n",
            "======================================================================\n",
            "Epoch 27/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.04it/s, loss=1.45]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3731 | Train PPL: 3.95\n",
            "  Val Loss:   3.6816 | Val PPL:   39.71\n",
            "  Time:       59.24s\n",
            "\n",
            "======================================================================\n",
            "Epoch 28/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.02it/s, loss=1.48]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3662 | Train PPL: 3.92\n",
            "  Val Loss:   3.6792 | Val PPL:   39.61\n",
            "  Time:       59.31s\n",
            "\n",
            "======================================================================\n",
            "Epoch 29/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.96it/s, loss=1.3]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 75.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3618 | Train PPL: 3.90\n",
            "  Val Loss:   3.6912 | Val PPL:   40.09\n",
            "  Time:       59.47s\n",
            "\n",
            "======================================================================\n",
            "Epoch 30/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.95it/s, loss=1.13]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3523 | Train PPL: 3.87\n",
            "  Val Loss:   3.6904 | Val PPL:   40.06\n",
            "  Time:       59.53s\n",
            "\n",
            "======================================================================\n",
            "Epoch 31/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.02it/s, loss=1.44]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3503 | Train PPL: 3.86\n",
            "  Val Loss:   3.6964 | Val PPL:   40.30\n",
            "  Time:       59.30s\n",
            "\n",
            "======================================================================\n",
            "Epoch 32/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.91it/s, loss=1.47]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3476 | Train PPL: 3.85\n",
            "  Val Loss:   3.6930 | Val PPL:   40.16\n",
            "  Time:       59.65s\n",
            "\n",
            "======================================================================\n",
            "Epoch 33/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.03it/s, loss=1.27]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 75.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3428 | Train PPL: 3.83\n",
            "  Val Loss:   3.6984 | Val PPL:   40.38\n",
            "  Time:       59.27s\n",
            "\n",
            "======================================================================\n",
            "Epoch 34/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.89it/s, loss=1.24]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3409 | Train PPL: 3.82\n",
            "  Val Loss:   3.6997 | Val PPL:   40.43\n",
            "  Time:       59.69s\n",
            "\n",
            "======================================================================\n",
            "Epoch 35/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.96it/s, loss=1.3]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3394 | Train PPL: 3.82\n",
            "  Val Loss:   3.7005 | Val PPL:   40.47\n",
            "  Time:       59.50s\n",
            "\n",
            "======================================================================\n",
            "Epoch 36/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.02it/s, loss=1.31]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3381 | Train PPL: 3.81\n",
            "  Val Loss:   3.6991 | Val PPL:   40.41\n",
            "  Time:       59.31s\n",
            "\n",
            "======================================================================\n",
            "Epoch 37/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.95it/s, loss=1.61]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3387 | Train PPL: 3.81\n",
            "  Val Loss:   3.7013 | Val PPL:   40.50\n",
            "  Time:       59.51s\n",
            "\n",
            "======================================================================\n",
            "Epoch 38/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.91it/s, loss=1.47]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 75.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3358 | Train PPL: 3.80\n",
            "  Val Loss:   3.7033 | Val PPL:   40.58\n",
            "  Time:       59.62s\n",
            "\n",
            "======================================================================\n",
            "Epoch 39/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.99it/s, loss=1.39]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3350 | Train PPL: 3.80\n",
            "  Val Loss:   3.7004 | Val PPL:   40.47\n",
            "  Time:       59.42s\n",
            "\n",
            "======================================================================\n",
            "Epoch 40/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.04it/s, loss=1.29]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 71.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3359 | Train PPL: 3.80\n",
            "  Val Loss:   3.7009 | Val PPL:   40.48\n",
            "  Time:       59.33s\n",
            "\n",
            "======================================================================\n",
            "Epoch 41/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.01it/s, loss=1.26]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 69.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3344 | Train PPL: 3.80\n",
            "  Val Loss:   3.7014 | Val PPL:   40.50\n",
            "  Time:       59.47s\n",
            "\n",
            "======================================================================\n",
            "Epoch 42/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.02it/s, loss=1.26]\n",
            "Evaluating: 100%|██████████| 137/137 [00:02<00:00, 67.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3347 | Train PPL: 3.80\n",
            "  Val Loss:   3.7018 | Val PPL:   40.52\n",
            "  Time:       59.53s\n",
            "\n",
            "======================================================================\n",
            "Epoch 43/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.93it/s, loss=1.25]\n",
            "Evaluating: 100%|██████████| 137/137 [00:02<00:00, 66.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3345 | Train PPL: 3.80\n",
            "  Val Loss:   3.7009 | Val PPL:   40.48\n",
            "  Time:       59.81s\n",
            "\n",
            "======================================================================\n",
            "Epoch 44/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.99it/s, loss=1.51]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 68.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3341 | Train PPL: 3.80\n",
            "  Val Loss:   3.7021 | Val PPL:   40.53\n",
            "  Time:       59.55s\n",
            "\n",
            "======================================================================\n",
            "Epoch 45/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.94it/s, loss=1.58]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 71.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3332 | Train PPL: 3.79\n",
            "  Val Loss:   3.7024 | Val PPL:   40.54\n",
            "  Time:       59.66s\n",
            "\n",
            "======================================================================\n",
            "Epoch 46/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 19.02it/s, loss=1.56]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 73.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3322 | Train PPL: 3.79\n",
            "  Val Loss:   3.7024 | Val PPL:   40.54\n",
            "  Time:       59.34s\n",
            "\n",
            "======================================================================\n",
            "Epoch 47/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.91it/s, loss=1.27]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 75.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3337 | Train PPL: 3.80\n",
            "  Val Loss:   3.7022 | Val PPL:   40.54\n",
            "  Time:       59.64s\n",
            "\n",
            "======================================================================\n",
            "Epoch 48/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.90it/s, loss=1.53]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3323 | Train PPL: 3.79\n",
            "  Val Loss:   3.7014 | Val PPL:   40.51\n",
            "  Time:       59.68s\n",
            "\n",
            "======================================================================\n",
            "Epoch 49/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.87it/s, loss=1.11]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 74.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3327 | Train PPL: 3.79\n",
            "  Val Loss:   3.7020 | Val PPL:   40.53\n",
            "  Time:       59.76s\n",
            "\n",
            "======================================================================\n",
            "Epoch 50/50\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1093/1093 [00:57<00:00, 18.90it/s, loss=1.41]\n",
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 75.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Results:\n",
            "  Train Loss: 1.3332 | Train PPL: 3.79\n",
            "  Val Loss:   3.7023 | Val PPL:   40.54\n",
            "  Time:       59.66s\n",
            "\n",
            "======================================================================\n",
            "✓ Training completed in 49.59 minutes\n",
            "  Average time per epoch: 0.99 minutes\n",
            "\n",
            "======================================================================\n",
            "STEP 6: LOADING BEST MODEL\n",
            "======================================================================\n",
            "✓ Loaded best model from epoch 14\n",
            "  Val Loss: 3.4942\n",
            "  Val PPL:  32.92\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TRAINING MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(config['num_epochs']):\n",
        "    epoch_start = time.time()\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Train\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "\n",
        "    # Validate\n",
        "    val_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    # Record losses\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\n📊 Results:\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train PPL: {math.exp(train_loss):.2f}\")\n",
        "    print(f\"  Val Loss:   {val_loss:.4f} | Val PPL:   {math.exp(val_loss):.2f}\")\n",
        "    print(f\"  Time:       {epoch_time:.2f}s\")\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'config': config\n",
        "        }, 'best_model.pt')\n",
        "        print(\"  ✓ Best model saved!\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"✓ Training completed in {total_time/60:.2f} minutes\")\n",
        "print(f\"  Average time per epoch: {total_time/config['num_epochs']/60:.2f} minutes\")\n",
        "\n",
        "# ============================================================================\n",
        "# Cell 19: Load Best Model\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 6: LOADING BEST MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "checkpoint = torch.load('best_model.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "print(f\"✓ Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
        "print(f\"  Val Loss: {checkpoint['val_loss']:.4f}\")\n",
        "print(f\"  Val PPL:  {math.exp(checkpoint['val_loss']):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.6 Testing & BLEU Evaluation\n",
        "* Evaluate final model on test set.\n",
        "* Compute Test Loss, Perplexity, and BLEU score\n",
        "* Display a few sample translations for inspection."
      ],
      "metadata": {
        "id": "oN1A6cxn5Pi5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kKSB4B2RboK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a64ae72-6660-4533-d5ac-2fe5d2a13fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUATING ON TEST SET\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 137/137 [00:01<00:00, 73.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Test Results:\n",
            "  Test Loss:       3.5257\n",
            "  Test Perplexity: 33.98\n",
            "\n",
            "======================================================================\n",
            "STEP 8: CALCULATING BLEU SCORE\n",
            "======================================================================\n",
            "Generating translations for BLEU calculation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 BLEU Score: 17.16\n",
            "\n",
            "📝 Sample Translations:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "[Example 1]\n",
            "Source:     if not , it could be a loser .\n",
            "Reference:  bạn phải đưa ra nguyên tắc , luật lệ đúng nơi đúng chỗ , vì vậy con bạn biết là các nguyên tắc ấy có thể bị phá vỡ . short cho biết .\n",
            "Prediction: bạn phải có những quy định trong nơi mà trẻ biết rằng chúng có thể bị vỡ , ngắn gọn , nói .\n",
            "\n",
            "[Example 2]\n",
            "Source:     arguably , security matters most to windows 7 's success , and to how consumers and it administrators view the new os .\n",
            "Reference:  mặc dù phổ biến hơn so với tập tin . rar được mã hóa , chúng ít có khả năng đính kém vào các thư điện tử độc hại hơn .\n",
            "Prediction: mặc dù họ thường thấy được mã hóa trên máy tính xách tay , họ đã được mang đến gần đây ít có khả năng gắn với e-mail .\n",
            "\n",
            "[Example 3]\n",
            "Source:     here 's why :\n",
            "Reference:  ồ , nó ở đó kìa !\n",
            "Prediction: anh ấy là anh ấy ! ! ! .\n",
            "\n",
            "[Example 4]\n",
            "Source:     1 . the enterprise relies on security\n",
            "Reference:  bà nói rằng dựa vào điều đó và việc chủ tịch trung quốc hồ cẩm đào đã cam kết sẽ tiếp tục tăng giá đồng tiền , bộ tài chính không còn gọi trung quốc là một kẻ thao túng thị trường tiền tệ khi gần đây bộ đưa ra một báo cáo nửa năm về ngoại tệ .\n",
            "Prediction: cô ấy nói rằng dựa trên thực tế và thực tế của trung quốc hồ cẩm chướng đã tiến bộ tiền tệ quốc gia vào việc tiếp tục diễn bộ tài chính , bộ tài khoản ngân hàng không hề biết một báo cáo mới khi nào đó một báo\n",
            "\n",
            "[Example 5]\n",
            "Source:     there 's nothing worse for an enterprise than deploying an operating system that fails to offer the kind of security it expects .\n",
            "Reference:  kỹ thuật đo nhiệt độ ở miệng : quá trình này cũng dễ dàng đối với trẻ lớn tuổi hơn và chịu hợp tác .\n",
            "Prediction: để mất nhiệt độ răng miệng : đây dễ dễ nhìn vào một chút , hợp tác với trẻ lớn tuổi .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EVALUATING ON TEST SET\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "test_loss = evaluate(model, test_loader, criterion)\n",
        "test_ppl = math.exp(test_loss)\n",
        "\n",
        "print(f\"\\n📊 Test Results:\")\n",
        "print(f\"  Test Loss:       {test_loss:.4f}\")\n",
        "print(f\"  Test Perplexity: {test_ppl:.2f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Cell 21: Calculate BLEU Score\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 8: CALCULATING BLEU SCORE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "bleu_score, predictions, references = calculate_bleu(\n",
        "    model, (test_en, test_vi), en_tokenizer, vi_tokenizer, sample_size=100\n",
        ")\n",
        "\n",
        "print(f\"\\n🎯 BLEU Score: {bleu_score:.2f}\")\n",
        "\n",
        "print(\"\\n📝 Sample Translations:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for i in range(min(5, len(predictions))):\n",
        "    # Clean test sentences (remove BOS/EOS for display)\n",
        "    test_en_clean = test_en[i].replace(BOS, '').replace(EOS, '').strip()\n",
        "\n",
        "    print(f\"\\n[Example {i+1}]\")\n",
        "    print(f\"Source:     {test_en_clean}\")\n",
        "    print(f\"Reference:  {references[i]}\")\n",
        "    print(f\"Prediction: {predictions[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.7 Visualization"
      ],
      "metadata": {
        "id": "w82lN0j25qFg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EKs9WrUJb5gg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "48f8cb7b-f68c-4824-b047-cbbb27c4491a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "VISUALIZING RESULTS\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Training curves saved to 'training_curves.png'\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"VISUALIZING RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "plt.plot(epochs, train_losses, 'bo-', label='Train Loss', linewidth=2, markersize=6)\n",
        "plt.plot(epochs, val_losses, 'rs-', label='Val Loss', linewidth=2, markersize=6)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Perplexity plot\n",
        "plt.subplot(1, 2, 2)\n",
        "train_ppls = [math.exp(loss) for loss in train_losses]\n",
        "val_ppls = [math.exp(loss) for loss in val_losses]\n",
        "plt.plot(epochs, train_ppls, 'bo-', label='Train Perplexity', linewidth=2, markersize=6)\n",
        "plt.plot(epochs, val_ppls, 'rs-', label='Val Perplexity', linewidth=2, markersize=6)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Perplexity', fontsize=12)\n",
        "plt.title('Training and Validation Perplexity', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Training curves saved to 'training_curves.png'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "l0jRXG75b7fj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39adff8d-8d05-4e04-b13f-ca3cd61017ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SAVING RESULTS\n",
            "======================================================================\n",
            "✓ Results saved to 'results.pkl'\n",
            "✓ Tokenizers saved to 'en_tokenizer.pkl' and 'vi_tokenizer.pkl'\n",
            "✓ Best model saved to 'best_model.pt'\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SAVING RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_perplexity': test_ppl,\n",
        "    'bleu_score': bleu_score,\n",
        "    'config': config,\n",
        "    'vocab_sizes': {\n",
        "        'en': en_tokenizer.get_vocab_size(),\n",
        "        'vi': vi_tokenizer.get_vocab_size()\n",
        "    },\n",
        "    'training_time': total_time,\n",
        "    'train_losses': train_losses,\n",
        "    'val_losses': val_losses\n",
        "}\n",
        "\n",
        "with open('results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "\n",
        "# Save tokenizers\n",
        "en_tokenizer.save('en_tokenizer.pkl')\n",
        "vi_tokenizer.save('vi_tokenizer.pkl')\n",
        "\n",
        "print(\"✓ Results saved to 'results.pkl'\")\n",
        "print(\"✓ Tokenizers saved to 'en_tokenizer.pkl' and 'vi_tokenizer.pkl'\")\n",
        "print(\"✓ Best model saved to 'best_model.pt'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.8 Final Report"
      ],
      "metadata": {
        "id": "Yr4S6HTC6dW1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OArymzMUb9vv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978fe2eb-b2a6-40ba-85ff-d76f5f714a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "FINAL TRANSLATION QUALITY REPORT\n",
            "======================================================================\n",
            "\n",
            "📊 Model Performance:\n",
            "  Metric               Value          \n",
            "  -----------------------------------\n",
            "  Test Loss            3.5257         \n",
            "  Test Perplexity      33.98          \n",
            "  BLEU Score           17.16          \n",
            "\n",
            "📐 Model Size:\n",
            "  EN Vocabulary        30,354         \n",
            "  VI Vocabulary        13,152         \n",
            "  Parameters           18,472,288     \n",
            "\n",
            "⏱️  Training Time:\n",
            "  Total Time           49.59           minutes\n",
            "  Avg per Epoch        0.99            minutes\n",
            "\n",
            "✅ Training Complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FINAL TRANSLATION QUALITY REPORT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\n📊 Model Performance:\")\n",
        "print(f\"  {'Metric':<20} {'Value':<15}\")\n",
        "print(f\"  {'-'*35}\")\n",
        "print(f\"  {'Test Loss':<20} {test_loss:<15.4f}\")\n",
        "print(f\"  {'Test Perplexity':<20} {test_ppl:<15.2f}\")\n",
        "print(f\"  {'BLEU Score':<20} {bleu_score:<15.2f}\")\n",
        "\n",
        "print(f\"\\n📐 Model Size:\")\n",
        "print(f\"  {'EN Vocabulary':<20} {en_tokenizer.get_vocab_size():<15,}\")\n",
        "print(f\"  {'VI Vocabulary':<20} {vi_tokenizer.get_vocab_size():<15,}\")\n",
        "print(f\"  {'Parameters':<20} {total_params:<15,}\")\n",
        "\n",
        "print(f\"\\n⏱️  Training Time:\")\n",
        "print(f\"  {'Total Time':<20} {total_time/60:<15.2f} minutes\")\n",
        "print(f\"  {'Avg per Epoch':<20} {total_time/config['num_epochs']/60:<15.2f} minutes\")\n",
        "\n",
        "print(\"\\n✅ Training Complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.9 Translation Tests"
      ],
      "metadata": {
        "id": "v4o7w9oU6H4L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uv3R6caEcDFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3d9356-a337-4bed-e03e-3b02f2834cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRANSLATION TEST\n",
            "======================================================================\n",
            "\n",
            "Translating 10 sentences...\n",
            "\n",
            "Processing [1/10]... Done\n",
            "Processing [2/10]... Done\n",
            "Processing [3/10]... Done\n",
            "Processing [4/10]... Done\n",
            "Processing [5/10]... Done\n",
            "Processing [6/10]... Done\n",
            "Processing [7/10]... Done\n",
            "Processing [8/10]... Done\n",
            "Processing [9/10]... Done\n",
            "Processing [10/10]... Done\n",
            "\n",
            "======================================================================\n",
            "RESULTS\n",
            "======================================================================\n",
            "\n",
            "✅ Test 1:\n",
            "   🇬🇧 EN: Hello, how are you?\n",
            "   🇻🇳 VI: xin chào , làm sao con là gì ?\n",
            "\n",
            "✅ Test 2:\n",
            "   🇬🇧 EN: I love learning natural language processing.\n",
            "   🇻🇳 VI: tôi yêu thích sự tự nhiên bằng ngôn ngữ tự nhiên .\n",
            "\n",
            "✅ Test 3:\n",
            "   🇬🇧 EN: The weather is beautiful today.\n",
            "   🇻🇳 VI: thời tiết thời là tuyệt vời ngày nay rất đẹp .\n",
            "\n",
            "✅ Test 4:\n",
            "   🇬🇧 EN: Machine learning is changing the world.\n",
            "   🇻🇳 VI: máy học đang học đang thay đổi thế giới .\n",
            "\n",
            "✅ Test 5:\n",
            "   🇬🇧 EN: What is your name?\n",
            "   🇻🇳 VI: cái tên của bạn là gì ? ? ? ? ? ? ?\n",
            "\n",
            "✅ Test 6:\n",
            "   🇬🇧 EN: I am studying artificial intelligence.\n",
            "   🇻🇳 VI: tôi đang học đại học nhân tình báo nhân của tình báo .\n",
            "\n",
            "✅ Test 7:\n",
            "   🇬🇧 EN: She goes to school every day.\n",
            "   🇻🇳 VI: cô ấy đi học mỗi ngày mỗi ngày .\n",
            "\n",
            "✅ Test 8:\n",
            "   🇬🇧 EN: This book is very interesting.\n",
            "   🇻🇳 VI: quyển sách này rất thú vị rất thú vị .\n",
            "\n",
            "✅ Test 9:\n",
            "   🇬🇧 EN: Can you help me with this problem?\n",
            "   🇻🇳 VI: bạn có thể giúp tôi làm cho tôi vấn đề này ?\n",
            "\n",
            "✅ Test 10:\n",
            "   🇬🇧 EN: Thank you for your time.\n",
            "   🇻🇳 VI: cám ơn bạn cho thời gian của bạn . . .\n",
            "\n",
            "======================================================================\n",
            "✅ Completed: 10/10\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TRANSLATION TEST\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Danh sách các câu test\n",
        "test_sentences = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"I love learning natural language processing.\",\n",
        "    \"The weather is beautiful today.\",\n",
        "    \"Machine learning is changing the world.\",\n",
        "    \"What is your name?\",\n",
        "    \"I am studying artificial intelligence.\",\n",
        "    \"She goes to school every day.\",\n",
        "    \"This book is very interesting.\",\n",
        "    \"Can you help me with this problem?\",\n",
        "    \"Thank you for your time.\"\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "print(f\"\\nTranslating {len(test_sentences)} sentences...\\n\")\n",
        "\n",
        "for i, sentence in enumerate(test_sentences, 1):\n",
        "    print(f\"Processing [{i}/{len(test_sentences)}]...\", end=\" \")\n",
        "\n",
        "    try:\n",
        "        translation = translate_sentence(model, sentence, en_tokenizer, vi_tokenizer)\n",
        "        results.append((sentence, translation, \"✅\"))\n",
        "        print(\"Done\")\n",
        "    except Exception as e:\n",
        "        results.append((sentence, f\"Error: {e}\", \"❌\"))\n",
        "        print(\"Failed\")\n",
        "\n",
        "# In kết quả\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"RESULTS\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "for i, (en, vi, status) in enumerate(results, 1):\n",
        "    print(f\"{status} Test {i}:\")\n",
        "    print(f\"   🇬🇧 EN: {en}\")\n",
        "    print(f\"   🇻🇳 VI: {vi}\\n\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(f\"✅ Completed: {sum(1 for r in results if r[2] == '✅')}/{len(results)}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tZR73uv0iL0G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}