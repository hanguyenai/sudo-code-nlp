{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanguyenai/sudo-code-nlp/blob/main/06_machine_translation/EVBCorpus_English_Vietnamese_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OoHhVOe0lQ8"
      },
      "source": [
        "# 1 Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DtVc1jn0yRG",
        "outputId": "38a72b9f-f70e-4ba7-dda6-aa4d6f754254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (5.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.32.4)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.3)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: rarfile, portalocker, colorama, sacrebleu, torchtext\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 rarfile-4.2 sacrebleu-2.5.1 torchtext-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu sentencepiece torchtext rarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT1sRK5P0Ayy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import sacrebleu\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import os\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "import rarfile\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsor3--k10Ks",
        "outputId": "0bfde461-96fa-4d7f-aeb2-24a42d65d250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Special tokens\n",
        "PAD = '<pad>'\n",
        "UNK = '<unk>'\n",
        "BOS = '<sos>'\n",
        "EOS = '<eos>'\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wFwRgYABDbh",
        "outputId": "f328aae9-dfff-4654-c576-f2374d3d7b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'EVBCorpus'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Total 35 (delta 0), reused 0 (delta 0), pack-reused 35 (from 1)\u001b[K\n",
            "Receiving objects: 100% (35/35), 35.37 MiB | 41.11 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/qhungngo/EVBCorpus.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClVlsL2L6Ld8"
      },
      "outputs": [],
      "source": [
        "def parse_sgml_file(sgml_path):\n",
        "    \"\"\"Parse a single SGML file and extract English-Vietnamese sentence pairs\"\"\"\n",
        "    try:\n",
        "        # Read file content\n",
        "        with open(sgml_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Parse with BeautifulSoup (handles SGML/XML-like formats)\n",
        "        soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "        pairs = []\n",
        "\n",
        "        # Find all sentence pairs\n",
        "        for spair in soup.find_all('spair'):\n",
        "            en_text = \"\"\n",
        "            vi_text = \"\"\n",
        "\n",
        "            # Get all <s> tags in this spair\n",
        "            s_tags = spair.find_all('s')\n",
        "\n",
        "            for s in s_tags:\n",
        "                s_id = s.get('id', '')\n",
        "                text = s.get_text(strip=True)\n",
        "\n",
        "                # Identify English vs Vietnamese by id prefix\n",
        "                if s_id.startswith('en'):\n",
        "                    en_text = text\n",
        "                elif s_id.startswith('vn'):\n",
        "                    vi_text = text\n",
        "\n",
        "            # Only add if both sentences exist and are non-empty\n",
        "            if en_text and vi_text:\n",
        "                pairs.append({\n",
        "                    'english': en_text,\n",
        "                    'vietnamese': vi_text\n",
        "                })\n",
        "\n",
        "        return pairs\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error parsing {os.path.basename(sgml_path)}: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cceqdx78KvPv"
      },
      "outputs": [],
      "source": [
        "def load_evbcorpus_to_dataframe(extract_dir):\n",
        "    \"\"\"Load all SGML files from EVBCorpus and create pandas DataFrame\"\"\"\n",
        "    print(\"\\nüìñ Parsing SGML files...\")\n",
        "\n",
        "    # Find all SGML/XML files\n",
        "    sgml_files = []\n",
        "    for root, dirs, files in os.walk(extract_dir):\n",
        "        for f in files:\n",
        "            if f.endswith('.xml') or f.endswith('.sgml'):\n",
        "                sgml_files.append(os.path.join(root, f))\n",
        "\n",
        "    if not sgml_files:\n",
        "        print(\"‚ö†Ô∏è  No SGML/XML files found!\")\n",
        "        print(f\"Searched in: {extract_dir}\")\n",
        "        print(\"\\nTrying to find all files...\")\n",
        "        all_files = []\n",
        "        for root, dirs, files in os.walk(extract_dir):\n",
        "            all_files.extend([os.path.join(root, f) for f in files[:5]])\n",
        "        print(f\"Found files: {all_files[:10]}\")\n",
        "        raise FileNotFoundError(\"No SGML/XML files found in extracted directory\")\n",
        "\n",
        "    print(f\"Found {len(sgml_files)} SGML/XML files\")\n",
        "\n",
        "    # Parse all SGML files\n",
        "    all_pairs = []\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    for sgml_file in tqdm(sgml_files, desc=\"Parsing SGML\"):\n",
        "        pairs = parse_sgml_file(sgml_file)\n",
        "        all_pairs.extend(pairs)\n",
        "\n",
        "    if not all_pairs:\n",
        "        raise ValueError(\"No sentence pairs found! Check SGML file format.\")\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(all_pairs)\n",
        "\n",
        "    # Remove duplicates\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    print(f\"\\n‚úì Loaded {len(df):,} sentence pairs\")\n",
        "    print(f\"  Unique pairs: {len(df):,}\")\n",
        "    print(f\"\\nDataFrame Info:\")\n",
        "    print(f\"  Shape: {df.shape}\")\n",
        "    print(f\"  Columns: {df.columns.tolist()}\")\n",
        "\n",
        "    # Show statistics\n",
        "    print(f\"\\nSentence Length Statistics:\")\n",
        "    df['en_words'] = df['english'].str.split().str.len()\n",
        "    df['vi_words'] = df['vietnamese'].str.split().str.len()\n",
        "    print(f\"  English words: mean={df['en_words'].mean():.1f}, max={df['en_words'].max()}\")\n",
        "    print(f\"  Vietnamese words: mean={df['vi_words'].mean():.1f}, max={df['vi_words'].max()}\")\n",
        "\n",
        "    # Drop temporary columns\n",
        "    df = df.drop(['en_words', 'vi_words'], axis=1)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBiVuqFKLvSF"
      },
      "outputs": [],
      "source": [
        "rar_path = \"/content/EVBCorpus/EVBCorpus_EVBNews_v2.0.rar\"\n",
        "out_dir = \"/content/evbcorpus_data/EVBCorpus_v2\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "with rarfile.RarFile(rar_path) as rf:\n",
        "    # rf.printdir()  # xem list file\n",
        "    rf.extractall(path=out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq8HgnFIKzC4",
        "outputId": "5b469214-a112-4e0c-eae3-1bfe159725ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "EVBCorpus v2.0 - SGML Parser\n",
            "================================================================================\n",
            "\n",
            "üìñ Parsing SGML files...\n",
            "Found 1000 SGML/XML files\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parsing SGML: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:13<00:00, 75.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úì Loaded 43,695 sentence pairs\n",
            "  Unique pairs: 43,695\n",
            "\n",
            "DataFrame Info:\n",
            "  Shape: (43695, 2)\n",
            "  Columns: ['english', 'vietnamese']\n",
            "\n",
            "Sentence Length Statistics:\n",
            "  English words: mean=19.6, max=149\n",
            "  Vietnamese words: mean=26.8, max=185\n",
            "\n",
            "üìä Sample data from DataFrame:\n",
            "================================================================================\n",
            "                                                           english                                                       vietnamese\n",
            "0  Baby development : 12 ways to help your infant learn and gro...  S·ª± ph√°t tri·ªÉn c·ªßa tr·∫ª : 12 c√°ch ƒë·ªÉ gi√∫p tr·∫ª s∆° sinh nh·∫≠n th·ª©...\n",
            "1                                                     One month...                                                  1 th√°ng tu·ªïi...\n",
            "2                        Spend time with your baby , up close ....  ·ªû giai ƒëo·∫°n n√†y b·∫°n n√™n d√†nh th·ªùi gian v·ªõi con , ·ªü g·∫ßn s√°t b...\n",
            "3                                                         Why ?...                                                   T·∫°i sao ∆∞ ?...\n",
            "4  She sees best now when things are only 8 to 15 inches away ....  B√© c·ªßa b·∫°n gi·ªù ƒë√¢y ch·ªâ c√≥ th·ªÉ nh√¨n th·∫•y r√µ nh·∫•t c√°c v·∫≠t ·ªü g·∫ß...\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Download and parse corpus\n",
        "print(\"=\" * 80)\n",
        "print(\"EVBCorpus v2.0 - SGML Parser\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "extract_dir = out_dir\n",
        "corpus_df = load_evbcorpus_to_dataframe(extract_dir)\n",
        "\n",
        "# Display sample data\n",
        "print(\"\\nüìä Sample data from DataFrame:\")\n",
        "print(\"=\" * 80)\n",
        "display_df = corpus_df.head(5).copy()\n",
        "display_df['english'] = display_df['english'].str[:60] + '...'\n",
        "display_df['vietnamese'] = display_df['vietnamese'].str[:60] + '...'\n",
        "print(display_df.to_string(index=True))\n",
        "print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQbOADRhNJ29"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(w, max_length=None):\n",
        "    \"\"\"Preprocess a sentence (TensorFlow/Keras style)\"\"\"\n",
        "    w = w.lower().strip()\n",
        "\n",
        "    # Add space around punctuation\n",
        "    w = re.sub(r\"([?.!,¬ø])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # Replace multiple spaces with single space\n",
        "    w = re.sub(r'\\s+', ' ', w)\n",
        "    w = w.strip()\n",
        "\n",
        "    # Truncate to max_length if specified\n",
        "    if max_length:\n",
        "        w = \" \".join(w.split()[:max_length])\n",
        "\n",
        "    # Add start and end tokens\n",
        "    w = '{} {} {}'.format(BOS, w, EOS)\n",
        "\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMA8TOumNLQh"
      },
      "outputs": [],
      "source": [
        "def display_samples(inp_lines, targ_lines, num_of_pairs=5):\n",
        "    \"\"\"Display sample data pairs\"\"\"\n",
        "    pairs = list(zip(inp_lines[:num_of_pairs], targ_lines[:num_of_pairs]))\n",
        "\n",
        "    print('=' * 70)\n",
        "    print('SAMPLE DATA')\n",
        "    print('=' * 70)\n",
        "\n",
        "    for i, (inp, targ) in enumerate(pairs):\n",
        "        print(f'\\n--> Sample {i + 1}:')\n",
        "        print(f'    Input:  {inp}')\n",
        "        print(f'    Target: {targ}')\n",
        "\n",
        "    print('\\n' + '=' * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkHVqFTuNOmO"
      },
      "outputs": [],
      "source": [
        "def load_data_from_dataframe(df, max_samples=None, max_length=100):\n",
        "    \"\"\"Load and preprocess data from pandas DataFrame\"\"\"\n",
        "    print(f\"\\nüìñ Loading data from DataFrame...\")\n",
        "    print(f\"  Total pairs: {len(df):,}\")\n",
        "\n",
        "    # Get English and Vietnamese sentences\n",
        "    en_sentences = df['english'].tolist()\n",
        "    vi_sentences = df['vietnamese'].tolist()\n",
        "\n",
        "    print(f\"\\nüßπ Preprocessing sentences...\")\n",
        "    en_preprocessed = []\n",
        "    vi_preprocessed = []\n",
        "\n",
        "    for en, vi in tqdm(zip(en_sentences, vi_sentences), total=len(en_sentences), desc=\"Processing\"):\n",
        "        en_prep = preprocess_sentence(en, max_length=max_length)\n",
        "        vi_prep = preprocess_sentence(vi, max_length=max_length)\n",
        "\n",
        "        # Filter out empty sentences\n",
        "        if len(en_prep.split()) > 2 and len(vi_prep.split()) > 2:  # More than BOS+EOS\n",
        "            en_preprocessed.append(en_prep)\n",
        "            vi_preprocessed.append(vi_prep)\n",
        "\n",
        "    print(f\"‚úì After preprocessing: {len(en_preprocessed):,} sentences\")\n",
        "\n",
        "    if max_samples:\n",
        "        en_preprocessed = en_preprocessed[:max_samples]\n",
        "        vi_preprocessed = vi_preprocessed[:max_samples]\n",
        "        print(f\"‚úì Using {max_samples:,} samples\")\n",
        "\n",
        "    # Display samples\n",
        "    display_samples(en_preprocessed, vi_preprocessed, num_of_pairs=3)\n",
        "\n",
        "    return en_preprocessed, vi_preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1lEeM9X6v30"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "    \"\"\"Tokenizer similar to TensorFlow/Keras Tokenizer\"\"\"\n",
        "    def __init__(self, num_words=None, oov_token='<unk>'):\n",
        "        self.num_words = num_words\n",
        "        self.oov_token = oov_token\n",
        "\n",
        "        self.word_index = {}  # word -> index mapping\n",
        "        self.index_word = {}  # index -> word mapping\n",
        "        self.word_counts = Counter()\n",
        "\n",
        "        # Initialize with special tokens\n",
        "        self.word_index = {\n",
        "            PAD: 0,\n",
        "            BOS: 1,\n",
        "            EOS: 2,\n",
        "            UNK: 3\n",
        "        }\n",
        "        self.index_word = {v: k for k, v in self.word_index.items()}\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        \"\"\"Build vocabulary from texts\"\"\"\n",
        "        print(f\"üîß Building vocabulary...\")\n",
        "\n",
        "        # Count words\n",
        "        for text in tqdm(texts, desc=\"Counting words\"):\n",
        "            words = text.split()\n",
        "            self.word_counts.update(words)\n",
        "\n",
        "        # Build word_index based on frequency\n",
        "        sorted_words = sorted(self.word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Start from index 4 (after special tokens)\n",
        "        idx = 4\n",
        "        for word, count in sorted_words:\n",
        "            if word not in self.word_index:\n",
        "                if self.num_words is None or idx < self.num_words:\n",
        "                    self.word_index[word] = idx\n",
        "                    self.index_word[idx] = word\n",
        "                    idx += 1\n",
        "\n",
        "        vocab_size = len(self.word_index)\n",
        "        print(f\"‚úì Vocabulary size: {vocab_size:,}\")\n",
        "        print(f\"  Total unique words: {len(self.word_counts):,}\")\n",
        "        if self.num_words:\n",
        "            print(f\"  Kept top {self.num_words:,} words\")\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        \"\"\"Convert texts to sequences of integers\"\"\"\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            words = text.split()\n",
        "            sequence = []\n",
        "            for word in words:\n",
        "                if word in self.word_index:\n",
        "                    sequence.append(self.word_index[word])\n",
        "                else:\n",
        "                    sequence.append(self.word_index[UNK])\n",
        "            sequences.append(sequence)\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        \"\"\"Convert sequences of integers back to texts\"\"\"\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            words = []\n",
        "            for idx in sequence:\n",
        "                if idx in self.index_word:\n",
        "                    word = self.index_word[idx]\n",
        "                    # Skip special tokens except for visualization\n",
        "                    if word not in [PAD, BOS, EOS]:\n",
        "                        words.append(word)\n",
        "                else:\n",
        "                    words.append(UNK)\n",
        "            texts.append(' '.join(words))\n",
        "        return texts\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        \"\"\"Get vocabulary size\"\"\"\n",
        "        return len(self.word_index)\n",
        "\n",
        "    def save(self, filepath):\n",
        "        \"\"\"Save tokenizer\"\"\"\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'word_index': self.word_index,\n",
        "                'index_word': self.index_word,\n",
        "                'word_counts': self.word_counts,\n",
        "                'num_words': self.num_words,\n",
        "                'oov_token': self.oov_token\n",
        "            }, f)\n",
        "\n",
        "    def load(self, filepath):\n",
        "        \"\"\"Load tokenizer\"\"\"\n",
        "        with open(filepath, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self.word_index = data['word_index']\n",
        "            self.index_word = data['index_word']\n",
        "            self.word_counts = data['word_counts']\n",
        "            self.num_words = data['num_words']\n",
        "            self.oov_token = data['oov_token']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2kjrgxN71xc"
      },
      "outputs": [],
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    \"\"\"Dataset for translation task\"\"\"\n",
        "    def __init__(self, src_sequences, trg_sequences, max_len=None):\n",
        "        self.src_sequences = src_sequences\n",
        "        self.trg_sequences = trg_sequences\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src_sequences[idx]\n",
        "        trg = self.trg_sequences[idx]\n",
        "\n",
        "        # Truncate if too long\n",
        "        if self.max_len:\n",
        "            src = src[:self.max_len]\n",
        "            trg = trg[:self.max_len]\n",
        "\n",
        "        src = torch.tensor(src, dtype=torch.long)\n",
        "        trg = torch.tensor(trg, dtype=torch.long)\n",
        "        return src, trg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etGSHqXpc2M-"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for DataLoader with padding\"\"\"\n",
        "    src_batch, trg_batch = zip(*batch)\n",
        "\n",
        "    # Pad sequences\n",
        "    src_batch = nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    trg_batch = nn.utils.rnn.pad_sequence(trg_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    return src_batch, trg_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6-c9uxiOXiT"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Positional encoding for Transformer\"\"\"\n",
        "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # FIX: Use torch.arange instead of torch.range (deprecated)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add positional encoding and apply dropout\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eC40b5UO_CN"
      },
      "outputs": [],
      "source": [
        "class TransformerTranslator(nn.Module):\n",
        "    \"\"\"Transformer model for translation\"\"\"\n",
        "    def __init__(self, src_vocab_size, trg_vocab_size, d_model=512, nhead=8,\n",
        "                 num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048,\n",
        "                 dropout=0.1, max_len=200):\n",
        "        super(TransformerTranslator, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.trg_embedding = nn.Embedding(trg_vocab_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len=max_len, dropout=dropout)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"Initialize weights\"\"\"\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        \"\"\"Generate mask for target sequence\"\"\"\n",
        "        mask = torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n",
        "        return mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \"\"\"Forward pass\"\"\"\n",
        "        # Create masks\n",
        "        trg_mask = self.generate_square_subsequent_mask(trg.size(1)).to(src.device)\n",
        "        src_padding_mask = (src == 0)\n",
        "        trg_padding_mask = (trg == 0)\n",
        "\n",
        "        # Embeddings with scaling\n",
        "        src_emb = self.pos_encoder(self.src_embedding(src) * math.sqrt(self.d_model))\n",
        "        trg_emb = self.pos_encoder(self.trg_embedding(trg) * math.sqrt(self.d_model))\n",
        "\n",
        "        # Transformer\n",
        "        output = self.transformer(\n",
        "            src_emb, trg_emb,\n",
        "            tgt_mask=trg_mask,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_key_padding_mask=trg_padding_mask\n",
        "        )\n",
        "\n",
        "        return self.fc_out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_3TiwXGY0n5"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer, criterion, clip=1.0):\n",
        "  \"\"\"Train for one epoch\"\"\"\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  progress_bar = tqdm(dataloader, desc=\"Training\")\n",
        "  for src, trg in progress_bar:\n",
        "    src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(src, trg[:, :-1])\n",
        "\n",
        "    # Reshape for loss calculation\n",
        "    output = output.reshape(-1, output.shape[-1])\n",
        "    trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "    loss = criterion(output, trg)\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "  return epoch_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crgy3IrqZi-5"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    \"\"\"Evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, trg in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output = model(src, trg[:, :-1])\n",
        "            output = output.reshape(-1, output.shape[-1])\n",
        "            trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLM1t15PZkch"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(model, sentence, src_tokenizer, trg_tokenizer, max_len=50):\n",
        "    \"\"\"Translate a single sentence\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Preprocess and tokenize source sentence\n",
        "    preprocessed = preprocess_sentence(sentence, max_length=max_len)\n",
        "    src_sequence = src_tokenizer.texts_to_sequences([preprocessed])[0]\n",
        "    src_tensor = torch.tensor(src_sequence).unsqueeze(0).to(device)\n",
        "\n",
        "    # Start with BOS token\n",
        "    trg_indices = [trg_tokenizer.word_index[BOS]]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            trg_tensor = torch.tensor(trg_indices).unsqueeze(0).to(device)\n",
        "\n",
        "            output = model(src_tensor, trg_tensor)\n",
        "            next_token = output.argmax(dim=-1)[:, -1].item()\n",
        "\n",
        "            trg_indices.append(next_token)\n",
        "\n",
        "            # Stop if EOS token\n",
        "            if next_token == trg_tokenizer.word_index[EOS]:\n",
        "                break\n",
        "\n",
        "    # Decode to text\n",
        "    translation = trg_tokenizer.sequences_to_texts([trg_indices])[0]\n",
        "    return translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGOX51v3Zo3X"
      },
      "outputs": [],
      "source": [
        "def calculate_bleu(model, test_texts, src_tokenizer, trg_tokenizer, sample_size=None):\n",
        "    \"\"\"Calculate BLEU score on test data\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    src_texts, trg_texts = test_texts\n",
        "\n",
        "    if sample_size:\n",
        "        indices = random.sample(range(len(src_texts)), min(sample_size, len(src_texts)))\n",
        "        src_texts = [src_texts[i] for i in indices]\n",
        "        trg_texts = [trg_texts[i] for i in indices]\n",
        "\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    print(\"Generating translations for BLEU calculation...\")\n",
        "    for src, trg in tqdm(zip(src_texts, trg_texts), total=len(src_texts)):\n",
        "        # Translate (src is already preprocessed with BOS/EOS)\n",
        "        # Remove BOS/EOS for input to translate_sentence\n",
        "        src_clean = src.replace(BOS, '').replace(EOS, '').strip()\n",
        "        pred = translate_sentence(model, src_clean, src_tokenizer, trg_tokenizer)\n",
        "\n",
        "        # Clean reference (remove BOS/EOS)\n",
        "        trg_clean = trg.replace(BOS, '').replace(EOS, '').strip()\n",
        "\n",
        "        predictions.append(pred)\n",
        "        references.append(trg_clean)\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    bleu = sacrebleu.corpus_bleu(predictions, [references])\n",
        "\n",
        "    return bleu.score, predictions, references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sApPKs6nZr23",
        "outputId": "e369eb3b-60c7-4570-e487-c44ba02fa113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "TRANSFORMER MODEL FOR ENGLISH-VIETNAMESE TRANSLATION\n",
            "======================================================================\n",
            "\n",
            "üìã Configuration:\n",
            "  d_model: 256\n",
            "  nhead: 8\n",
            "  num_encoder_layers: 3\n",
            "  num_decoder_layers: 3\n",
            "  dim_feedforward: 512\n",
            "  dropout: 0.1\n",
            "  batch_size: 32\n",
            "  num_epochs: 100\n",
            "  learning_rate: 0.0001\n",
            "  max_len: 150\n",
            "  max_samples: None\n",
            "  max_sentence_length: 100\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"TRANSFORMER MODEL FOR ENGLISH-VIETNAMESE TRANSLATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Model configuration\n",
        "config = {\n",
        "    'd_model': 256,\n",
        "    'nhead': 8,\n",
        "    'num_encoder_layers': 3,\n",
        "    'num_decoder_layers': 3,\n",
        "    'dim_feedforward': 512,\n",
        "    'dropout': 0.1,\n",
        "    'batch_size': 32,\n",
        "    'num_epochs': 100,\n",
        "    'learning_rate': 0.0001,\n",
        "    'max_len': 150,\n",
        "    'max_samples': None,  # None for full dataset, or number like 5000 for testing\n",
        "    'max_sentence_length': 100  # Max words per sentence\n",
        "}\n",
        "\n",
        "print(\"\\nüìã Configuration:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaTw14kgZ5F3",
        "outputId": "062f7856-27b1-4163-813a-bb74cdc0268a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "LOADING DATA\n",
            "======================================================================\n",
            "\n",
            "üìñ Loading data from DataFrame...\n",
            "  Total pairs: 43,695\n",
            "\n",
            "üßπ Preprocessing sentences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43695/43695 [00:02<00:00, 16338.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì After preprocessing: 43,695 sentences\n",
            "======================================================================\n",
            "SAMPLE DATA\n",
            "======================================================================\n",
            "\n",
            "--> Sample 1:\n",
            "    Input:  <sos> baby development : 12 ways to help your infant learn and grow <eos>\n",
            "    Target: <sos> s·ª± ph√°t tri·ªÉn c·ªßa tr·∫ª : 12 c√°ch ƒë·ªÉ gi√∫p tr·∫ª s∆° sinh nh·∫≠n th·ª©c v√† ph√°t tri·ªÉn <eos>\n",
            "\n",
            "--> Sample 2:\n",
            "    Input:  <sos> one month <eos>\n",
            "    Target: <sos> 1 th√°ng tu·ªïi <eos>\n",
            "\n",
            "--> Sample 3:\n",
            "    Input:  <sos> spend time with your baby , up close . <eos>\n",
            "    Target: <sos> ·ªü giai ƒëo·∫°n n√†y b·∫°n n√™n d√†nh th·ªùi gian v·ªõi con , ·ªü g·∫ßn s√°t b√™n con nh√© . <eos>\n",
            "\n",
            "======================================================================\n",
            "\n",
            "üìä Data split:\n",
            "  Train: 34,956 sentences\n",
            "  Val:   4,369 sentences\n",
            "  Test:  4,370 sentences\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"LOADING DATA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Load data from DataFrame\n",
        "en_data, vi_data = load_data_from_dataframe(\n",
        "    corpus_df,\n",
        "    max_samples=config['max_samples'],\n",
        "    max_length=config['max_sentence_length']\n",
        ")\n",
        "\n",
        "# Split data: 80% train, 10% val, 10% test\n",
        "train_size = int(0.8 * len(en_data))\n",
        "val_size = int(0.1 * len(en_data))\n",
        "\n",
        "train_en = en_data[:train_size]\n",
        "train_vi = vi_data[:train_size]\n",
        "val_en = en_data[train_size:train_size+val_size]\n",
        "val_vi = vi_data[train_size:train_size+val_size]\n",
        "test_en = en_data[train_size+val_size:]\n",
        "test_vi = vi_data[train_size+val_size:]\n",
        "\n",
        "print(f\"\\nüìä Data split:\")\n",
        "print(f\"  Train: {len(train_en):,} sentences\")\n",
        "print(f\"  Val:   {len(val_en):,} sentences\")\n",
        "print(f\"  Test:  {len(test_en):,} sentences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhEeEAdKZ7SC",
        "outputId": "9bd14684-72e7-42fd-e8f7-61284c60b217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "BUILDING VOCABULARIES (Keras/TensorFlow style)\n",
            "======================================================================\n",
            "\n",
            "üî§ Fitting English tokenizer...\n",
            "üîß Building vocabulary...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Counting words: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34956/34956 [00:00<00:00, 224741.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Vocabulary size: 30,560\n",
            "  Total unique words: 30,558\n",
            "  Kept top 50,000 words\n",
            "üî§ Fitting Vietnamese tokenizer...\n",
            "üîß Building vocabulary...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Counting words: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34956/34956 [00:00<00:00, 171287.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Vocabulary size: 13,154\n",
            "  Total unique words: 13,152\n",
            "  Kept top 50,000 words\n",
            "\n",
            "‚úì English vocab size: 30,560\n",
            "‚úì Vietnamese vocab size: 13,154\n",
            "\n",
            "üìù Tokenization examples:\n",
            "\n",
            "English text: <sos> baby development : 12 ways to help your infant learn and grow <eos>\n",
            "Sequence:     [1, 111, 319, 48, 580, 537, 7, 89, 24, 1409, 476, 8, 772, 2]...\n",
            "Decoded back: baby development : 12 ways to help your infant learn and grow\n",
            "\n",
            "Vietnamese text: <sos> s·ª± ph√°t tri·ªÉn c·ªßa tr·∫ª : 12 c√°ch ƒë·ªÉ gi√∫p tr·∫ª s∆° sinh nh·∫≠n th·ª©c v√† ph√°t tri·ªÉn <eos>\n",
            "Sequence:        [1, 45, 61, 172, 8, 91, 104, 846, 83, 26, 142, 91, 667, 113, 150, 214, 6, 61, 172, 2]...\n",
            "Decoded back:    s·ª± ph√°t tri·ªÉn c·ªßa tr·∫ª : 12 c√°ch ƒë·ªÉ gi√∫p tr·∫ª s∆° sinh nh·∫≠n th·ª©c v√† ph√°t tri·ªÉn\n",
            "\n",
            "üîÑ Converting texts to sequences...\n",
            "‚úì Converted all texts to sequences\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BUILDING VOCABULARIES (Keras/TensorFlow style)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Initialize tokenizers\n",
        "en_tokenizer = Tokenizer(num_words=50000)  # Keep top 50K words\n",
        "vi_tokenizer = Tokenizer(num_words=50000)\n",
        "\n",
        "# Fit on training data\n",
        "print(\"\\nüî§ Fitting English tokenizer...\")\n",
        "en_tokenizer.fit_on_texts(train_en)\n",
        "\n",
        "print(\"üî§ Fitting Vietnamese tokenizer...\")\n",
        "vi_tokenizer.fit_on_texts(train_vi)\n",
        "\n",
        "print(f\"\\n‚úì English vocab size: {en_tokenizer.get_vocab_size():,}\")\n",
        "print(f\"‚úì Vietnamese vocab size: {vi_tokenizer.get_vocab_size():,}\")\n",
        "\n",
        "# Show tokenization examples\n",
        "print(\"\\nüìù Tokenization examples:\")\n",
        "sample_en = train_en[0]\n",
        "sample_vi = train_vi[0]\n",
        "\n",
        "en_seq = en_tokenizer.texts_to_sequences([sample_en])[0]\n",
        "vi_seq = vi_tokenizer.texts_to_sequences([sample_vi])[0]\n",
        "\n",
        "print(f\"\\nEnglish text: {sample_en}\")\n",
        "print(f\"Sequence:     {en_seq[:20]}...\")  # Show first 20 tokens\n",
        "print(f\"Decoded back: {en_tokenizer.sequences_to_texts([en_seq])[0]}\")\n",
        "\n",
        "print(f\"\\nVietnamese text: {sample_vi}\")\n",
        "print(f\"Sequence:        {vi_seq[:20]}...\")\n",
        "print(f\"Decoded back:    {vi_tokenizer.sequences_to_texts([vi_seq])[0]}\")\n",
        "\n",
        "# Convert all texts to sequences\n",
        "print(\"\\nüîÑ Converting texts to sequences...\")\n",
        "train_en_seq = en_tokenizer.texts_to_sequences(train_en)\n",
        "train_vi_seq = vi_tokenizer.texts_to_sequences(train_vi)\n",
        "val_en_seq = en_tokenizer.texts_to_sequences(val_en)\n",
        "val_vi_seq = vi_tokenizer.texts_to_sequences(val_vi)\n",
        "test_en_seq = en_tokenizer.texts_to_sequences(test_en)\n",
        "test_vi_seq = vi_tokenizer.texts_to_sequences(test_vi)\n",
        "\n",
        "print(f\"‚úì Converted all texts to sequences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWAv2wmWaYoy",
        "outputId": "b0e89d1b-c8f1-4a62-8e4f-3293ace7d1a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CREATING DATASETS\n",
            "======================================================================\n",
            "‚úì Train batches: 1093\n",
            "‚úì Val batches:   137\n",
            "‚úì Test batches:  137\n",
            "‚úì Max sequence length: 150\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CREATING DATASETS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create datasets from sequences with max_len truncation\n",
        "train_dataset = TranslationDataset(train_en_seq, train_vi_seq, max_len=config['max_len'])\n",
        "val_dataset = TranslationDataset(val_en_seq, val_vi_seq, max_len=config['max_len'])\n",
        "test_dataset = TranslationDataset(test_en_seq, test_vi_seq, max_len=config['max_len'])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'],\n",
        "                         shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'],\n",
        "                       collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'],\n",
        "                        collate_fn=collate_fn)\n",
        "\n",
        "print(f\"‚úì Train batches: {len(train_loader)}\")\n",
        "print(f\"‚úì Val batches:   {len(val_loader)}\")\n",
        "print(f\"‚úì Test batches:  {len(test_loader)}\")\n",
        "print(f\"‚úì Max sequence length: {config['max_len']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G95MbOnabMS",
        "outputId": "5900a3fb-be2e-4bb9-a78a-1375fd6112bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "INITIALIZING MODEL\n",
            "======================================================================\n",
            "\n",
            "ü§ñ Model Architecture:\n",
            "  Total parameters:     18,526,050\n",
            "  Trainable parameters: 18,526,050\n",
            "  Model size:           ~74.10 MB\n",
            "‚úì Loss function: CrossEntropyLoss\n",
            "‚úì Optimizer: Adam (lr=0.0001)\n",
            "‚úì Scheduler: ReduceLROnPlateau\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"INITIALIZING MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "model = TransformerTranslator(\n",
        "    src_vocab_size=en_tokenizer.get_vocab_size(),\n",
        "    trg_vocab_size=vi_tokenizer.get_vocab_size(),\n",
        "    d_model=config['d_model'],\n",
        "    nhead=config['nhead'],\n",
        "    num_encoder_layers=config['num_encoder_layers'],\n",
        "    num_decoder_layers=config['num_decoder_layers'],\n",
        "    dim_feedforward=config['dim_feedforward'],\n",
        "    dropout=config['dropout'],\n",
        "    max_len=config['max_len']\n",
        ").to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nü§ñ Model Architecture:\")\n",
        "print(f\"  Total parameters:     {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"  Model size:           ~{total_params * 4 / 1e6:.2f} MB\")\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "print(f\"‚úì Loss function: CrossEntropyLoss\")\n",
        "print(f\"‚úì Optimizer: Adam (lr={config['learning_rate']})\")\n",
        "print(f\"‚úì Scheduler: ReduceLROnPlateau\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orOgGL1kaeAb",
        "outputId": "15f06c04-5031-445d-b35f-16591c65fcad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING MODEL\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Epoch 1/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:55<00:00, 19.65it/s, loss=5.44]\n",
            "Evaluating:   0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 67.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 6.3063 | Train PPL: 548.03\n",
            "  Val Loss:   5.5272 | Val PPL:   251.45\n",
            "  Time:       57.66s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 2/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.17it/s, loss=4.86]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 5.1466 | Train PPL: 171.85\n",
            "  Val Loss:   4.8491 | Val PPL:   127.62\n",
            "  Time:       58.88s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 3/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.42it/s, loss=4.31]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 4.5667 | Train PPL: 96.22\n",
            "  Val Loss:   4.4359 | Val PPL:   84.43\n",
            "  Time:       58.19s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 4/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.42it/s, loss=4.06]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 65.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 4.1383 | Train PPL: 62.69\n",
            "  Val Loss:   4.1251 | Val PPL:   61.87\n",
            "  Time:       58.41s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 5/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.17it/s, loss=3.68]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 68.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 3.7930 | Train PPL: 44.39\n",
            "  Val Loss:   3.9224 | Val PPL:   50.52\n",
            "  Time:       59.02s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 6/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.34it/s, loss=3.91]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 3.4987 | Train PPL: 33.07\n",
            "  Val Loss:   3.7505 | Val PPL:   42.54\n",
            "  Time:       58.40s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 7/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.39it/s, loss=3.11]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 3.2395 | Train PPL: 25.52\n",
            "  Val Loss:   3.6133 | Val PPL:   37.09\n",
            "  Time:       58.27s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 8/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.39it/s, loss=3.25]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 3.0130 | Train PPL: 20.35\n",
            "  Val Loss:   3.5467 | Val PPL:   34.70\n",
            "  Time:       58.26s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 9/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.15it/s, loss=2.78]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 2.8118 | Train PPL: 16.64\n",
            "  Val Loss:   3.4536 | Val PPL:   31.62\n",
            "  Time:       58.97s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 10/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.34it/s, loss=2.57]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 2.6350 | Train PPL: 13.94\n",
            "  Val Loss:   3.4194 | Val PPL:   30.55\n",
            "  Time:       58.41s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 11/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.34it/s, loss=2.56]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 2.4747 | Train PPL: 11.88\n",
            "  Val Loss:   3.3745 | Val PPL:   29.21\n",
            "  Time:       58.43s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 12/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.27it/s, loss=2.52]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 68.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 2.3326 | Train PPL: 10.31\n",
            "  Val Loss:   3.3655 | Val PPL:   28.95\n",
            "  Time:       58.73s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 13/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.30it/s, loss=2.19]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 64.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 2.2025 | Train PPL: 9.05\n",
            "  Val Loss:   3.3886 | Val PPL:   29.63\n",
            "  Time:       58.79s\n",
            "\n",
            "======================================================================\n",
            "Epoch 14/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.15it/s, loss=2.2]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 69.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 2.0862 | Train PPL: 8.05\n",
            "  Val Loss:   3.3442 | Val PPL:   28.34\n",
            "  Time:       59.07s\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "======================================================================\n",
            "Epoch 15/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.32it/s, loss=1.91]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.9778 | Train PPL: 7.23\n",
            "  Val Loss:   3.3534 | Val PPL:   28.60\n",
            "  Time:       58.48s\n",
            "\n",
            "======================================================================\n",
            "Epoch 16/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.30it/s, loss=2.13]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.8812 | Train PPL: 6.56\n",
            "  Val Loss:   3.3868 | Val PPL:   29.57\n",
            "  Time:       58.54s\n",
            "\n",
            "======================================================================\n",
            "Epoch 17/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.27it/s, loss=1.81]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.7922 | Train PPL: 6.00\n",
            "  Val Loss:   3.4098 | Val PPL:   30.26\n",
            "  Time:       58.61s\n",
            "\n",
            "======================================================================\n",
            "Epoch 18/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.29it/s, loss=1.48]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.6612 | Train PPL: 5.27\n",
            "  Val Loss:   3.3822 | Val PPL:   29.44\n",
            "  Time:       58.55s\n",
            "\n",
            "======================================================================\n",
            "Epoch 19/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.38it/s, loss=1.48]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 68.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.6038 | Train PPL: 4.97\n",
            "  Val Loss:   3.4147 | Val PPL:   30.41\n",
            "  Time:       58.39s\n",
            "\n",
            "======================================================================\n",
            "Epoch 20/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.38it/s, loss=1.62]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 68.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.5589 | Train PPL: 4.75\n",
            "  Val Loss:   3.4379 | Val PPL:   31.12\n",
            "  Time:       58.40s\n",
            "\n",
            "======================================================================\n",
            "Epoch 21/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.37it/s, loss=1.3]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.4925 | Train PPL: 4.45\n",
            "  Val Loss:   3.4523 | Val PPL:   31.57\n",
            "  Time:       58.33s\n",
            "\n",
            "======================================================================\n",
            "Epoch 22/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.35it/s, loss=1.38]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.4683 | Train PPL: 4.34\n",
            "  Val Loss:   3.4559 | Val PPL:   31.69\n",
            "  Time:       58.38s\n",
            "\n",
            "======================================================================\n",
            "Epoch 23/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.33it/s, loss=1.25]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.4434 | Train PPL: 4.24\n",
            "  Val Loss:   3.4806 | Val PPL:   32.48\n",
            "  Time:       58.45s\n",
            "\n",
            "======================================================================\n",
            "Epoch 24/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.30it/s, loss=1.43]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.4101 | Train PPL: 4.10\n",
            "  Val Loss:   3.4880 | Val PPL:   32.72\n",
            "  Time:       58.50s\n",
            "\n",
            "======================================================================\n",
            "Epoch 25/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.33it/s, loss=1.55]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 70.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3996 | Train PPL: 4.05\n",
            "  Val Loss:   3.4922 | Val PPL:   32.86\n",
            "  Time:       58.50s\n",
            "\n",
            "======================================================================\n",
            "Epoch 26/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.44it/s, loss=1.41]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 66.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3866 | Train PPL: 4.00\n",
            "  Val Loss:   3.4920 | Val PPL:   32.85\n",
            "  Time:       58.29s\n",
            "\n",
            "======================================================================\n",
            "Epoch 27/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.35it/s, loss=1.26]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3699 | Train PPL: 3.93\n",
            "  Val Loss:   3.5024 | Val PPL:   33.20\n",
            "  Time:       58.38s\n",
            "\n",
            "======================================================================\n",
            "Epoch 28/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.28it/s, loss=1.7]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3636 | Train PPL: 3.91\n",
            "  Val Loss:   3.5117 | Val PPL:   33.51\n",
            "  Time:       58.58s\n",
            "\n",
            "======================================================================\n",
            "Epoch 29/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.34it/s, loss=1.26]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3597 | Train PPL: 3.90\n",
            "  Val Loss:   3.5084 | Val PPL:   33.39\n",
            "  Time:       58.41s\n",
            "\n",
            "======================================================================\n",
            "Epoch 30/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.19it/s, loss=1.27]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3513 | Train PPL: 3.86\n",
            "  Val Loss:   3.5140 | Val PPL:   33.58\n",
            "  Time:       58.86s\n",
            "\n",
            "======================================================================\n",
            "Epoch 31/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.38it/s, loss=1.09]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 69.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3472 | Train PPL: 3.85\n",
            "  Val Loss:   3.5193 | Val PPL:   33.76\n",
            "  Time:       58.38s\n",
            "\n",
            "======================================================================\n",
            "Epoch 32/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.29it/s, loss=1.53]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 67.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3440 | Train PPL: 3.83\n",
            "  Val Loss:   3.5177 | Val PPL:   33.71\n",
            "  Time:       58.70s\n",
            "\n",
            "======================================================================\n",
            "Epoch 33/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.31it/s, loss=1.33]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3399 | Train PPL: 3.82\n",
            "  Val Loss:   3.5178 | Val PPL:   33.71\n",
            "  Time:       58.51s\n",
            "\n",
            "======================================================================\n",
            "Epoch 34/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.19it/s, loss=1.4]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3387 | Train PPL: 3.81\n",
            "  Val Loss:   3.5199 | Val PPL:   33.78\n",
            "  Time:       58.85s\n",
            "\n",
            "======================================================================\n",
            "Epoch 35/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.12it/s, loss=1.27]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3366 | Train PPL: 3.81\n",
            "  Val Loss:   3.5240 | Val PPL:   33.92\n",
            "  Time:       59.06s\n",
            "\n",
            "======================================================================\n",
            "Epoch 36/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.19it/s, loss=1.52]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3343 | Train PPL: 3.80\n",
            "  Val Loss:   3.5237 | Val PPL:   33.91\n",
            "  Time:       58.86s\n",
            "\n",
            "======================================================================\n",
            "Epoch 37/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.31it/s, loss=1.35]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3342 | Train PPL: 3.80\n",
            "  Val Loss:   3.5230 | Val PPL:   33.89\n",
            "  Time:       58.49s\n",
            "\n",
            "======================================================================\n",
            "Epoch 38/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.31it/s, loss=1.48]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 66.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3353 | Train PPL: 3.80\n",
            "  Val Loss:   3.5261 | Val PPL:   33.99\n",
            "  Time:       58.67s\n",
            "\n",
            "======================================================================\n",
            "Epoch 39/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.36it/s, loss=1.33]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3317 | Train PPL: 3.79\n",
            "  Val Loss:   3.5247 | Val PPL:   33.94\n",
            "  Time:       58.39s\n",
            "\n",
            "======================================================================\n",
            "Epoch 40/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.26it/s, loss=1.11]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3331 | Train PPL: 3.79\n",
            "  Val Loss:   3.5257 | Val PPL:   33.98\n",
            "  Time:       58.65s\n",
            "\n",
            "======================================================================\n",
            "Epoch 41/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.26it/s, loss=1.63]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3350 | Train PPL: 3.80\n",
            "  Val Loss:   3.5247 | Val PPL:   33.94\n",
            "  Time:       58.62s\n",
            "\n",
            "======================================================================\n",
            "Epoch 42/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.10it/s, loss=1.34]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3314 | Train PPL: 3.79\n",
            "  Val Loss:   3.5244 | Val PPL:   33.93\n",
            "  Time:       59.12s\n",
            "\n",
            "======================================================================\n",
            "Epoch 43/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.31it/s, loss=1.38]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3323 | Train PPL: 3.79\n",
            "  Val Loss:   3.5237 | Val PPL:   33.91\n",
            "  Time:       58.50s\n",
            "\n",
            "======================================================================\n",
            "Epoch 44/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.37it/s, loss=1.4]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 63.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3313 | Train PPL: 3.79\n",
            "  Val Loss:   3.5259 | Val PPL:   33.99\n",
            "  Time:       58.58s\n",
            "\n",
            "======================================================================\n",
            "Epoch 45/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.42it/s, loss=1.2]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3295 | Train PPL: 3.78\n",
            "  Val Loss:   3.5258 | Val PPL:   33.98\n",
            "  Time:       58.16s\n",
            "\n",
            "======================================================================\n",
            "Epoch 46/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.25it/s, loss=1.54]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3307 | Train PPL: 3.78\n",
            "  Val Loss:   3.5256 | Val PPL:   33.97\n",
            "  Time:       58.66s\n",
            "\n",
            "======================================================================\n",
            "Epoch 47/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.29it/s, loss=1.18]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3305 | Train PPL: 3.78\n",
            "  Val Loss:   3.5257 | Val PPL:   33.98\n",
            "  Time:       58.54s\n",
            "\n",
            "======================================================================\n",
            "Epoch 48/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.35it/s, loss=1.31]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3304 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       58.35s\n",
            "\n",
            "======================================================================\n",
            "Epoch 49/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.33it/s, loss=1.33]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3308 | Train PPL: 3.78\n",
            "  Val Loss:   3.5256 | Val PPL:   33.97\n",
            "  Time:       58.43s\n",
            "\n",
            "======================================================================\n",
            "Epoch 50/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.41it/s, loss=1.42]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 66.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3303 | Train PPL: 3.78\n",
            "  Val Loss:   3.5256 | Val PPL:   33.97\n",
            "  Time:       58.39s\n",
            "\n",
            "======================================================================\n",
            "Epoch 51/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.39it/s, loss=1.31]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3301 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       58.28s\n",
            "\n",
            "======================================================================\n",
            "Epoch 52/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.38it/s, loss=1.56]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3312 | Train PPL: 3.79\n",
            "  Val Loss:   3.5253 | Val PPL:   33.96\n",
            "  Time:       58.27s\n",
            "\n",
            "======================================================================\n",
            "Epoch 53/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.13it/s, loss=1.38]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3296 | Train PPL: 3.78\n",
            "  Val Loss:   3.5257 | Val PPL:   33.98\n",
            "  Time:       59.04s\n",
            "\n",
            "======================================================================\n",
            "Epoch 54/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 18.98it/s, loss=1.26]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3306 | Train PPL: 3.78\n",
            "  Val Loss:   3.5256 | Val PPL:   33.98\n",
            "  Time:       59.50s\n",
            "\n",
            "======================================================================\n",
            "Epoch 55/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:58<00:00, 18.82it/s, loss=1.41]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 69.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3299 | Train PPL: 3.78\n",
            "  Val Loss:   3.5256 | Val PPL:   33.97\n",
            "  Time:       60.05s\n",
            "\n",
            "======================================================================\n",
            "Epoch 56/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 18.97it/s, loss=1.13]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3305 | Train PPL: 3.78\n",
            "  Val Loss:   3.5256 | Val PPL:   33.98\n",
            "  Time:       59.53s\n",
            "\n",
            "======================================================================\n",
            "Epoch 57/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.10it/s, loss=1.36]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 66.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3274 | Train PPL: 3.77\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.29s\n",
            "\n",
            "======================================================================\n",
            "Epoch 58/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.14it/s, loss=1.69]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 66.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3312 | Train PPL: 3.79\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.17s\n",
            "\n",
            "======================================================================\n",
            "Epoch 59/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.15it/s, loss=1.59]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3311 | Train PPL: 3.79\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.00s\n",
            "\n",
            "======================================================================\n",
            "Epoch 60/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.12it/s, loss=1.31]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3300 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.08s\n",
            "\n",
            "======================================================================\n",
            "Epoch 61/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.11it/s, loss=1.16]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3293 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       59.14s\n",
            "\n",
            "======================================================================\n",
            "Epoch 62/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.06it/s, loss=1.2]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3286 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       59.28s\n",
            "\n",
            "======================================================================\n",
            "Epoch 63/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:56<00:00, 19.19it/s, loss=1.62]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3296 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       58.88s\n",
            "\n",
            "======================================================================\n",
            "Epoch 64/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.16it/s, loss=1.15]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 65.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3310 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.12s\n",
            "\n",
            "======================================================================\n",
            "Epoch 65/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.10it/s, loss=1.18]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 70.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3306 | Train PPL: 3.78\n",
            "  Val Loss:   3.5256 | Val PPL:   33.97\n",
            "  Time:       59.20s\n",
            "\n",
            "======================================================================\n",
            "Epoch 66/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.09it/s, loss=1.11]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3296 | Train PPL: 3.78\n",
            "  Val Loss:   3.5256 | Val PPL:   33.98\n",
            "  Time:       59.18s\n",
            "\n",
            "======================================================================\n",
            "Epoch 67/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.07it/s, loss=1.44]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3304 | Train PPL: 3.78\n",
            "  Val Loss:   3.5256 | Val PPL:   33.97\n",
            "  Time:       59.22s\n",
            "\n",
            "======================================================================\n",
            "Epoch 68/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.14it/s, loss=1.61]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3298 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       59.00s\n",
            "\n",
            "======================================================================\n",
            "Epoch 69/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 18.99it/s, loss=1.35]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3306 | Train PPL: 3.78\n",
            "  Val Loss:   3.5256 | Val PPL:   33.97\n",
            "  Time:       59.48s\n",
            "\n",
            "======================================================================\n",
            "Epoch 70/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.04it/s, loss=1.15]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 69.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3316 | Train PPL: 3.79\n",
            "  Val Loss:   3.5256 | Val PPL:   33.97\n",
            "  Time:       59.40s\n",
            "\n",
            "======================================================================\n",
            "Epoch 71/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.07it/s, loss=1.34]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 64.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3280 | Train PPL: 3.77\n",
            "  Val Loss:   3.5256 | Val PPL:   33.97\n",
            "  Time:       59.44s\n",
            "\n",
            "======================================================================\n",
            "Epoch 72/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.05it/s, loss=1.32]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 69.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3307 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.34s\n",
            "\n",
            "======================================================================\n",
            "Epoch 73/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.08it/s, loss=1.35]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3295 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       59.17s\n",
            "\n",
            "======================================================================\n",
            "Epoch 74/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.02it/s, loss=1.11]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3294 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       59.35s\n",
            "\n",
            "======================================================================\n",
            "Epoch 75/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.10it/s, loss=1.76]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3306 | Train PPL: 3.78\n",
            "  Val Loss:   3.5253 | Val PPL:   33.96\n",
            "  Time:       59.12s\n",
            "\n",
            "======================================================================\n",
            "Epoch 76/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.06it/s, loss=1.29]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3291 | Train PPL: 3.78\n",
            "  Val Loss:   3.5252 | Val PPL:   33.96\n",
            "  Time:       59.23s\n",
            "\n",
            "======================================================================\n",
            "Epoch 77/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.01it/s, loss=1.37]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3304 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.40s\n",
            "\n",
            "======================================================================\n",
            "Epoch 78/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.13it/s, loss=1.01]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 66.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3311 | Train PPL: 3.79\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.22s\n",
            "\n",
            "======================================================================\n",
            "Epoch 79/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.13it/s, loss=1.01]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 68.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3295 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.14s\n",
            "\n",
            "======================================================================\n",
            "Epoch 80/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.05it/s, loss=1.25]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3292 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       59.29s\n",
            "\n",
            "======================================================================\n",
            "Epoch 81/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.13it/s, loss=1.26]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3292 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       59.05s\n",
            "\n",
            "======================================================================\n",
            "Epoch 82/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.12it/s, loss=1.27]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3292 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.08s\n",
            "\n",
            "======================================================================\n",
            "Epoch 83/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.04it/s, loss=1.1]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3306 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.31s\n",
            "\n",
            "======================================================================\n",
            "Epoch 84/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.04it/s, loss=1.59]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 66.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3302 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.46s\n",
            "\n",
            "======================================================================\n",
            "Epoch 85/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.03it/s, loss=1.14]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 62.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3290 | Train PPL: 3.78\n",
            "  Val Loss:   3.5253 | Val PPL:   33.97\n",
            "  Time:       59.63s\n",
            "\n",
            "======================================================================\n",
            "Epoch 86/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.10it/s, loss=1.34]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 70.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3305 | Train PPL: 3.78\n",
            "  Val Loss:   3.5253 | Val PPL:   33.97\n",
            "  Time:       59.16s\n",
            "\n",
            "======================================================================\n",
            "Epoch 87/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.04it/s, loss=1.6]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3293 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       59.34s\n",
            "\n",
            "======================================================================\n",
            "Epoch 88/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 18.99it/s, loss=1.44]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3299 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       59.44s\n",
            "\n",
            "======================================================================\n",
            "Epoch 89/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.12it/s, loss=1.17]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3280 | Train PPL: 3.77\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       59.06s\n",
            "\n",
            "======================================================================\n",
            "Epoch 90/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.03it/s, loss=1.09]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3297 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.37s\n",
            "\n",
            "======================================================================\n",
            "Epoch 91/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.10it/s, loss=1.43]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3295 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.13s\n",
            "\n",
            "======================================================================\n",
            "Epoch 92/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.09it/s, loss=1.09]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 65.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3301 | Train PPL: 3.78\n",
            "  Val Loss:   3.5254 | Val PPL:   33.97\n",
            "  Time:       59.36s\n",
            "\n",
            "======================================================================\n",
            "Epoch 93/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 18.98it/s, loss=1.26]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 66.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3295 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.68s\n",
            "\n",
            "======================================================================\n",
            "Epoch 94/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.08it/s, loss=1.37]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3301 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.19s\n",
            "\n",
            "======================================================================\n",
            "Epoch 95/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.07it/s, loss=1.08]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 73.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3289 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.20s\n",
            "\n",
            "======================================================================\n",
            "Epoch 96/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.02it/s, loss=1.39]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3295 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.37s\n",
            "\n",
            "======================================================================\n",
            "Epoch 97/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.04it/s, loss=1.28]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 71.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3304 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.31s\n",
            "\n",
            "======================================================================\n",
            "Epoch 98/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.03it/s, loss=1.55]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 72.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3313 | Train PPL: 3.79\n",
            "  Val Loss:   3.5256 | Val PPL:   33.97\n",
            "  Time:       59.35s\n",
            "\n",
            "======================================================================\n",
            "Epoch 99/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 18.97it/s, loss=1.52]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 66.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3305 | Train PPL: 3.78\n",
            "  Val Loss:   3.5255 | Val PPL:   33.97\n",
            "  Time:       59.69s\n",
            "\n",
            "======================================================================\n",
            "Epoch 100/100\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1093/1093 [00:57<00:00, 19.07it/s, loss=1.5]\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:02<00:00, 67.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Results:\n",
            "  Train Loss: 1.3300 | Train PPL: 3.78\n",
            "  Val Loss:   3.5256 | Val PPL:   33.97\n",
            "  Time:       59.36s\n",
            "\n",
            "======================================================================\n",
            "‚úì Training completed in 98.25 minutes\n",
            "  Average time per epoch: 0.98 minutes\n",
            "\n",
            "======================================================================\n",
            "STEP 6: LOADING BEST MODEL\n",
            "======================================================================\n",
            "‚úì Loaded best model from epoch 14\n",
            "  Val Loss: 3.3442\n",
            "  Val PPL:  28.34\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TRAINING MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(config['num_epochs']):\n",
        "    epoch_start = time.time()\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Train\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "\n",
        "    # Validate\n",
        "    val_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    # Record losses\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nüìä Results:\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train PPL: {math.exp(train_loss):.2f}\")\n",
        "    print(f\"  Val Loss:   {val_loss:.4f} | Val PPL:   {math.exp(val_loss):.2f}\")\n",
        "    print(f\"  Time:       {epoch_time:.2f}s\")\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'config': config\n",
        "        }, 'best_model.pt')\n",
        "        print(\"  ‚úì Best model saved!\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"‚úì Training completed in {total_time/60:.2f} minutes\")\n",
        "print(f\"  Average time per epoch: {total_time/config['num_epochs']/60:.2f} minutes\")\n",
        "\n",
        "# ============================================================================\n",
        "# Cell 19: Load Best Model\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 6: LOADING BEST MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "checkpoint = torch.load('best_model.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "print(f\"‚úì Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
        "print(f\"  Val Loss: {checkpoint['val_loss']:.4f}\")\n",
        "print(f\"  Val PPL:  {math.exp(checkpoint['val_loss']):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKSB4B2RboK_",
        "outputId": "8009d6f1-2edb-4d00-e1df-6fd7c1bfd5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUATING ON TEST SET\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:01<00:00, 70.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Test Results:\n",
            "  Test Loss:       3.5252\n",
            "  Test Perplexity: 33.96\n",
            "\n",
            "======================================================================\n",
            "STEP 8: CALCULATING BLEU SCORE\n",
            "======================================================================\n",
            "Generating translations for BLEU calculation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:21<00:00,  4.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéØ BLEU Score: 14.91\n",
            "\n",
            "üìù Sample Translations:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "[Example 1]\n",
            "Source:     jessie j is being sued by a us singer , who says that her single domino copies one of his songs .\n",
            "Reference:  m·ªôt √Ω t∆∞·ªüng ƒë∆∞·ª£c g·ªçi l√† quy·ªÅn ti·∫øp c·∫≠n t√†i ch√≠nh ngay t·ª´ l√∫c m·ªõi sinh , vi·∫øt t·∫Øt l√† fab .\n",
            "Prediction: m·ªôt √Ω t∆∞·ªüng l√† ƒë∆∞·ª£c g·ªçi l√† truy c·∫≠p ·ªü c√°c d√≤ng sinh n·ªü , ho·∫∑c c√°c m√°y t·ª´ s·ªØa b·ªôt .\n",
            "\n",
            "[Example 2]\n",
            "Source:     will loomis claims that portions of the british star 's hit were lifted from his 2008 track , bright red chords .\n",
            "Reference:  g·∫ßn ¬æ s·ªë tr∆∞·ªùng h·ª£p m·∫Øc b·ªánh d·∫°i t·ª´ 1990 ƒë·∫øn 2001 l√† do ti·∫øp x√∫c v·ªõi d∆°i .\n",
            "Prediction: g·∫ßn ba ph·∫ßn l·ªõn c√°c tr∆∞·ªùng h·ª£p nhi·ªÖm tr√πng gi·ªØa nƒÉm 1990 v√† nƒÉm 1990 ƒë·∫øn t·ª´ v·ª• t·∫•n x√£ c·∫£nh b√°o v·ªõi ng∆∞·ªùi d∆°i bay c·∫£nh s√°t n∆°i bay ƒë·∫øn n∆°i bay thung l≈©ng ch·∫øt .\n",
            "\n",
            "[Example 3]\n",
            "Source:     loomis never consented to the use of his song , said the singer 's lawyer in a statement .\n",
            "Reference:  2008 : martti ahtisaari\n",
            "Prediction: 2008 : qu·∫£ng c√°o v√†ng s√≥ng nhanh ch√≥ng sau v·ª• n·ªï s√≥ng th·∫ßn ti√™n c·ªßa kh·ª© ƒë√£ l√†m rung chuy·ªÉn t·ª´ kh·ª© s·∫Øc b√©n sau nƒÉm 2008 : kh·ª© ƒë√£ ƒë√¢m v√†o nƒÉm 2008 :\n",
            "\n",
            "[Example 4]\n",
            "Source:     we look forward to obtaining an appropriate remedy .\n",
            "Reference:  m·ª•n m·ªß - c√≥ th·ªÉ nh√¨n th·∫•y tr√™n b·ªÅ m·∫∑t c·ªßa da .\n",
            "Prediction: ch√† - ch·ª•p s∆∞∆°ng m√π r√µ r√µ r√†ng tr√™n b·ªÅ m·∫∑t c·ªßa da tr√™n da .\n",
            "\n",
            "[Example 5]\n",
            "Source:     jessie j and her representatives said they would not currently be commenting on the case .\n",
            "Reference:  c√°c v·ªã b·ªô tr∆∞·ªüng ƒë√£ th·∫£o lu·∫≠n v·∫•n ƒë·ªÅ m√† c√°c b√™n ƒë·∫∑c bi·ªát quan t√¢m , bao g·ªìm t√¨m hi·ªÉu ·∫£nh h∆∞·ªüng c·ªßa vi·ªác thay ƒë·ªïi kh√≠ h·∫≠u v√† bi·ªán ph√°p ph·∫£n ·ª©ng c√≥ hi·ªáu qu·∫£ ; ph√≤ng ch·ªëng b·ªánh truy·ªÅn nhi·ªÖm ; m·ªü r·ªông vi·ªác s·ª≠ d·ª•ng c√¥ng ngh·ªá ph·ª•c v·ª• gi√°o d·ª•c v√† ph√°t tri·ªÉn , nh·∫•t l√† ·ªü v√πng n√¥ng th√¥n ; c√¥ng t√°c ph√°t tri·ªÉn c∆° s·ªü h·∫° t·∫ßng .\n",
            "Prediction: b·ªô tr∆∞·ªüng ƒë√£ th·∫£o lu·∫≠n c√πng v·ªõi ∆∞u ti√™n , bao g·ªìm ·∫£nh h∆∞·ªüng v·ªÅ kh√≠ h·∫≠u v√† thay ƒë·ªïi ph·∫£n ·ª©ng c·ªßa cu·ªôc ƒë·∫•u , ph·∫£n ·ª©ng l·∫°i , ph·∫£n ·ª©ng truy·ªÅn th·∫ßn kinh ; c√°c cu·ªôc s·ªëng truy·ªÅn h√¨nh , v√† ph√°t tri·ªÉn khai th√°c n∆∞·ªõc ti·ªÉu ,\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EVALUATING ON TEST SET\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "test_loss = evaluate(model, test_loader, criterion)\n",
        "test_ppl = math.exp(test_loss)\n",
        "\n",
        "print(f\"\\nüìä Test Results:\")\n",
        "print(f\"  Test Loss:       {test_loss:.4f}\")\n",
        "print(f\"  Test Perplexity: {test_ppl:.2f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Cell 21: Calculate BLEU Score\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 8: CALCULATING BLEU SCORE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "bleu_score, predictions, references = calculate_bleu(\n",
        "    model, (test_en, test_vi), en_tokenizer, vi_tokenizer, sample_size=100\n",
        ")\n",
        "\n",
        "print(f\"\\nüéØ BLEU Score: {bleu_score:.2f}\")\n",
        "\n",
        "print(\"\\nüìù Sample Translations:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for i in range(min(5, len(predictions))):\n",
        "    # Clean test sentences (remove BOS/EOS for display)\n",
        "    test_en_clean = test_en[i].replace(BOS, '').replace(EOS, '').strip()\n",
        "\n",
        "    print(f\"\\n[Example {i+1}]\")\n",
        "    print(f\"Source:     {test_en_clean}\")\n",
        "    print(f\"Reference:  {references[i]}\")\n",
        "    print(f\"Prediction: {predictions[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "EKs9WrUJb5gg",
        "outputId": "5c7bf8b6-e768-4d29-f6c1-d6c19ebad6c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "VISUALIZING RESULTS\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Training curves saved to 'training_curves.png'\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"VISUALIZING RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "plt.plot(epochs, train_losses, 'bo-', label='Train Loss', linewidth=2, markersize=6)\n",
        "plt.plot(epochs, val_losses, 'rs-', label='Val Loss', linewidth=2, markersize=6)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Perplexity plot\n",
        "plt.subplot(1, 2, 2)\n",
        "train_ppls = [math.exp(loss) for loss in train_losses]\n",
        "val_ppls = [math.exp(loss) for loss in val_losses]\n",
        "plt.plot(epochs, train_ppls, 'bo-', label='Train Perplexity', linewidth=2, markersize=6)\n",
        "plt.plot(epochs, val_ppls, 'rs-', label='Val Perplexity', linewidth=2, markersize=6)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Perplexity', fontsize=12)\n",
        "plt.title('Training and Validation Perplexity', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úì Training curves saved to 'training_curves.png'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0jRXG75b7fj",
        "outputId": "92c86bd7-5d80-4e62-f190-e6026ccc2928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "SAVING RESULTS\n",
            "======================================================================\n",
            "‚úì Results saved to 'results.pkl'\n",
            "‚úì Tokenizers saved to 'en_tokenizer.pkl' and 'vi_tokenizer.pkl'\n",
            "‚úì Best model saved to 'best_model.pt'\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SAVING RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_perplexity': test_ppl,\n",
        "    'bleu_score': bleu_score,\n",
        "    'config': config,\n",
        "    'vocab_sizes': {\n",
        "        'en': en_tokenizer.get_vocab_size(),\n",
        "        'vi': vi_tokenizer.get_vocab_size()\n",
        "    },\n",
        "    'training_time': total_time,\n",
        "    'train_losses': train_losses,\n",
        "    'val_losses': val_losses\n",
        "}\n",
        "\n",
        "with open('results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "\n",
        "# Save tokenizers\n",
        "en_tokenizer.save('en_tokenizer.pkl')\n",
        "vi_tokenizer.save('vi_tokenizer.pkl')\n",
        "\n",
        "print(\"‚úì Results saved to 'results.pkl'\")\n",
        "print(\"‚úì Tokenizers saved to 'en_tokenizer.pkl' and 'vi_tokenizer.pkl'\")\n",
        "print(\"‚úì Best model saved to 'best_model.pt'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OArymzMUb9vv",
        "outputId": "14a3d2e8-473c-4bbf-e676-185cc4bb59c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "FINAL TRANSLATION QUALITY REPORT\n",
            "======================================================================\n",
            "\n",
            "üìä Model Performance:\n",
            "  Metric               Value          \n",
            "  -----------------------------------\n",
            "  Test Loss            3.5252         \n",
            "  Test Perplexity      33.96          \n",
            "  BLEU Score           14.91          \n",
            "\n",
            "üìê Model Size:\n",
            "  EN Vocabulary        30,560         \n",
            "  VI Vocabulary        13,154         \n",
            "  Parameters           18,526,050     \n",
            "\n",
            "‚è±Ô∏è  Training Time:\n",
            "  Total Time           98.25           minutes\n",
            "  Avg per Epoch        0.98            minutes\n",
            "\n",
            "‚úÖ Training Complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FINAL TRANSLATION QUALITY REPORT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\nüìä Model Performance:\")\n",
        "print(f\"  {'Metric':<20} {'Value':<15}\")\n",
        "print(f\"  {'-'*35}\")\n",
        "print(f\"  {'Test Loss':<20} {test_loss:<15.4f}\")\n",
        "print(f\"  {'Test Perplexity':<20} {test_ppl:<15.2f}\")\n",
        "print(f\"  {'BLEU Score':<20} {bleu_score:<15.2f}\")\n",
        "\n",
        "print(f\"\\nüìê Model Size:\")\n",
        "print(f\"  {'EN Vocabulary':<20} {en_tokenizer.get_vocab_size():<15,}\")\n",
        "print(f\"  {'VI Vocabulary':<20} {vi_tokenizer.get_vocab_size():<15,}\")\n",
        "print(f\"  {'Parameters':<20} {total_params:<15,}\")\n",
        "\n",
        "print(f\"\\n‚è±Ô∏è  Training Time:\")\n",
        "print(f\"  {'Total Time':<20} {total_time/60:<15.2f} minutes\")\n",
        "print(f\"  {'Avg per Epoch':<20} {total_time/config['num_epochs']/60:<15.2f} minutes\")\n",
        "\n",
        "print(\"\\n‚úÖ Training Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv3R6caEcDFF",
        "outputId": "0cefddb3-d0c6-4526-a5d0-ce2dde288f9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "INTERACTIVE TRANSLATION\n",
            "======================================================================\n",
            "Enter English sentences to translate to Vietnamese\n",
            "Type 'quit', 'exit', or 'q' to stop\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"INTERACTIVE TRANSLATION\")\n",
        "print(\"=\" * 70)\n",
        "print(\"Enter English sentences to translate to Vietnamese\")\n",
        "print(\"Type 'quit', 'exit', or 'q' to stop\\n\")\n",
        "\n",
        "while True:\n",
        "    sentence = input(\"üá¨üáß EN: \").strip()\n",
        "\n",
        "    if sentence.lower() in ['quit', 'exit', 'q', '']:\n",
        "        print(\"üëã Goodbye!\")\n",
        "        break\n",
        "\n",
        "    try:\n",
        "        translation = translate_sentence(model, sentence, en_tokenizer, vi_tokenizer)\n",
        "        print(f\"üáªüá≥ VI: {translation}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZR73uv0iL0G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPY5ptqpB1BVGwSgMMeDnnh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}