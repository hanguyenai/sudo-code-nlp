# 01. Text Preprocessing

This folder contains notebooks and code related to **text preprocessing** in NLP.  
It is part of the **Sudo Code Program NLP** repository.

## ğŸ“‚ Contents

- **Unicode & Diacritic Normalization**  
  Ensure consistent text representation by normalizing Unicode forms (NFC/NFKC).  
  Example: `"HoÃ "` and `"HoaÌ€"` â†’ `"HoÃ "`.

- **Removing Noise (HTML tags, URLs, emails, numbers, emojis)**  
  Clean the text by removing unnecessary elements such as:  
  - HTML tags (`<div>`, `<p>`, â€¦)  
  - URLs (http://, https://)  
  - Email addresses (e.g., `abc@gmail.com`)  
  - Numbers (e.g., `2025`, `12345`)  
  - Emojis (ğŸ˜ŠğŸ˜‚ğŸ”¥)

- **Vietnamese Tokenization â€“ PyVi**  
  Segment sentences into meaningful words, preserving multi-syllable words.  
  Example:  
  - Input: `TÃ´i sá»‘ng á»Ÿ HÃ  Ná»™i`  
  - Output: `["TÃ´i", "sá»‘ng", "á»Ÿ", "HÃ _Ná»™i"]`

- **Smart Lowercasing with POS Tagging**  
  Convert text to lowercase while keeping **proper nouns (PROPN)** intact.  
  - Example: `"Viá»‡t Nam"` should remain `"Viá»‡t_Nam"`,  
    while `"TrÆ°á»ng há»c ráº¥t Ä‘áº¹p"` â†’ `"trÆ°á»ng_há»c ráº¥t Ä‘áº¹p"`.

---

### ğŸ†• More Preprocessing Methods (to be added)

- **Stopword Removal**  
  Eliminate common words (*â€œlÃ â€*, *â€œvÃ â€*, *â€œcá»§aâ€*) that do not add semantic value.  

- **Stemming & Lemmatization**  
  Reduce words to their root form.  
  - *há»c*, *há»c táº­p*, *há»c sinh* â†’ *há»c*  

- **Handling Abbreviations & Acronyms**  
  Expand or standardize abbreviations.  
  - *TP.HCM* â†’ *ThÃ nh_phá»‘_Há»“_ChÃ­_Minh*  
  - *UN* â†’ *United_Nations*  

- **Synonym Normalization**  
  Map different words with the same meaning to one form.  
  - *xe hÆ¡i* = *Ã´ tÃ´*  

- **Spelling Correction**  
  Fix common typos or OCR errors.  
  - *ngÃ´n ngá»¯ anh* â†’ *ngÃ´n_ngá»¯_anh*  

- **Handling Negations**  
  Mark or transform negative phrases to preserve meaning.  
  - *khÃ´ng vui* â†’ *khÃ´ng_vui*  

- **Part-of-Speech Filtering**  
  Keep only relevant word types (e.g., nouns, verbs, adjectives).  

- **Lemmatization with Dictionaries**  
  Use Vietnamese lexicons to convert inflected forms to their canonical form.  

- **Handling Rare Words / Class Balancing**  
  Replace low-frequency terms with `<UNK>` or group rare labels into `"other"`.  

## ğŸ“’ Notebook

- [Vietnam Online News Text Processing](Vietnam_Online_News_Text_Processing.ipynb)

## ğŸ“š References
- [NLTK Book â€“ Chapter 3: Processing Raw Text](https://www.nltk.org/book/ch03.html)  
- [PyVi: Vietnamese Tokenizer](https://github.com/trungtv/pyvi)  
- [Underthesea Documentation](https://underthesea.readthedocs.io/en/latest/)  
- [Jurafsky & Martin â€“ Speech and Language Processing (3rd ed. draft, Chapter 2)](https://web.stanford.edu/~jurafsky/slp3/2.pdf)  
